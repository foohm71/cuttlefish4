{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestAgentWorkflow.ipynb\n",
    "\n",
    "## Comprehensive Testing for MultiAgentWorkflow (workflow.py)\n",
    "\n",
    "This notebook tests the complete multi-agent workflow system that orchestrates the RAG pipeline for the FastAPI application.\n",
    "\n",
    "### Test Coverage:\n",
    "1. **Workflow Initialization** - Component setup and configuration\n",
    "2. **Supervisor Routing** - Agent selection based on query characteristics  \n",
    "3. **Supabase Fallback Methods** - BM25, Vector, and Hybrid search fallbacks\n",
    "4. **Complete Query Processing** - End-to-end workflow execution\n",
    "5. **Error Handling** - Robustness and edge cases\n",
    "6. **Performance Metrics** - Timing and resource usage\n",
    "\n",
    "---\n",
    "\n",
    "**Created**: August 15, 2025  \n",
    "**Purpose**: Validate MultiAgentWorkflow functionality before API integration  \n",
    "**Dependencies**: Supabase, OpenAI, RAG Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 INSTALLING REQUIRED PACKAGES\n",
      "==================================================\n",
      "🔄 Installing packages...\n",
      "   Installing openai>=1.0.0...Requirement already satisfied: openai>=1.0.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (1.99.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai>=1.0.0) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai>=1.0.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai>=1.0.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai>=1.0.0) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai>=1.0.0) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai>=1.0.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai>=1.0.0) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai>=1.0.0) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai>=1.0.0) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0) (0.4.1)\n",
      " ✅\n",
      "   Installing langchain-openai..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (0.1.22)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.33 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-openai) (0.2.38)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-openai) (1.99.9)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (4.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.33->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.33->langchain-openai) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.33->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.33->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.33->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.33->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
      " ✅\n",
      "   Installing langchain-core..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (0.2.38)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core) (2.11.7)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langchain-core) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core) (3.11.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.1)\n",
      "Requirement already satisfied: anyio in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (1.3.1)\n",
      " ✅\n",
      "   Installing supabase>=2.0.0..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: supabase>=2.0.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (2.18.0)\n",
      "Requirement already satisfied: postgrest==1.1.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from supabase>=2.0.0) (1.1.1)\n",
      "Requirement already satisfied: realtime==2.7.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from supabase>=2.0.0) (2.7.0)\n",
      "Requirement already satisfied: gotrue==2.12.3 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from supabase>=2.0.0) (2.12.3)\n",
      "Requirement already satisfied: storage3==0.12.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from supabase>=2.0.0) (0.12.1)\n",
      "Requirement already satisfied: supafunc==0.10.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from supabase>=2.0.0) (0.10.1)\n",
      "Requirement already satisfied: httpx<0.29,>=0.26 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from supabase>=2.0.0) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from gotrue==2.12.3->supabase>=2.0.0) (2.11.7)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from gotrue==2.12.3->supabase>=2.0.0) (2.10.1)\n",
      "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from postgrest==1.1.1->supabase>=2.0.0) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.14.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from realtime==2.7.0->supabase>=2.0.0) (4.14.1)\n",
      "Requirement already satisfied: websockets<16,>=11 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from realtime==2.7.0->supabase>=2.0.0) (15.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from storage3==0.12.1->supabase>=2.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: strenum<0.5.0,>=0.4.15 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from supafunc==0.10.1->supabase>=2.0.0) (0.4.15)\n",
      "Requirement already satisfied: anyio in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<0.29,>=0.26->supabase>=2.0.0) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<0.29,>=0.26->supabase>=2.0.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<0.29,>=0.26->supabase>=2.0.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx<0.29,>=0.26->supabase>=2.0.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase>=2.0.0) (0.16.0)\n",
      "Requirement already satisfied: packaging in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from deprecation<3.0.0,>=2.1.0->postgrest==1.1.1->supabase>=2.0.0) (24.2)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from httpx[http2]<0.29,>=0.26->gotrue==2.12.3->supabase>=2.0.0) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3,>=1.10->gotrue==2.12.3->supabase>=2.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3,>=1.10->gotrue==2.12.3->supabase>=2.0.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic<3,>=1.10->gotrue==2.12.3->supabase>=2.0.0) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.8.2->storage3==0.12.1->supabase>=2.0.0) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from anyio->httpx<0.29,>=0.26->supabase>=2.0.0) (1.3.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue==2.12.3->supabase>=2.0.0) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue==2.12.3->supabase>=2.0.0) (4.1.0)\n",
      " ✅\n",
      "   Installing python-dotenv..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (1.0.0)\n",
      " ✅\n",
      "   Installing pydantic>=2.0.0..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic>=2.0.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (2.11.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic>=2.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic>=2.0.0) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic>=2.0.0) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pydantic>=2.0.0) (0.4.1)\n",
      " ✅\n",
      "   Installing nest-asyncio..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest-asyncio in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (1.6.0)\n",
      " ✅\n",
      "   Installing numpy<2.0.0,>=1.26.0..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (1.26.4)\n",
      " ✅\n",
      "   Installing pandas..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      " ✅\n",
      "\n",
      "✅ Package installation completed!\n",
      "⚠️  Note: If any installations failed, you may need to install them manually\n",
      "   Example: pip install openai langchain-openai supabase python-dotenv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "print(\"📦 INSTALLING REQUIRED PACKAGES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of required packages for the workflow testing\n",
    "required_packages = [\n",
    "    \"openai>=1.0.0\",\n",
    "    \"langchain-openai\", \n",
    "    \"langchain-core\",\n",
    "    \"supabase>=2.0.0\",\n",
    "    \"python-dotenv\",\n",
    "    \"pydantic>=2.0.0\",\n",
    "    \"nest-asyncio\",  # For async support in Jupyter\n",
    "    \"numpy<2.0.0,>=1.26.0\",\n",
    "    \"pandas\",  # May be useful for results analysis\n",
    "]\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip.\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        return True\n",
    "    except subprocess.CalledProcessError:\n",
    "        return False\n",
    "\n",
    "print(\"🔄 Installing packages...\")\n",
    "\n",
    "for package in required_packages:\n",
    "    print(f\"   Installing {package}...\", end=\"\")\n",
    "    if install_package(package):\n",
    "        print(\" ✅\")\n",
    "    else:\n",
    "        print(f\" ❌ (failed)\")\n",
    "\n",
    "print(\"\\n✅ Package installation completed!\")\n",
    "print(\"⚠️  Note: If any installations failed, you may need to install them manually\")\n",
    "print(\"   Example: pip install openai langchain-openai supabase python-dotenv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 SETTING UP TEST ENVIRONMENT\n",
      "==================================================\n",
      "📁 Current Directory: /Users/foohm/github/cuttlefish4/app/api\n",
      "📁 App Directory: /Users/foohm/github/cuttlefish4/app\n",
      "📁 Project Root: /Users/foohm/github/cuttlefish4\n",
      "📎 Added to path: /Users/foohm/github/cuttlefish4\n",
      "📎 Added to path: /Users/foohm/github/cuttlefish4/app\n",
      "📎 Added to path: /Users/foohm/github/cuttlefish4/app/agents\n",
      "📎 Added to path: /Users/foohm/github/cuttlefish4/app/tools\n",
      "📎 Added to path: /Users/foohm/github/cuttlefish4/app/rag\n",
      "✅ Python paths configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "# Setup paths for imports\n",
    "print(\"🔧 SETTING UP TEST ENVIRONMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get the current working directory\n",
    "current_path = Path.cwd()\n",
    "print(f\"📁 Current Directory: {current_path}\")\n",
    "\n",
    "# Navigate to app directory \n",
    "app_dir = current_path.parent\n",
    "project_root = app_dir.parent\n",
    "\n",
    "print(f\"📁 App Directory: {app_dir}\")\n",
    "print(f\"📁 Project Root: {project_root}\")\n",
    "\n",
    "# Add necessary paths to Python path\n",
    "for path in [str(project_root), str(app_dir), str(app_dir / 'agents'), str(app_dir / 'tools'), str(app_dir / 'rag')]:\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "        print(f\"📎 Added to path: {path}\")\n",
    "\n",
    "print(\"✅ Python paths configured\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌍 LOADING ENVIRONMENT\n",
      "==================================================\n",
      "✅ Environment loaded from: /Users/foohm/github/cuttlefish4/.env\n",
      "✅ OPENAI_API_KEY: **********...IzAA\n",
      "✅ SUPABASE_URL: **********...e.co\n",
      "✅ SUPABASE_KEY: **********...PhMQ\n",
      "✅ CUTTLEFISH_HOME: **********...ish4\n",
      "✅ All required environment variables found\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "print(\"\\n🌍 LOADING ENVIRONMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    # Try to load .env from project root\n",
    "    env_file = project_root / \".env\"\n",
    "    if env_file.exists():\n",
    "        load_dotenv(str(env_file))\n",
    "        print(f\"✅ Environment loaded from: {env_file}\")\n",
    "    else:\n",
    "        load_dotenv()\n",
    "        print(\"⚠️  .env file not found in project root, using system environment\")\n",
    "        \n",
    "    # Check required environment variables\n",
    "    required_vars = ['OPENAI_API_KEY', 'SUPABASE_URL', 'SUPABASE_KEY', 'CUTTLEFISH_HOME']\n",
    "    missing_vars = []\n",
    "    \n",
    "    for var in required_vars:\n",
    "        if os.environ.get(var):\n",
    "            print(f\"✅ {var}: {'*' * 10}...{os.environ.get(var)[-4:]}\")\n",
    "        else:\n",
    "            missing_vars.append(var)\n",
    "            print(f\"❌ {var}: Missing\")\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"⚠️  Missing required variables: {', '.join(missing_vars)}\")\n",
    "        print(\"   Tests may fail without these variables\")\n",
    "    else:\n",
    "        print(\"✅ All required environment variables found\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"⚠️  python-dotenv not installed, using system environment variables\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Environment loading error: {e}\")\n",
    "\n",
    "# Set CUTTLEFISH_HOME to project root\n",
    "if 'CUTTLEFISH_HOME' not in os.environ:\n",
    "    os.environ['CUTTLEFISH_HOME'] = str(project_root)\n",
    "    print(f\"🏠 Set CUTTLEFISH_HOME to: {project_root}\")\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"📎 Added project root to path: {project_root}\")\n",
    "\n",
    "# Add app directory to Python path for direct imports\n",
    "if str(app_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(app_dir))\n",
    "    print(f\"📎 Added app dir to path: {app_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "import_components"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 IMPORTING COMPONENTS\n",
      "==================================================\n",
      "✅ MultiAgentWorkflow imported\n",
      "✅ Pydantic models imported\n",
      "✅ LangChain OpenAI imported\n",
      "✅ Testing utilities imported\n",
      "✅ Import phase completed\n"
     ]
    }
   ],
   "source": [
    "# Import all required components\n",
    "print(\"\\n📦 IMPORTING COMPONENTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Core workflow import\n",
    "try:\n",
    "    from workflow import MultiAgentWorkflow\n",
    "    print(\"✅ MultiAgentWorkflow imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ MultiAgentWorkflow import failed: {e}\")\n",
    "    print(\"   Trying alternative import paths...\")\n",
    "    try:\n",
    "        from api.workflow import MultiAgentWorkflow\n",
    "        print(\"✅ MultiAgentWorkflow imported (alternative path)\")\n",
    "    except ImportError as e2:\n",
    "        print(f\"❌ Alternative import also failed: {e2}\")\n",
    "\n",
    "# Import models for validation\n",
    "try:\n",
    "    from models import (\n",
    "        MultiAgentRAGRequest, MultiAgentRAGResponse, \n",
    "        DebugRoutingRequest, DebugRoutingResponse,\n",
    "        RetrievalMetadata, RetrievedContext, RelevantTicket\n",
    "    )\n",
    "    print(\"✅ Pydantic models imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠️  Pydantic models import failed: {e}\")\n",
    "    print(\"   Will create mock data structures\")\n",
    "\n",
    "# Import supporting components\n",
    "try:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    print(\"✅ LangChain OpenAI imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ LangChain OpenAI import failed: {e}\")\n",
    "\n",
    "# Test framework imports\n",
    "try:\n",
    "    import json\n",
    "    import time\n",
    "    from unittest.mock import Mock, patch\n",
    "    print(\"✅ Testing utilities imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠️  Some testing utilities unavailable: {e}\")\n",
    "\n",
    "print(\"✅ Import phase completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: MultiAgentWorkflow Initialization\n",
    "\n",
    "Test the initialization of the workflow system, including:\n",
    "- LLM setup (GPT-4o for supervisor/response, GPT-4o-mini for RAG)\n",
    "- Vectorstore connection (Qdrant fallback to Supabase)\n",
    "- Agent initialization (Supervisor, ResponseWriter, and retrieval agents)\n",
    "- RAG tools integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "multiagentworkflow_init"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:00,249 - MultiAgentWorkflow - INFO - ✅ LLMs initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 TEST 1: MULTIAGENTWORKFLOW INITIALIZATION\n",
      "============================================================\n",
      "🔄 Creating MultiAgentWorkflow instance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:01,014 - SupabaseRetriever_bugs - INFO - ✅ Connection to bugs table successful\n",
      "2025-08-18 19:03:01,360 - SupabaseRetriever_pcr - INFO - ✅ Connection to pcr table successful\n",
      "2025-08-18 19:03:01,361 - MultiAgentWorkflow - INFO - ✅ Connected to Supabase retrievers (bugs & pcr)\n",
      "2025-08-18 19:03:01,362 - MultiAgentWorkflow - INFO - ✅ Vectorstore and RAG tools initialized\n",
      "2025-08-18 19:03:01,372 - MultiAgentWorkflow - WARNING - Using mock agents - full Supabase integration needed\n",
      "2025-08-18 19:03:01,373 - MultiAgentWorkflow - INFO - ✅ Agents initialized\n",
      "2025-08-18 19:03:01,373 - MultiAgentWorkflow - INFO - ✅ Multi-agent workflow initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MultiAgentWorkflow created in 1.27s\n",
      "\n",
      "🔍 Checking LLM initialization...\n",
      "   ✅ Supervisor LLM: gpt-4o\n",
      "   ✅ RAG LLM: gpt-4o-mini\n",
      "   ✅ Response Writer LLM: gpt-4o\n",
      "\n",
      "🔍 Checking vectorstore setup...\n",
      "   ⚠️  No vectorstore connected - using Supabase fallbacks\n",
      "\n",
      "🔍 Checking RAG tools...\n",
      "   ✅ RAG tools initialized: RAGTools\n",
      "\n",
      "🔍 Checking agent initialization...\n",
      "   ✅ supervisor_agent: SupervisorAgent\n",
      "   ✅ response_writer_agent: ResponseWriterAgent\n",
      "   ⚠️  bm25_agent: None (expected for Supabase fallbacks)\n",
      "   ⚠️  contextual_compression_agent: None (expected for Supabase fallbacks)\n",
      "   ⚠️  ensemble_agent: None (expected for Supabase fallbacks)\n",
      "\n",
      "📊 INITIALIZATION SUMMARY:\n",
      "   ✅ Workflow Creation: True\n",
      "   ✅ Llm Initialization: True\n",
      "   ✅ Vectorstore Setup: True\n",
      "   ✅ Agents Initialization: True\n",
      "   ✅ Rag Tools Setup: True\n",
      "\n",
      "🎉 ALL INITIALIZATION TESTS PASSED! (we do not need QDrant so Supabase fallback is expected)\n"
     ]
    }
   ],
   "source": [
    "# Test 1: MultiAgentWorkflow Initialization\n",
    "print(\"\\n🧪 TEST 1: MULTIAGENTWORKFLOW INITIALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "workflow = None\n",
    "initialization_results = {\n",
    "    'workflow_creation': False,\n",
    "    'llm_initialization': False,\n",
    "    'vectorstore_setup': False,\n",
    "    'agents_initialization': False,\n",
    "    'rag_tools_setup': False,\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(\"🔄 Creating MultiAgentWorkflow instance...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize the workflow\n",
    "    workflow = MultiAgentWorkflow()\n",
    "    initialization_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"✅ MultiAgentWorkflow created in {initialization_time:.2f}s\")\n",
    "    initialization_results['workflow_creation'] = True\n",
    "    \n",
    "    # Test LLM initialization\n",
    "    print(\"\\n🔍 Checking LLM initialization...\")\n",
    "    if hasattr(workflow, 'supervisor_llm') and workflow.supervisor_llm:\n",
    "        print(f\"   ✅ Supervisor LLM: {workflow.supervisor_llm.model_name}\")\n",
    "        initialization_results['llm_initialization'] = True\n",
    "    else:\n",
    "        print(\"   ❌ Supervisor LLM not initialized\")\n",
    "        \n",
    "    if hasattr(workflow, 'rag_llm') and workflow.rag_llm:\n",
    "        print(f\"   ✅ RAG LLM: {workflow.rag_llm.model_name}\")\n",
    "    else:\n",
    "        print(\"   ❌ RAG LLM not initialized\")\n",
    "        \n",
    "    if hasattr(workflow, 'response_writer_llm') and workflow.response_writer_llm:\n",
    "        print(f\"   ✅ Response Writer LLM: {workflow.response_writer_llm.model_name}\")\n",
    "    else:\n",
    "        print(\"   ❌ Response Writer LLM not initialized\")\n",
    "    \n",
    "    # Test vectorstore setup\n",
    "    print(f\"\\n🔍 Checking vectorstore setup...\")\n",
    "    if hasattr(workflow, 'vectorstore'):\n",
    "        if workflow.vectorstore:\n",
    "            print(f\"   ✅ Vectorstore connected: {type(workflow.vectorstore).__name__}\")\n",
    "            initialization_results['vectorstore_setup'] = True\n",
    "        else:\n",
    "            print(\"   ⚠️  No vectorstore connected - using Supabase fallbacks\")\n",
    "            initialization_results['vectorstore_setup'] = True  # This is expected\n",
    "    \n",
    "    # Test RAG tools setup\n",
    "    print(f\"\\n🔍 Checking RAG tools...\")\n",
    "    if hasattr(workflow, 'rag_tools') and workflow.rag_tools:\n",
    "        print(f\"   ✅ RAG tools initialized: {type(workflow.rag_tools).__name__}\")\n",
    "        initialization_results['rag_tools_setup'] = True\n",
    "    else:\n",
    "        print(\"   ❌ RAG tools not initialized\")\n",
    "    \n",
    "    # Test agent initialization\n",
    "    print(f\"\\n🔍 Checking agent initialization...\")\n",
    "    agents_status = {}\n",
    "    \n",
    "    for agent_name in ['supervisor_agent', 'response_writer_agent', 'bm25_agent', 'contextual_compression_agent', 'ensemble_agent']:\n",
    "        if hasattr(workflow, agent_name):\n",
    "            agent = getattr(workflow, agent_name)\n",
    "            if agent:\n",
    "                print(f\"   ✅ {agent_name}: {type(agent).__name__}\")\n",
    "                agents_status[agent_name] = True\n",
    "            else:\n",
    "                print(f\"   ⚠️  {agent_name}: None (expected for Supabase fallbacks)\")\n",
    "                agents_status[agent_name] = 'expected_none'\n",
    "        else:\n",
    "            print(f\"   ❌ {agent_name}: Missing attribute\")\n",
    "            agents_status[agent_name] = False\n",
    "    \n",
    "    # At least supervisor and response writer should be initialized\n",
    "    if agents_status.get('supervisor_agent') and agents_status.get('response_writer_agent'):\n",
    "        initialization_results['agents_initialization'] = True\n",
    "    \n",
    "    print(f\"\\n📊 INITIALIZATION SUMMARY:\")\n",
    "    for key, status in initialization_results.items():\n",
    "        if key != 'errors':\n",
    "            status_icon = \"✅\" if status else \"❌\"\n",
    "            print(f\"   {status_icon} {key.replace('_', ' ').title()}: {status}\")\n",
    "    \n",
    "    if all(v for k, v in initialization_results.items() if k != 'errors'):\n",
    "        print(\"\\n🎉 ALL INITIALIZATION TESTS PASSED! (we do not need QDrant so Supabase fallback is expected)\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  Some initialization components failed - check details above\")\n",
    "\n",
    "except Exception as e:\n",
    "    error_msg = f\"Initialization failed: {str(e)}\"\n",
    "    print(f\"❌ {error_msg}\")\n",
    "    initialization_results['errors'].append(error_msg)\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Initialized summary_data for comprehensive workflow test tracking\n",
      "   This will collect results from all workflow tests including WebSearch integration\n"
     ]
    }
   ],
   "source": [
    "# Initialize summary_data for tracking workflow test results\n",
    "from datetime import datetime\n",
    "\n",
    "summary_data = {\n",
    "    'components_tested': [],\n",
    "    'test_results': {},\n",
    "    'recommendations': [],\n",
    "    'overall_status': 'PENDING',\n",
    "    'start_time': datetime.now().isoformat(),\n",
    "    'workflow_tests': {\n",
    "        'initialization': False,\n",
    "        'routing': False,\n",
    "        'fallback_methods': False,\n",
    "        'query_processing': False,\n",
    "        'error_handling': False,\n",
    "        'websearch_routing': False,\n",
    "        'websearch_integration': False\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"✅ Initialized summary_data for comprehensive workflow test tracking\")\n",
    "print(\"   This will collect results from all workflow tests including WebSearch integration\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Supervisor Routing Decisions\n",
    "\n",
    "Test the supervisor agent's routing logic with different query types:\n",
    "- **Production incidents** → ContextualCompression (urgent)  \n",
    "- **User can wait** → Ensemble (comprehensive)\n",
    "- **JIRA ticket references** → BM25 (exact match)\n",
    "- **General queries** → ContextualCompression (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:01,393 - MultiAgentWorkflow - INFO - Getting routing decision for: 'database connection timeout causing login failures...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 TEST 2: SUPERVISOR ROUTING DECISIONS\n",
      "============================================================\n",
      "🔄 Testing supervisor routing decisions...\n",
      "\n",
      "📋 Scenario 1: Production Incident\n",
      "   Query: 'database connection timeout causing login failures...'\n",
      "   user_can_wait: False, production_incident: True\n",
      "🧠 Supervisor Agent analyzing query: 'database connection timeout causing login failures'\n",
      "   user_can_wait: False, production_incident: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:02,783 - MultiAgentWorkflow - INFO - Getting routing decision for: 'authentication error patterns in recent tickets...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: ContextualCompression - The query is about a production incident and the user cannot wait, so a fast semantic search is needed.\n",
      "   Analysis time: 1.39s\n",
      "   🎯 Decision: ContextualCompression (1.39s)\n",
      "   💭 Reasoning: The query is about a production incident and the user cannot wait, so a fast semantic search is need...\n",
      "   ✅ Routing decision correct\n",
      "\n",
      "📋 Scenario 2: User Can Wait\n",
      "   Query: 'authentication error patterns in recent tickets...'\n",
      "   user_can_wait: True, production_incident: False\n",
      "🧠 Supervisor Agent analyzing query: 'authentication error patterns in recent tickets'\n",
      "   user_can_wait: True, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:04,418 - MultiAgentWorkflow - INFO - Getting routing decision for: 'HBASE-12345 connection timeout issue details...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: Ensemble - The query is complex and user_can_wait=True, allowing for a comprehensive search to analyze authentication error patterns in recent tickets.\n",
      "   Analysis time: 1.63s\n",
      "   🎯 Decision: Ensemble (1.63s)\n",
      "   💭 Reasoning: The query is complex and user_can_wait=True, allowing for a comprehensive search to analyze authenti...\n",
      "   ✅ Routing decision correct\n",
      "\n",
      "📋 Scenario 3: JIRA Ticket Reference\n",
      "   Query: 'HBASE-12345 connection timeout issue details...'\n",
      "   user_can_wait: False, production_incident: False\n",
      "🧠 Supervisor Agent analyzing query: 'HBASE-12345 connection timeout issue details'\n",
      "   user_can_wait: False, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:05,631 - MultiAgentWorkflow - INFO - Getting routing decision for: 'Java OutOfMemoryError troubleshooting...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: BM25 - The query contains a specific ticket reference 'HBASE-12345', which is best handled by the BM25 agent for fast keyword-based search.\n",
      "   Analysis time: 1.21s\n",
      "   🎯 Decision: BM25 (1.21s)\n",
      "   💭 Reasoning: The query contains a specific ticket reference 'HBASE-12345', which is best handled by the BM25 agen...\n",
      "   ✅ Routing decision correct\n",
      "\n",
      "📋 Scenario 4: General Query\n",
      "   Query: 'Java OutOfMemoryError troubleshooting...'\n",
      "   user_can_wait: False, production_incident: False\n",
      "🧠 Supervisor Agent analyzing query: 'Java OutOfMemoryError troubleshooting'\n",
      "   user_can_wait: False, production_incident: False\n",
      "✅ Supervisor decision: ContextualCompression - The query is a general troubleshooting question and the user cannot wait, so a fast semantic search is appropriate.\n",
      "   Analysis time: 2.57s\n",
      "   🎯 Decision: ContextualCompression (2.57s)\n",
      "   💭 Reasoning: The query is a general troubleshooting question and the user cannot wait, so a fast semantic search ...\n",
      "   ✅ Routing decision correct\n",
      "\n",
      "📊 ROUTING TEST SUMMARY:\n",
      "----------------------------------------\n",
      "✅ Correct routing decisions: 4/4\n",
      "⏱️  Average routing time: 1.70s\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Supervisor Routing Decisions\n",
    "print(\"\\n🧪 TEST 2: SUPERVISOR ROUTING DECISIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test scenarios for routing\n",
    "test_scenarios = [\n",
    "    {\n",
    "        'name': 'Production Incident',\n",
    "        'query': 'database connection timeout causing login failures',\n",
    "        'user_can_wait': False,\n",
    "        'production_incident': True,\n",
    "        'expected_reasoning': 'production incident',\n",
    "        'expected_agent': 'ContextualCompression'\n",
    "    },\n",
    "    {\n",
    "        'name': 'User Can Wait',\n",
    "        'query': 'authentication error patterns in recent tickets', \n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'expected_reasoning': 'comprehensive analysis',\n",
    "        'expected_agent': 'Ensemble'\n",
    "    },\n",
    "    {\n",
    "        'name': 'JIRA Ticket Reference',\n",
    "        'query': 'HBASE-12345 connection timeout issue details',\n",
    "        'user_can_wait': False,\n",
    "        'production_incident': False,\n",
    "        'expected_reasoning': 'specific ticket',\n",
    "        'expected_agent': 'BM25'\n",
    "    },\n",
    "    {\n",
    "        'name': 'General Query',\n",
    "        'query': 'Java OutOfMemoryError troubleshooting',\n",
    "        'user_can_wait': False,\n",
    "        'production_incident': False,\n",
    "        'expected_reasoning': 'default routing',\n",
    "        'expected_agent': 'ContextualCompression'\n",
    "    }\n",
    "]\n",
    "\n",
    "routing_results = []\n",
    "\n",
    "if workflow:\n",
    "    print(\"🔄 Testing supervisor routing decisions...\")\n",
    "    \n",
    "    for i, scenario in enumerate(test_scenarios, 1):\n",
    "        try:\n",
    "            print(f\"\\n📋 Scenario {i}: {scenario['name']}\")\n",
    "            print(f\"   Query: '{scenario['query'][:60]}...'\")\n",
    "            print(f\"   user_can_wait: {scenario['user_can_wait']}, production_incident: {scenario['production_incident']}\")\n",
    "            \n",
    "            # Test routing decision (this is async)\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # For async testing in Jupyter, we need to handle the event loop\n",
    "            try:\n",
    "                # Try to get existing loop\n",
    "                loop = asyncio.get_event_loop()\n",
    "                if loop.is_running():\n",
    "                    # Create task for running loop\n",
    "                    import nest_asyncio\n",
    "                    nest_asyncio.apply()\n",
    "                    result = await workflow.get_routing_decision(\n",
    "                        query=scenario['query'],\n",
    "                        user_can_wait=scenario['user_can_wait'],\n",
    "                        production_incident=scenario['production_incident']\n",
    "                    )\n",
    "                else:\n",
    "                    result = loop.run_until_complete(\n",
    "                        workflow.get_routing_decision(\n",
    "                            query=scenario['query'],\n",
    "                            user_can_wait=scenario['user_can_wait'],\n",
    "                            production_incident=scenario['production_incident']\n",
    "                        )\n",
    "                    )\n",
    "            except RuntimeError:\n",
    "                # No existing loop, create new one\n",
    "                result = asyncio.run(\n",
    "                    workflow.get_routing_decision(\n",
    "                        query=scenario['query'],\n",
    "                        user_can_wait=scenario['user_can_wait'],\n",
    "                        production_incident=scenario['production_incident']\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            routing_time = time.time() - start_time\n",
    "            \n",
    "            decision = result.get('routing_decision', 'Unknown')\n",
    "            reasoning = result.get('routing_reasoning', 'No reasoning provided')\n",
    "            \n",
    "            print(f\"   🎯 Decision: {decision} ({routing_time:.2f}s)\")\n",
    "            print(f\"   💭 Reasoning: {reasoning[:100]}...\")\n",
    "            \n",
    "            # Validate against expected results\n",
    "            decision_correct = decision == scenario['expected_agent']\n",
    "            reasoning_relevant = any(keyword in reasoning.lower() \n",
    "                                   for keyword in scenario['expected_reasoning'].split())\n",
    "            \n",
    "            result_entry = {\n",
    "                'scenario': scenario['name'],\n",
    "                'query': scenario['query'],\n",
    "                'expected_agent': scenario['expected_agent'],\n",
    "                'actual_agent': decision,\n",
    "                'decision_correct': decision_correct,\n",
    "                'reasoning_relevant': reasoning_relevant,\n",
    "                'routing_time': routing_time,\n",
    "                'full_reasoning': reasoning\n",
    "            }\n",
    "            \n",
    "            routing_results.append(result_entry)\n",
    "            \n",
    "            if decision_correct:\n",
    "                print(f\"   ✅ Routing decision correct\")\n",
    "            else:\n",
    "                print(f\"   ❌ Expected {scenario['expected_agent']}, got {decision}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Routing test failed: {str(e)}\")\n",
    "            routing_results.append({\n",
    "                'scenario': scenario['name'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # Summary of routing tests\n",
    "    print(f\"\\n📊 ROUTING TEST SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    correct_decisions = sum(1 for r in routing_results if r.get('decision_correct', False))\n",
    "    total_tests = len([r for r in routing_results if 'error' not in r])\n",
    "    \n",
    "    print(f\"✅ Correct routing decisions: {correct_decisions}/{total_tests}\")\n",
    "    \n",
    "    if total_tests > 0:\n",
    "        avg_routing_time = sum(r.get('routing_time', 0) for r in routing_results if 'routing_time' in r) / total_tests\n",
    "        print(f\"⏱️  Average routing time: {avg_routing_time:.2f}s\")\n",
    "    \n",
    "    # Show any errors\n",
    "    errors = [r for r in routing_results if 'error' in r]\n",
    "    if errors:\n",
    "        print(f\"❌ Failed tests: {len(errors)}\")\n",
    "        for error in errors:\n",
    "            print(f\"   - {error['scenario']}: {error['error']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Workflow not initialized - skipping routing tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Supabase Fallback Methods\n",
    "\n",
    "Test the Supabase-based fallback retrieval methods:\n",
    "- **BM25 Fallback** - keyword/text search\n",
    "- **Vector Fallback** - semantic similarity search  \n",
    "- **Hybrid Fallback** - combined vector + keyword search\n",
    "\n",
    "These fallbacks are used when Qdrant vectorstore is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:08,235 - RAGTools - INFO - ✅ RAG tools initialized successfully\n",
      "2025-08-18 19:03:08,236 - SupabaseRetriever_bugs - INFO - Direct keyword search for: 'authentication error...' in bugs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 TEST 3: SUPABASE FALLBACK METHODS\n",
      "============================================================\n",
      "🔄 Testing Supabase BM25 fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:09,286 - SupabaseRetriever_bugs - INFO - Direct keyword search returned 10 results\n",
      "2025-08-18 19:03:09,287 - RAGTools - INFO - Keyword search (bugs): 10 results for 'authentication error...'\n",
      "2025-08-18 19:03:09,287 - MultiAgentWorkflow - INFO - Supabase BM25 fallback: 10 results\n",
      "2025-08-18 19:03:09,288 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'authentication error...' in bugs\n",
      "2025-08-18 19:03:09,290 - SupabaseRetriever_bugs - INFO - Parameters: k=10, similarity_threshold=0.2, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ BM25 fallback completed in 1.07s\n",
      "   📄 Retrieved contexts: 10\n",
      "   🔍 Method: Supabase_BM25\n",
      "\n",
      "🔄 Testing Supabase Vector fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:10,200 - SupabaseRetriever_bugs - INFO - Processing 30 candidates for similarity calculation\n",
      "2025-08-18 19:03:10,214 - SupabaseRetriever_bugs - INFO - Calculated 30 similarities, 17 above threshold 0.2\n",
      "2025-08-18 19:03:10,214 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2479', '0.2604', '0.2196']\n",
      "2025-08-18 19:03:10,214 - SupabaseRetriever_bugs - INFO - Direct vector search returned 10 results (from 30 candidates)\n",
      "2025-08-18 19:03:10,214 - RAGTools - INFO - Vector search (bugs): 10 results for 'authentication error...'\n",
      "2025-08-18 19:03:10,215 - MultiAgentWorkflow - INFO - Supabase vector fallback: 10 results\n",
      "2025-08-18 19:03:10,215 - SupabaseRetriever_bugs - INFO - Direct hybrid search for: 'authentication error...' in bugs\n",
      "2025-08-18 19:03:10,215 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'authentication error...' in bugs\n",
      "2025-08-18 19:03:10,215 - SupabaseRetriever_bugs - INFO - Parameters: k=20, similarity_threshold=0.2, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Vector fallback completed in 0.93s\n",
      "   📄 Retrieved contexts: 10\n",
      "   🔍 Method: Supabase_Vector\n",
      "\n",
      "🔄 Testing Supabase Hybrid fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:12,130 - SupabaseRetriever_bugs - INFO - Processing 60 candidates for similarity calculation\n",
      "2025-08-18 19:03:12,153 - SupabaseRetriever_bugs - INFO - Calculated 60 similarities, 34 above threshold 0.2\n",
      "2025-08-18 19:03:12,154 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2478', '0.2604', '0.2196']\n",
      "2025-08-18 19:03:12,154 - SupabaseRetriever_bugs - INFO - Direct vector search returned 20 results (from 60 candidates)\n",
      "2025-08-18 19:03:12,155 - SupabaseRetriever_bugs - INFO - Direct keyword search for: 'authentication error...' in bugs\n",
      "2025-08-18 19:03:13,144 - SupabaseRetriever_bugs - INFO - Direct keyword search returned 20 results\n",
      "2025-08-18 19:03:13,145 - SupabaseRetriever_bugs - INFO - Direct hybrid search returned 10 results\n",
      "2025-08-18 19:03:13,145 - RAGTools - INFO - Hybrid search (bugs): 10 results for 'authentication error...'\n",
      "2025-08-18 19:03:13,146 - MultiAgentWorkflow - INFO - Supabase hybrid fallback: 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Hybrid fallback completed in 2.93s\n",
      "   📄 Retrieved contexts: 10\n",
      "   🔍 Method: Supabase_Hybrid\n",
      "\n",
      "📊 FALLBACK METHODS SUMMARY:\n",
      "----------------------------------------\n",
      "✅ BM25: 10 contexts in 1.07s\n",
      "✅ VECTOR: 10 contexts in 0.93s\n",
      "✅ HYBRID: 10 contexts in 2.93s\n",
      "\n",
      "🎉 3/3 fallback methods successfully retrieved contexts!\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Supabase Fallback Methods\n",
    "print(\"\\n🧪 TEST 3: SUPABASE FALLBACK METHODS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fallback_results = {}\n",
    "\n",
    "if workflow:\n",
    "    # Create test state for fallback methods\n",
    "    test_state = {\n",
    "        'query': 'authentication error',\n",
    "        'user_can_wait': False,\n",
    "        'production_incident': False,\n",
    "        'routing_decision': None,\n",
    "        'routing_reasoning': None,\n",
    "        'retrieved_contexts': [],\n",
    "        'retrieval_method': None,\n",
    "        'retrieval_metadata': {},\n",
    "        'final_answer': None,\n",
    "        'relevant_tickets': [],\n",
    "        'messages': []\n",
    "    }\n",
    "    \n",
    "    # Test BM25 fallback\n",
    "    print(\"🔄 Testing Supabase BM25 fallback...\")\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Since these are async methods, handle event loop\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            if loop.is_running():\n",
    "                import nest_asyncio\n",
    "                nest_asyncio.apply()\n",
    "                bm25_result = await workflow._supabase_bm25_fallback(test_state.copy())\n",
    "            else:\n",
    "                bm25_result = loop.run_until_complete(workflow._supabase_bm25_fallback(test_state.copy()))\n",
    "        except RuntimeError:\n",
    "            bm25_result = asyncio.run(workflow._supabase_bm25_fallback(test_state.copy()))\n",
    "        \n",
    "        bm25_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   ✅ BM25 fallback completed in {bm25_time:.2f}s\")\n",
    "        print(f\"   📄 Retrieved contexts: {len(bm25_result.get('retrieved_contexts', []))}\")\n",
    "        print(f\"   🔍 Method: {bm25_result.get('retrieval_method', 'Unknown')}\")\n",
    "        \n",
    "        fallback_results['bm25'] = {\n",
    "            'success': True,\n",
    "            'contexts': len(bm25_result.get('retrieved_contexts', [])),\n",
    "            'time': bm25_time,\n",
    "            'method': bm25_result.get('retrieval_method', 'Unknown'),\n",
    "            'metadata': bm25_result.get('retrieval_metadata', {})\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ BM25 fallback failed: {str(e)}\")\n",
    "        fallback_results['bm25'] = {'success': False, 'error': str(e)}\n",
    "    \n",
    "    # Test Vector fallback\n",
    "    print(\"\\n🔄 Testing Supabase Vector fallback...\")\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            if loop.is_running():\n",
    "                import nest_asyncio\n",
    "                nest_asyncio.apply()\n",
    "                vector_result = await workflow._supabase_vector_fallback(test_state.copy())\n",
    "            else:\n",
    "                vector_result = loop.run_until_complete(workflow._supabase_vector_fallback(test_state.copy()))\n",
    "        except RuntimeError:\n",
    "            vector_result = asyncio.run(workflow._supabase_vector_fallback(test_state.copy()))\n",
    "        \n",
    "        vector_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   ✅ Vector fallback completed in {vector_time:.2f}s\")\n",
    "        print(f\"   📄 Retrieved contexts: {len(vector_result.get('retrieved_contexts', []))}\")\n",
    "        print(f\"   🔍 Method: {vector_result.get('retrieval_method', 'Unknown')}\")\n",
    "        \n",
    "        fallback_results['vector'] = {\n",
    "            'success': True,\n",
    "            'contexts': len(vector_result.get('retrieved_contexts', [])),\n",
    "            'time': vector_time,\n",
    "            'method': vector_result.get('retrieval_method', 'Unknown'),\n",
    "            'metadata': vector_result.get('retrieval_metadata', {})\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Vector fallback failed: {str(e)}\")\n",
    "        fallback_results['vector'] = {'success': False, 'error': str(e)}\n",
    "    \n",
    "    # Test Hybrid fallback\n",
    "    print(\"\\n🔄 Testing Supabase Hybrid fallback...\")\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            if loop.is_running():\n",
    "                import nest_asyncio\n",
    "                nest_asyncio.apply()\n",
    "                hybrid_result = await workflow._supabase_hybrid_fallback(test_state.copy())\n",
    "            else:\n",
    "                hybrid_result = loop.run_until_complete(workflow._supabase_hybrid_fallback(test_state.copy()))\n",
    "        except RuntimeError:\n",
    "            hybrid_result = asyncio.run(workflow._supabase_hybrid_fallback(test_state.copy()))\n",
    "        \n",
    "        hybrid_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   ✅ Hybrid fallback completed in {hybrid_time:.2f}s\")\n",
    "        print(f\"   📄 Retrieved contexts: {len(hybrid_result.get('retrieved_contexts', []))}\")\n",
    "        print(f\"   🔍 Method: {hybrid_result.get('retrieval_method', 'Unknown')}\")\n",
    "        \n",
    "        fallback_results['hybrid'] = {\n",
    "            'success': True,\n",
    "            'contexts': len(hybrid_result.get('retrieved_contexts', [])),\n",
    "            'time': hybrid_time,\n",
    "            'method': hybrid_result.get('retrieval_method', 'Unknown'),\n",
    "            'metadata': hybrid_result.get('retrieval_metadata', {})\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Hybrid fallback failed: {str(e)}\")\n",
    "        fallback_results['hybrid'] = {'success': False, 'error': str(e)}\n",
    "    \n",
    "    # Fallback results summary\n",
    "    print(f\"\\n📊 FALLBACK METHODS SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for method, results in fallback_results.items():\n",
    "        if results.get('success'):\n",
    "            print(f\"✅ {method.upper()}: {results['contexts']} contexts in {results['time']:.2f}s\")\n",
    "        else:\n",
    "            print(f\"❌ {method.upper()}: Failed - {results.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    # Check if any method retrieved results\n",
    "    successful_methods = sum(1 for r in fallback_results.values() if r.get('success') and r.get('contexts', 0) > 0)\n",
    "    if successful_methods > 0:\n",
    "        print(f\"\\n🎉 {successful_methods}/3 fallback methods successfully retrieved contexts!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  No fallback methods retrieved contexts - check RAG tools setup\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Workflow not initialized - skipping fallback tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Complete Query Processing\n",
    "\n",
    "Test the end-to-end workflow processing with real queries:\n",
    "- Full supervisor → retrieval → response writer pipeline\n",
    "- Performance metrics and timing\n",
    "- Response format validation\n",
    "- Context quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:13,174 - MultiAgentWorkflow - INFO - Processing query: 'authentication error in login system...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 TEST 4: COMPLETE QUERY PROCESSING\n",
      "============================================================\n",
      "🔄 Testing complete query processing...\n",
      "\n",
      "📋 Query 1: 'authentication error in login system'\n",
      "   Parameters: user_can_wait=False, production_incident=False\n",
      "🧠 Supervisor Agent analyzing query: 'authentication error in login system'\n",
      "   user_can_wait: False, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:14,484 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'authentication error in login system...' in bugs\n",
      "2025-08-18 19:03:14,485 - SupabaseRetriever_bugs - INFO - Parameters: k=10, similarity_threshold=0.2, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: ContextualCompression - The query is a general troubleshooting question related to an authentication error, and the user cannot wait, making speed critical.\n",
      "   Analysis time: 1.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:15,256 - SupabaseRetriever_bugs - INFO - Processing 30 candidates for similarity calculation\n",
      "2025-08-18 19:03:15,270 - SupabaseRetriever_bugs - INFO - Calculated 30 similarities, 16 above threshold 0.2\n",
      "2025-08-18 19:03:15,270 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2022', '0.2315', '0.2099']\n",
      "2025-08-18 19:03:15,270 - SupabaseRetriever_bugs - INFO - Direct vector search returned 10 results (from 30 candidates)\n",
      "2025-08-18 19:03:15,271 - RAGTools - INFO - Vector search (bugs): 10 results for 'authentication error in login system...'\n",
      "2025-08-18 19:03:15,271 - MultiAgentWorkflow - INFO - Supabase vector fallback: 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✍️  ResponseWriter Agent  generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:19,886 - MultiAgentWorkflow - INFO - Query processed successfully in 6.71s\n",
      "2025-08-18 19:03:19,887 - MultiAgentWorkflow - INFO - Processing query: 'HBASE-12345 connection timeout troubleshooting...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 4.61s\n",
      "   Generated response: 870 characters\n",
      "   Relevant tickets: 10\n",
      "   ⏱️  Processing time: 6.71s\n",
      "   🎯 Routing: ContextualCompression\n",
      "   🔍 Retrieval: Supabase_Vector\n",
      "   📄 Contexts: 10\n",
      "   📝 Answer length: 870\n",
      "   ✅ Response structure: Valid\n",
      "   ✅ Content relevance: Good\n",
      "   ✅ Context retrieval: Success\n",
      "   💬 Answer preview: Based on your query regarding an \"authentication error in login system,\" it appears that none of the...\n",
      "\n",
      "📋 Query 2: 'HBASE-12345 connection timeout troubleshooting'\n",
      "   Parameters: user_can_wait=False, production_incident=False\n",
      "🧠 Supervisor Agent analyzing query: 'HBASE-12345 connection timeout troubleshooting'\n",
      "   user_can_wait: False, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:21,113 - SupabaseRetriever_bugs - INFO - Direct keyword search for: 'HBASE-12345 connection timeout troubleshooting...' in bugs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: BM25 - The query contains a specific ticket reference 'HBASE-12345', which is best handled by the BM25 agent for fast keyword-based search.\n",
      "   Analysis time: 1.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:21,806 - SupabaseRetriever_bugs - INFO - Direct keyword search returned 10 results\n",
      "2025-08-18 19:03:21,807 - RAGTools - INFO - Keyword search (bugs): 10 results for 'HBASE-12345 connection timeout troubleshooting...'\n",
      "2025-08-18 19:03:21,807 - MultiAgentWorkflow - INFO - Supabase BM25 fallback: 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✍️  ResponseWriter Agent  generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:27,582 - MultiAgentWorkflow - INFO - Query processed successfully in 7.70s\n",
      "2025-08-18 19:03:27,584 - MultiAgentWorkflow - INFO - Processing query: 'Java OutOfMemoryError heap space issues...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 5.77s\n",
      "   Generated response: 1522 characters\n",
      "   Relevant tickets: 10\n",
      "   ⏱️  Processing time: 7.70s\n",
      "   🎯 Routing: BM25\n",
      "   🔍 Retrieval: Supabase_BM25\n",
      "   📄 Contexts: 10\n",
      "   📝 Answer length: 1522\n",
      "   ✅ Response structure: Valid\n",
      "   ✅ Content relevance: Good\n",
      "   ✅ Context retrieval: Success\n",
      "   💬 Answer preview: Based on your query regarding \"HBASE-12345 connection timeout troubleshooting,\" it appears that none...\n",
      "\n",
      "📋 Query 3: 'Java OutOfMemoryError heap space issues'\n",
      "   Parameters: user_can_wait=True, production_incident=False\n",
      "🧠 Supervisor Agent analyzing query: 'Java OutOfMemoryError heap space issues'\n",
      "   user_can_wait: True, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:28,686 - SupabaseRetriever_bugs - INFO - Direct hybrid search for: 'Java OutOfMemoryError heap space issues...' in bugs\n",
      "2025-08-18 19:03:28,686 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'Java OutOfMemoryError heap space issues...' in bugs\n",
      "2025-08-18 19:03:28,687 - SupabaseRetriever_bugs - INFO - Parameters: k=20, similarity_threshold=0.2, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: Ensemble - The user can wait, and the query is complex, requiring thorough analysis of Java OutOfMemoryError heap space issues.\n",
      "   Analysis time: 1.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:29,792 - SupabaseRetriever_bugs - INFO - Processing 60 candidates for similarity calculation\n",
      "2025-08-18 19:03:29,815 - SupabaseRetriever_bugs - INFO - Calculated 60 similarities, 34 above threshold 0.2\n",
      "2025-08-18 19:03:29,816 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.4497', '0.2525', '0.2674']\n",
      "2025-08-18 19:03:29,816 - SupabaseRetriever_bugs - INFO - Direct vector search returned 20 results (from 60 candidates)\n",
      "2025-08-18 19:03:29,817 - SupabaseRetriever_bugs - INFO - Direct keyword search for: 'Java OutOfMemoryError heap space issues...' in bugs\n",
      "2025-08-18 19:03:30,598 - SupabaseRetriever_bugs - INFO - Direct keyword search returned 20 results\n",
      "2025-08-18 19:03:30,598 - SupabaseRetriever_bugs - INFO - Direct hybrid search returned 10 results\n",
      "2025-08-18 19:03:30,599 - RAGTools - INFO - Hybrid search (bugs): 10 results for 'Java OutOfMemoryError heap space issues...'\n",
      "2025-08-18 19:03:30,599 - MultiAgentWorkflow - INFO - Supabase hybrid fallback: 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✍️  ResponseWriter Agent  generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:37,724 - MultiAgentWorkflow - INFO - Query processed successfully in 10.14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 7.12s\n",
      "   Generated response: 1353 characters\n",
      "   Relevant tickets: 10\n",
      "   ⏱️  Processing time: 10.14s\n",
      "   🎯 Routing: Ensemble\n",
      "   🔍 Retrieval: Supabase_Hybrid\n",
      "   📄 Contexts: 10\n",
      "   📝 Answer length: 1353\n",
      "   ✅ Response structure: Valid\n",
      "   ✅ Content relevance: Good\n",
      "   ✅ Context retrieval: Success\n",
      "   💬 Answer preview: Based on your query regarding \"Java OutOfMemoryError heap space issues,\" the retrieved JIRA ticket [...\n",
      "\n",
      "📊 COMPLETE PROCESSING SUMMARY:\n",
      "--------------------------------------------------\n",
      "✅ Successful queries: 3/3\n",
      "❌ Failed queries: 0\n",
      "⏱️  Average processing time: 8.18s\n",
      "📄 Average contexts retrieved: 10.0\n",
      "📝 Average answer length: 1248 characters\n",
      "🏗️  Structure validation: 3/3\n",
      "🎯 Content relevance: 3/3\n",
      "📚 Context retrieval: 3/3\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Complete Query Processing \n",
    "print(\"\\n🧪 TEST 4: COMPLETE QUERY PROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test queries for end-to-end processing\n",
    "end_to_end_queries = [\n",
    "    {\n",
    "        'query': 'authentication error in login system',\n",
    "        'user_can_wait': False,\n",
    "        'production_incident': False,\n",
    "        'expected_elements': ['authentication', 'login', 'error']\n",
    "    },\n",
    "    {\n",
    "        'query': 'HBASE-12345 connection timeout troubleshooting',\n",
    "        'user_can_wait': False, \n",
    "        'production_incident': False,\n",
    "        'expected_elements': ['HBASE-12345', 'connection', 'timeout']\n",
    "    },\n",
    "    {\n",
    "        'query': 'Java OutOfMemoryError heap space issues',\n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'expected_elements': ['Java', 'OutOfMemoryError', 'heap']\n",
    "    }\n",
    "]\n",
    "\n",
    "processing_results = []\n",
    "\n",
    "if workflow:\n",
    "    print(\"🔄 Testing complete query processing...\")\n",
    "    \n",
    "    for i, test_case in enumerate(end_to_end_queries, 1):\n",
    "        try:\n",
    "            print(f\"\\n📋 Query {i}: '{test_case['query']}'\")\n",
    "            print(f\"   Parameters: user_can_wait={test_case['user_can_wait']}, production_incident={test_case['production_incident']}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Process query through complete workflow\n",
    "            try:\n",
    "                loop = asyncio.get_event_loop()\n",
    "                if loop.is_running():\n",
    "                    import nest_asyncio\n",
    "                    nest_asyncio.apply()\n",
    "                    result = await workflow.process_query(\n",
    "                        query=test_case['query'],\n",
    "                        user_can_wait=test_case['user_can_wait'],\n",
    "                        production_incident=test_case['production_incident']\n",
    "                    )\n",
    "                else:\n",
    "                    result = loop.run_until_complete(\n",
    "                        workflow.process_query(\n",
    "                            query=test_case['query'],\n",
    "                            user_can_wait=test_case['user_can_wait'],\n",
    "                            production_incident=test_case['production_incident']\n",
    "                        )\n",
    "                    )\n",
    "            except RuntimeError:\n",
    "                result = asyncio.run(\n",
    "                    workflow.process_query(\n",
    "                        query=test_case['query'],\n",
    "                        user_can_wait=test_case['user_can_wait'],\n",
    "                        production_incident=test_case['production_incident']\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Analyze results\n",
    "            print(f\"   ⏱️  Processing time: {processing_time:.2f}s\")\n",
    "            print(f\"   🎯 Routing: {result.get('routing_decision', 'Unknown')}\")\n",
    "            print(f\"   🔍 Retrieval: {result.get('retrieval_method', 'Unknown')}\")\n",
    "            print(f\"   📄 Contexts: {len(result.get('retrieved_contexts', []))}\")\n",
    "            print(f\"   📝 Answer length: {len(result.get('final_answer', ''))}\")\n",
    "            \n",
    "            # Validate response structure\n",
    "            required_fields = [\n",
    "                'query', 'final_answer', 'routing_decision', 'routing_reasoning',\n",
    "                'retrieval_method', 'retrieved_contexts', 'retrieval_metadata',\n",
    "                'timestamp', 'total_processing_time'\n",
    "            ]\n",
    "            \n",
    "            missing_fields = [field for field in required_fields if field not in result]\n",
    "            structure_valid = len(missing_fields) == 0\n",
    "            \n",
    "            # Check content quality\n",
    "            final_answer = result.get('final_answer', '')\n",
    "            content_relevant = any(element.lower() in final_answer.lower() \n",
    "                                 for element in test_case['expected_elements'])\n",
    "            \n",
    "            has_contexts = len(result.get('retrieved_contexts', [])) > 0\n",
    "            \n",
    "            # Store results\n",
    "            test_result = {\n",
    "                'query': test_case['query'],\n",
    "                'processing_time': processing_time,\n",
    "                'workflow_time': result.get('total_processing_time', 0),\n",
    "                'routing_decision': result.get('routing_decision'),\n",
    "                'retrieval_method': result.get('retrieval_method'),\n",
    "                'contexts_count': len(result.get('retrieved_contexts', [])),\n",
    "                'answer_length': len(final_answer),\n",
    "                'structure_valid': structure_valid,\n",
    "                'missing_fields': missing_fields,\n",
    "                'content_relevant': content_relevant,\n",
    "                'has_contexts': has_contexts,\n",
    "                'full_result': result\n",
    "            }\n",
    "            \n",
    "            processing_results.append(test_result)\n",
    "            \n",
    "            # Print validation results\n",
    "            if structure_valid:\n",
    "                print(f\"   ✅ Response structure: Valid\")\n",
    "            else:\n",
    "                print(f\"   ❌ Missing fields: {missing_fields}\")\n",
    "                \n",
    "            if content_relevant:\n",
    "                print(f\"   ✅ Content relevance: Good\")\n",
    "            else:\n",
    "                print(f\"   ⚠️  Content relevance: Could not verify\")\n",
    "                \n",
    "            if has_contexts:\n",
    "                print(f\"   ✅ Context retrieval: Success\")\n",
    "            else:\n",
    "                print(f\"   ❌ Context retrieval: No contexts found\")\n",
    "            \n",
    "            # Show first part of answer\n",
    "            print(f\"   💬 Answer preview: {final_answer[:100]}...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Query processing failed: {str(e)}\")\n",
    "            processing_results.append({\n",
    "                'query': test_case['query'],\n",
    "                'error': str(e),\n",
    "                'processing_time': time.time() - start_time\n",
    "            })\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # Overall processing summary\n",
    "    print(f\"\\n📊 COMPLETE PROCESSING SUMMARY:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    successful_queries = [r for r in processing_results if 'error' not in r]\n",
    "    failed_queries = [r for r in processing_results if 'error' in r]\n",
    "    \n",
    "    print(f\"✅ Successful queries: {len(successful_queries)}/{len(processing_results)}\")\n",
    "    print(f\"❌ Failed queries: {len(failed_queries)}\")\n",
    "    \n",
    "    if successful_queries:\n",
    "        avg_processing_time = sum(r['processing_time'] for r in successful_queries) / len(successful_queries)\n",
    "        avg_contexts = sum(r['contexts_count'] for r in successful_queries) / len(successful_queries)\n",
    "        avg_answer_length = sum(r['answer_length'] for r in successful_queries) / len(successful_queries)\n",
    "        \n",
    "        print(f\"⏱️  Average processing time: {avg_processing_time:.2f}s\")\n",
    "        print(f\"📄 Average contexts retrieved: {avg_contexts:.1f}\")\n",
    "        print(f\"📝 Average answer length: {avg_answer_length:.0f} characters\")\n",
    "        \n",
    "        structure_valid_count = sum(1 for r in successful_queries if r.get('structure_valid'))\n",
    "        content_relevant_count = sum(1 for r in successful_queries if r.get('content_relevant'))\n",
    "        contexts_found_count = sum(1 for r in successful_queries if r.get('has_contexts'))\n",
    "        \n",
    "        print(f\"🏗️  Structure validation: {structure_valid_count}/{len(successful_queries)}\")\n",
    "        print(f\"🎯 Content relevance: {content_relevant_count}/{len(successful_queries)}\")\n",
    "        print(f\"📚 Context retrieval: {contexts_found_count}/{len(successful_queries)}\")\n",
    "    \n",
    "    if failed_queries:\n",
    "        print(f\"\\n❌ FAILED QUERIES:\")\n",
    "        for failed in failed_queries:\n",
    "            print(f\"   - '{failed['query'][:50]}...': {failed['error']}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Workflow not initialized - skipping end-to-end tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Error Handling and Edge Cases\n",
    "\n",
    "Test the workflow's robustness with various error conditions:\n",
    "- Invalid queries and parameters\n",
    "- Missing environment variables\n",
    "- Network failures and timeouts\n",
    "- Empty retrieval results\n",
    "- Malformed responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:37,760 - MultiAgentWorkflow - INFO - Processing query: '...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 TEST 5: ERROR HANDLING AND EDGE CASES\n",
      "============================================================\n",
      "🔄 Testing error handling and edge cases...\n",
      "\n",
      "📋 Test 1: Empty Query\n",
      "   Query length: 0 characters\n",
      "   Expected: should handle gracefully\n",
      "🧠 Supervisor Agent analyzing query: ''\n",
      "   user_can_wait: False, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:39,133 - SupabaseRetriever_bugs - INFO - Direct vector search for: '...' in bugs\n",
      "2025-08-18 19:03:39,134 - SupabaseRetriever_bugs - INFO - Parameters: k=10, similarity_threshold=0.2, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: ContextualCompression - The query does not mention service status/outages or specific ticket references, and the user cannot wait, making ContextualCompression the best choice for fast semantic search.\n",
      "   Analysis time: 1.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:40,180 - SupabaseRetriever_bugs - INFO - Processing 30 candidates for similarity calculation\n",
      "2025-08-18 19:03:40,193 - SupabaseRetriever_bugs - INFO - Calculated 30 similarities, 0 above threshold 0.2\n",
      "2025-08-18 19:03:40,204 - SupabaseRetriever_bugs - WARNING - No results above threshold 0.2. Actual similarities range: 0.0701 to 0.1763\n",
      "2025-08-18 19:03:40,204 - SupabaseRetriever_bugs - INFO - Direct vector search returned 0 results (from 30 candidates)\n",
      "2025-08-18 19:03:40,205 - RAGTools - INFO - Vector search (bugs): 0 results for '...'\n",
      "2025-08-18 19:03:40,205 - MultiAgentWorkflow - INFO - Supabase vector fallback: 0 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✍️  ResponseWriter Agent  generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:44,676 - MultiAgentWorkflow - INFO - Query processed successfully in 6.92s\n",
      "2025-08-18 19:03:44,677 - MultiAgentWorkflow - INFO - Processing query: 'authentication error authentication error authenti...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 4.47s\n",
      "   Generated response: 1041 characters\n",
      "   Relevant tickets: 0\n",
      "   ✅ Processing completed in 6.92s\n",
      "   📝 Generated answer: 1041 characters\n",
      "   💬 Answer preview: Thank you for your query. Based on the information provided, it appears that no relevant JIRA ticket...\n",
      "\n",
      "📋 Test 2: Very Long Query\n",
      "   Query length: 2100 characters\n",
      "   Expected: should truncate or handle large input\n",
      "🧠 Supervisor Agent analyzing query: 'authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error authentication error '\n",
      "   user_can_wait: False, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:45,992 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'authentication error authentication error authenti...' in bugs\n",
      "2025-08-18 19:03:45,992 - SupabaseRetriever_bugs - INFO - Parameters: k=10, similarity_threshold=0.2, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: ContextualCompression - The query is a general troubleshooting question about an authentication error, and the user cannot wait, making speed critical.\n",
      "   Analysis time: 1.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:46,829 - SupabaseRetriever_bugs - INFO - Processing 30 candidates for similarity calculation\n",
      "2025-08-18 19:03:46,842 - SupabaseRetriever_bugs - INFO - Calculated 30 similarities, 1 above threshold 0.2\n",
      "2025-08-18 19:03:46,843 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2073']\n",
      "2025-08-18 19:03:46,843 - SupabaseRetriever_bugs - INFO - Direct vector search returned 1 results (from 30 candidates)\n",
      "2025-08-18 19:03:46,844 - RAGTools - INFO - Vector search (bugs): 1 results for 'authentication error authentication error authenti...'\n",
      "2025-08-18 19:03:46,844 - MultiAgentWorkflow - INFO - Supabase vector fallback: 1 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✍️  ResponseWriter Agent  generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:51,724 - MultiAgentWorkflow - INFO - Query processed successfully in 7.05s\n",
      "2025-08-18 19:03:51,726 - MultiAgentWorkflow - INFO - Processing query: 'SQL injection; DROP TABLE users; -- authentication...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 4.88s\n",
      "   Generated response: 1204 characters\n",
      "   Relevant tickets: 1\n",
      "   ✅ Processing completed in 7.05s\n",
      "   📝 Generated answer: 1204 characters\n",
      "   💬 Answer preview: It seems that your query is focused on an \"authentication error,\" but the retrieved JIRA ticket [JBI...\n",
      "\n",
      "📋 Test 3: Special Characters\n",
      "   Query length: 56 characters\n",
      "   Expected: should sanitize input\n",
      "🧠 Supervisor Agent analyzing query: 'SQL injection; DROP TABLE users; -- authentication error'\n",
      "   user_can_wait: False, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:53,160 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'SQL injection; DROP TABLE users; -- authentication...' in bugs\n",
      "2025-08-18 19:03:53,160 - SupabaseRetriever_bugs - INFO - Parameters: k=10, similarity_threshold=0.2, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: ContextualCompression - The query involves a general troubleshooting question related to SQL injection and authentication error, and the user cannot wait, making ContextualCompression the best choice for fast semantic search.\n",
      "   Analysis time: 1.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:53,963 - SupabaseRetriever_bugs - INFO - Processing 30 candidates for similarity calculation\n",
      "2025-08-18 19:03:53,975 - SupabaseRetriever_bugs - INFO - Calculated 30 similarities, 1 above threshold 0.2\n",
      "2025-08-18 19:03:53,976 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2529']\n",
      "2025-08-18 19:03:53,976 - SupabaseRetriever_bugs - INFO - Direct vector search returned 1 results (from 30 candidates)\n",
      "2025-08-18 19:03:53,976 - RAGTools - INFO - Vector search (bugs): 1 results for 'SQL injection; DROP TABLE users; -- authentication...'\n",
      "2025-08-18 19:03:53,977 - MultiAgentWorkflow - INFO - Supabase vector fallback: 1 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✍️  ResponseWriter Agent  generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:03:59,708 - MultiAgentWorkflow - INFO - Query processed successfully in 7.98s\n",
      "2025-08-18 19:03:59,712 - MultiAgentWorkflow - INFO - Processing query: '认证错误 🔒 authentication πρόβλημα...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 5.73s\n",
      "   Generated response: 1360 characters\n",
      "   Relevant tickets: 1\n",
      "   ✅ Processing completed in 7.99s\n",
      "   📝 Generated answer: 1360 characters\n",
      "   💬 Answer preview: Based on your query regarding \"SQL injection; DROP TABLE users; -- authentication error,\" it seems y...\n",
      "\n",
      "📋 Test 4: Unicode Characters\n",
      "   Query length: 30 characters\n",
      "   Expected: should handle unicode\n",
      "🧠 Supervisor Agent analyzing query: '认证错误 🔒 authentication πρόβλημα'\n",
      "   user_can_wait: False, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:04:01,157 - SupabaseRetriever_bugs - INFO - Direct vector search for: '认证错误 🔒 authentication πρόβλημα...' in bugs\n",
      "2025-08-18 19:04:01,159 - SupabaseRetriever_bugs - INFO - Parameters: k=10, similarity_threshold=0.2, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: ContextualCompression - The query involves an authentication problem, which is a general troubleshooting question and the user cannot wait.\n",
      "   Analysis time: 1.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:04:02,085 - SupabaseRetriever_bugs - INFO - Processing 30 candidates for similarity calculation\n",
      "2025-08-18 19:04:02,096 - SupabaseRetriever_bugs - INFO - Calculated 30 similarities, 3 above threshold 0.2\n",
      "2025-08-18 19:04:02,097 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2005', '0.2008', '0.2167']\n",
      "2025-08-18 19:04:02,097 - SupabaseRetriever_bugs - INFO - Direct vector search returned 3 results (from 30 candidates)\n",
      "2025-08-18 19:04:02,098 - RAGTools - INFO - Vector search (bugs): 3 results for '认证错误 🔒 authentication πρόβλημα...'\n",
      "2025-08-18 19:04:02,098 - MultiAgentWorkflow - INFO - Supabase vector fallback: 3 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✍️  ResponseWriter Agent  generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:04:07,092 - MultiAgentWorkflow - INFO - Query processed successfully in 7.38s\n",
      "2025-08-18 19:04:07,093 - MultiAgentWorkflow - WARNING - Using empty results fallback: Test_Empty_Fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 4.99s\n",
      "   Generated response: 949 characters\n",
      "   Relevant tickets: 3\n",
      "   ✅ Processing completed in 7.38s\n",
      "   📝 Generated answer: 949 characters\n",
      "   💬 Answer preview: It seems that your query \"认证错误 🔒 authentication πρόβλημα\" is related to authentication issues, possi...\n",
      "\n",
      "🔄 Testing empty results fallback...\n",
      "   ✅ Empty results fallback working\n",
      "   🔍 Method: Test_Empty_Fallback\n",
      "   📄 Contexts: 0\n",
      "\n",
      "📊 ERROR HANDLING SUMMARY:\n",
      "----------------------------------------\n",
      "✅ Handled gracefully: 5/5\n",
      "❌ Unhandled errors: 0\n",
      "⏱️  Average error handling time: 5.87s\n",
      "📝 Generated answers: 4/5\n",
      "\n",
      "🛡️  ROBUSTNESS ASSESSMENT:\n",
      "   🎉 Excellent: 100.0% of edge cases handled\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Error Handling and Edge Cases\n",
    "print(\"\\n🧪 TEST 5: ERROR HANDLING AND EDGE CASES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "error_test_cases = [\n",
    "    {\n",
    "        'name': 'Empty Query',\n",
    "        'query': '',\n",
    "        'user_can_wait': False,\n",
    "        'production_incident': False,\n",
    "        'expected_behavior': 'should handle gracefully'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Very Long Query',\n",
    "        'query': 'authentication error ' * 100,  # 2000+ characters\n",
    "        'user_can_wait': False,\n",
    "        'production_incident': False,\n",
    "        'expected_behavior': 'should truncate or handle large input'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Special Characters',\n",
    "        'query': 'SQL injection; DROP TABLE users; -- authentication error',\n",
    "        'user_can_wait': False,\n",
    "        'production_incident': False,\n",
    "        'expected_behavior': 'should sanitize input'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Unicode Characters',\n",
    "        'query': '认证错误 🔒 authentication πρόβλημα',\n",
    "        'user_can_wait': False,\n",
    "        'production_incident': False,\n",
    "        'expected_behavior': 'should handle unicode'\n",
    "    }\n",
    "]\n",
    "\n",
    "error_results = []\n",
    "\n",
    "if workflow:\n",
    "    print(\"🔄 Testing error handling and edge cases...\")\n",
    "    \n",
    "    for i, test_case in enumerate(error_test_cases, 1):\n",
    "        try:\n",
    "            print(f\"\\n📋 Test {i}: {test_case['name']}\")\n",
    "            print(f\"   Query length: {len(test_case['query'])} characters\")\n",
    "            print(f\"   Expected: {test_case['expected_behavior']}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Test with potentially problematic input\n",
    "            try:\n",
    "                loop = asyncio.get_event_loop()\n",
    "                if loop.is_running():\n",
    "                    import nest_asyncio\n",
    "                    nest_asyncio.apply()\n",
    "                    result = await workflow.process_query(\n",
    "                        query=test_case['query'],\n",
    "                        user_can_wait=test_case['user_can_wait'],\n",
    "                        production_incident=test_case['production_incident']\n",
    "                    )\n",
    "                else:\n",
    "                    result = loop.run_until_complete(\n",
    "                        workflow.process_query(\n",
    "                            query=test_case['query'],\n",
    "                            user_can_wait=test_case['user_can_wait'],\n",
    "                            production_incident=test_case['production_incident']\n",
    "                        )\n",
    "                    )\n",
    "            except RuntimeError:\n",
    "                result = asyncio.run(\n",
    "                    workflow.process_query(\n",
    "                        query=test_case['query'],\n",
    "                        user_can_wait=test_case['user_can_wait'],\n",
    "                        production_incident=test_case['production_incident']\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Check if workflow handled the edge case\n",
    "            has_result = result is not None\n",
    "            has_answer = bool(result.get('final_answer', '') if has_result else False)\n",
    "            answer_length = len(result.get('final_answer', '')) if has_result else 0\n",
    "            \n",
    "            print(f\"   ✅ Processing completed in {processing_time:.2f}s\")\n",
    "            print(f\"   📝 Generated answer: {answer_length} characters\")\n",
    "            if has_answer:\n",
    "                print(f\"   💬 Answer preview: {result['final_answer'][:100]}...\")\n",
    "            \n",
    "            error_results.append({\n",
    "                'test_case': test_case['name'],\n",
    "                'query_length': len(test_case['query']),\n",
    "                'success': True,\n",
    "                'processing_time': processing_time,\n",
    "                'has_answer': has_answer,\n",
    "                'answer_length': answer_length\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            processing_time = time.time() - start_time\n",
    "            print(f\"   ❌ Error occurred: {str(e)}\")\n",
    "            \n",
    "            # Check if error is expected/handled gracefully\n",
    "            error_handled_gracefully = any(keyword in str(e).lower() \n",
    "                                         for keyword in ['validation', 'invalid', 'empty'])\n",
    "            \n",
    "            error_results.append({\n",
    "                'test_case': test_case['name'],\n",
    "                'query_length': len(test_case['query']),\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'processing_time': processing_time,\n",
    "                'error_handled_gracefully': error_handled_gracefully\n",
    "            })\n",
    "    \n",
    "    # Test empty results fallback\n",
    "    print(f\"\\n🔄 Testing empty results fallback...\")\n",
    "    try:\n",
    "        # Create a state that would result in empty results\n",
    "        empty_state = {\n",
    "            'query': 'nonexistent_query_12345_abcdef',\n",
    "            'user_can_wait': False,\n",
    "            'production_incident': False,\n",
    "            'routing_decision': None,\n",
    "            'routing_reasoning': None,\n",
    "            'retrieved_contexts': [],\n",
    "            'retrieval_method': None,\n",
    "            'retrieval_metadata': {},\n",
    "            'final_answer': None,\n",
    "            'relevant_tickets': [],\n",
    "            'messages': []\n",
    "        }\n",
    "        \n",
    "        empty_result = workflow._empty_results_fallback(empty_state, 'Test_Empty_Fallback')\n",
    "        print(f\"   ✅ Empty results fallback working\")\n",
    "        print(f\"   🔍 Method: {empty_result.get('retrieval_method', 'Unknown')}\")\n",
    "        print(f\"   📄 Contexts: {len(empty_result.get('retrieved_contexts', []))}\")\n",
    "        \n",
    "        error_results.append({\n",
    "            'test_case': 'Empty Results Fallback',\n",
    "            'success': True,\n",
    "            'processing_time': 0.0,\n",
    "            'has_answer': False,\n",
    "            'contexts_count': len(empty_result.get('retrieved_contexts', []))\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Empty results fallback failed: {str(e)}\")\n",
    "        error_results.append({\n",
    "            'test_case': 'Empty Results Fallback',\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "    \n",
    "    # Error handling summary\n",
    "    print(f\"\\n📊 ERROR HANDLING SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    successful_tests = [r for r in error_results if r.get('success')]\n",
    "    failed_tests = [r for r in error_results if not r.get('success')]\n",
    "    \n",
    "    print(f\"✅ Handled gracefully: {len(successful_tests)}/{len(error_results)}\")\n",
    "    print(f\"❌ Unhandled errors: {len(failed_tests)}\")\n",
    "    \n",
    "    if successful_tests:\n",
    "        avg_time = sum(r.get('processing_time', 0) for r in successful_tests) / len(successful_tests)\n",
    "        print(f\"⏱️  Average error handling time: {avg_time:.2f}s\")\n",
    "        \n",
    "        with_answers = sum(1 for r in successful_tests if r.get('has_answer'))\n",
    "        print(f\"📝 Generated answers: {with_answers}/{len(successful_tests)}\")\n",
    "    \n",
    "    if failed_tests:\n",
    "        print(f\"\\n❌ UNHANDLED ERRORS:\")\n",
    "        for failed in failed_tests:\n",
    "            error_type = \"graceful\" if failed.get('error_handled_gracefully') else \"unexpected\"\n",
    "            print(f\"   - {failed['test_case']}: {error_type} - {failed.get('error', 'Unknown error')[:50]}...\")\n",
    "    \n",
    "    print(f\"\\n🛡️  ROBUSTNESS ASSESSMENT:\")\n",
    "    success_rate = len(successful_tests) / len(error_results) * 100\n",
    "    if success_rate >= 80:\n",
    "        print(f\"   🎉 Excellent: {success_rate:.1f}% of edge cases handled\")\n",
    "    elif success_rate >= 60:\n",
    "        print(f\"   ✅ Good: {success_rate:.1f}% of edge cases handled\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  Needs improvement: {success_rate:.1f}% of edge cases handled\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Workflow not initialized - skipping error handling tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6: WebSearch Routing Decisions\n",
    "\n",
    "Testing supervisor routing accuracy for WebSearch queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:04:22,798 - MultiAgentWorkflow - INFO - Getting routing decision for: 'Is GitHub down?...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 TESTING: WebSearch Routing Decisions\n",
      "==================================================\n",
      "\n",
      "🔍 Routing Test 1: 'Is GitHub down?'\n",
      "🧠 Supervisor Agent analyzing query: 'Is GitHub down?'\n",
      "   user_can_wait: False, production_incident: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:04:24,186 - MultiAgentWorkflow - INFO - Getting routing decision for: 'AWS Lambda outage...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: WebSearch - The query mentions a service status/outage ('Is GitHub down?'), which is best handled by WebSearch for real-time information.\n",
      "   Analysis time: 1.39s\n",
      "   Expected: WebSearch\n",
      "   Got: WebSearch\n",
      "   Reasoning: The query mentions a service status/outage ('Is GitHub down?'), which is best handled by WebSearch f...\n",
      "   ✅ Correct: True\n",
      "\n",
      "🔍 Routing Test 2: 'AWS Lambda outage'\n",
      "🧠 Supervisor Agent analyzing query: 'AWS Lambda outage'\n",
      "   user_can_wait: False, production_incident: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:04:25,384 - MultiAgentWorkflow - INFO - Getting routing decision for: 'Spring Boot security vulnerability...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: WebSearch - The query mentions an AWS outage, which is a service status check requiring real-time information.\n",
      "   Analysis time: 1.20s\n",
      "   Expected: WebSearch\n",
      "   Got: WebSearch\n",
      "   Reasoning: The query mentions an AWS outage, which is a service status check requiring real-time information....\n",
      "   ✅ Correct: True\n",
      "\n",
      "🔍 Routing Test 3: 'Spring Boot security vulnerability'\n",
      "🧠 Supervisor Agent analyzing query: 'Spring Boot security vulnerability'\n",
      "   user_can_wait: True, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:04:26,639 - MultiAgentWorkflow - INFO - Getting routing decision for: 'How to configure HBase cluster...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: Ensemble - The query is complex and user_can_wait=True, allowing for a comprehensive search to cover all aspects of the security vulnerability.\n",
      "   Analysis time: 1.25s\n",
      "   Expected: WebSearch\n",
      "   Got: Ensemble\n",
      "   Reasoning: The query is complex and user_can_wait=True, allowing for a comprehensive search to cover all aspect...\n",
      "   ✅ Correct: False\n",
      "\n",
      "🔍 Routing Test 4: 'How to configure HBase cluster'\n",
      "🧠 Supervisor Agent analyzing query: 'How to configure HBase cluster'\n",
      "   user_can_wait: True, production_incident: False\n",
      "✅ Supervisor decision: Ensemble - The query is a complex question about configuring an HBase cluster, and the user can wait for comprehensive results, making Ensemble the best choice for thorough analysis.\n",
      "   Analysis time: 1.54s\n",
      "   Expected: BM25\n",
      "   Got: Ensemble\n",
      "   Reasoning: The query is a complex question about configuring an HBase cluster, and the user can wait for compre...\n",
      "   ✅ Correct: False\n",
      "\n",
      "📊 ROUTING SUMMARY:\n",
      "   Correct routing decisions: 2/4\n",
      "   Routing Status: ❌ NEEDS IMPROVEMENT\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test WebSearch routing decisions\n",
    "from test_websearch_workflow import test_websearch_routing_only\n",
    "summary_data = test_websearch_routing_only(workflow, summary_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 7: WebSearch Workflow Integration\n",
    "\n",
    "Testing complete end-to-end WebSearch workflow integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:05:49,616 - MultiAgentWorkflow - INFO - Processing query: 'Is GitHub down right now?...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 TESTING: WebSearch Workflow Integration\n",
      "============================================================\n",
      "🧪 Running 4 WebSearch workflow integration tests...\n",
      "\n",
      "📋 Test 1: GitHub service status inquiry\n",
      "   Query: 'Is GitHub down right now?'\n",
      "   Expected routing: WebSearch\n",
      "🧠 Supervisor Agent analyzing query: 'Is GitHub down right now?'\n",
      "   user_can_wait: False, production_incident: True\n",
      "✅ Supervisor decision: WebSearch - The query mentions a service status check for GitHub, which is best handled by WebSearch for real-time information on outages or downtime.\n",
      "   Analysis time: 1.20s\n",
      "✍️  ResponseWriter Agent [PRODUCTION INCIDENT] generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:06:30,749 - MultiAgentWorkflow - INFO - Query processed successfully in 41.13s\n",
      "2025-08-18 19:06:30,750 - MultiAgentWorkflow - INFO - Processing query: 'AWS Lambda outage today...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 3.65s\n",
      "   Generated response: 527 characters\n",
      "   Relevant tickets: 0\n",
      "   📍 Actual routing: WebSearch\n",
      "   🔧 Retrieval method: WebSearch\n",
      "   📊 Retrieved contexts: 10\n",
      "   📝 Answer length: 527 chars\n",
      "   ⏱️  Processing time: 41.13s\n",
      "   ✅ Routing correct: True\n",
      "   🌐 WebSearch used: True\n",
      "   🔗 Web sources found: True (3 sources)\n",
      "   📊 Quality metrics: Contexts=True, Answer=True, Time=False\n",
      "   🎯 Overall: ✅ EXCELLENT\n",
      "\n",
      "📋 Test 2: AWS Lambda service outage check\n",
      "   Query: 'AWS Lambda outage today'\n",
      "   Expected routing: WebSearch\n",
      "🧠 Supervisor Agent analyzing query: 'AWS Lambda outage today'\n",
      "   user_can_wait: False, production_incident: True\n",
      "✅ Supervisor decision: WebSearch - The query mentions an AWS Lambda outage, which is a service status check and requires real-time information.\n",
      "   Analysis time: 1.23s\n",
      "✍️  ResponseWriter Agent [PRODUCTION INCIDENT] generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:07:11,550 - MultiAgentWorkflow - INFO - Query processed successfully in 40.80s\n",
      "2025-08-18 19:07:11,551 - MultiAgentWorkflow - INFO - Processing query: 'Docker Hub registry down...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 5.40s\n",
      "   Generated response: 800 characters\n",
      "   Relevant tickets: 0\n",
      "   📍 Actual routing: WebSearch\n",
      "   🔧 Retrieval method: WebSearch\n",
      "   📊 Retrieved contexts: 10\n",
      "   📝 Answer length: 800 chars\n",
      "   ⏱️  Processing time: 40.80s\n",
      "   ✅ Routing correct: True\n",
      "   🌐 WebSearch used: True\n",
      "   🔗 Web sources found: True (3 sources)\n",
      "   📊 Quality metrics: Contexts=True, Answer=True, Time=False\n",
      "   🎯 Overall: ✅ EXCELLENT\n",
      "\n",
      "📋 Test 3: Docker Hub registry status\n",
      "   Query: 'Docker Hub registry down'\n",
      "   Expected routing: WebSearch\n",
      "🧠 Supervisor Agent analyzing query: 'Docker Hub registry down'\n",
      "   user_can_wait: True, production_incident: False\n",
      "✅ Supervisor decision: WebSearch - The query mentions a service status/outage ('Docker Hub registry down'), which is best handled by WebSearch for real-time information.\n",
      "   Analysis time: 1.29s\n",
      "✍️  ResponseWriter Agent  generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:07:54,560 - MultiAgentWorkflow - INFO - Query processed successfully in 43.01s\n",
      "2025-08-18 19:07:54,562 - MultiAgentWorkflow - INFO - Processing query: 'Latest security vulnerability in Java Spring Boot...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 5.21s\n",
      "   Generated response: 970 characters\n",
      "   Relevant tickets: 0\n",
      "   📍 Actual routing: WebSearch\n",
      "   🔧 Retrieval method: WebSearch\n",
      "   📊 Retrieved contexts: 10\n",
      "   📝 Answer length: 970 chars\n",
      "   ⏱️  Processing time: 43.01s\n",
      "   ✅ Routing correct: True\n",
      "   🌐 WebSearch used: True\n",
      "   🔗 Web sources found: True (3 sources)\n",
      "   📊 Quality metrics: Contexts=True, Answer=True, Time=False\n",
      "   🎯 Overall: ✅ EXCELLENT\n",
      "\n",
      "📋 Test 4: Security research query\n",
      "   Query: 'Latest security vulnerability in Java Spring Boot'\n",
      "   Expected routing: WebSearch\n",
      "🧠 Supervisor Agent analyzing query: 'Latest security vulnerability in Java Spring Boot'\n",
      "   user_can_wait: True, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:07:56,195 - SupabaseRetriever_bugs - INFO - Direct hybrid search for: 'Latest security vulnerability in Java Spring Boot...' in bugs\n",
      "2025-08-18 19:07:56,195 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'Latest security vulnerability in Java Spring Boot...' in bugs\n",
      "2025-08-18 19:07:56,196 - SupabaseRetriever_bugs - INFO - Parameters: k=20, similarity_threshold=0.2, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor decision: Ensemble - The query is a research-type question about the latest security vulnerability in Java Spring Boot, and the user can wait for comprehensive results.\n",
      "   Analysis time: 1.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:07:57,301 - SupabaseRetriever_bugs - INFO - Processing 60 candidates for similarity calculation\n",
      "2025-08-18 19:07:57,317 - SupabaseRetriever_bugs - INFO - Calculated 60 similarities, 43 above threshold 0.2\n",
      "2025-08-18 19:07:57,318 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.3205', '0.2810', '0.2917']\n",
      "2025-08-18 19:07:57,318 - SupabaseRetriever_bugs - INFO - Direct vector search returned 20 results (from 60 candidates)\n",
      "2025-08-18 19:07:57,318 - SupabaseRetriever_bugs - INFO - Direct keyword search for: 'Latest security vulnerability in Java Spring Boot...' in bugs\n",
      "2025-08-18 19:07:58,546 - SupabaseRetriever_bugs - INFO - Direct keyword search returned 20 results\n",
      "2025-08-18 19:07:58,546 - SupabaseRetriever_bugs - INFO - Direct hybrid search returned 10 results\n",
      "2025-08-18 19:07:58,547 - RAGTools - INFO - Hybrid search (bugs): 10 results for 'Latest security vulnerability in Java Spring Boot...'\n",
      "2025-08-18 19:07:58,548 - MultiAgentWorkflow - INFO - Supabase hybrid fallback: 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✍️  ResponseWriter Agent  generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:08:03,574 - MultiAgentWorkflow - INFO - Query processed successfully in 9.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResponseWriter completed in 5.03s\n",
      "   Generated response: 777 characters\n",
      "   Relevant tickets: 10\n",
      "   📍 Actual routing: Ensemble\n",
      "   🔧 Retrieval method: Supabase_Hybrid\n",
      "   📊 Retrieved contexts: 10\n",
      "   📝 Answer length: 777 chars\n",
      "   ⏱️  Processing time: 9.01s\n",
      "   ✅ Routing correct: False\n",
      "   🌐 WebSearch used: False\n",
      "   🔗 Web sources found: False (0 sources)\n",
      "   📊 Quality metrics: Contexts=True, Answer=True, Time=True\n",
      "   🎯 Overall: ❌ POOR\n",
      "\n",
      "📊 WEBSEARCH WORKFLOW INTEGRATION SUMMARY:\n",
      "   Total tests: 4\n",
      "   Successful tests: 4/4\n",
      "   Correct routing: 3/4\n",
      "   WebSearch actually used: 3/4\n",
      "   Excellent results: 3/4\n",
      "   Average contexts per query: 10.0\n",
      "   Average processing time: 33.49s\n",
      "   Average answer length: 768 chars\n",
      "   Overall Integration Status: ✅ EXCELLENT\n",
      "\n",
      "📋 DETAILED RESULTS BY TEST TYPE:\n",
      "   status_check: 1/1 successful\n",
      "   outage_check: 1/1 successful\n",
      "   service_status: 1/1 successful\n",
      "   research: 1/1 successful\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test complete WebSearch workflow integration\n",
    "import asyncio\n",
    "from test_websearch_workflow import test_websearch_workflow_integration\n",
    "\n",
    "# Run async workflow integration tests\n",
    "summary_data = await test_websearch_workflow_integration(workflow, summary_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary and Test Report\n",
    "\n",
    "Generate a comprehensive test report with all results and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 COMPREHENSIVE TEST REPORT\n",
      "======================================================================\n",
      "📅 Generated: 2025-08-18 19:08:40\n",
      "======================================================================\n",
      "\n",
      "📊 OVERALL TEST STATISTICS:\n",
      "--------------------------------------------------\n",
      "🔧 Initialization: 5/5 components\n",
      "🎯 Routing Decisions: 4/4 correct\n",
      "🔄 Fallback Methods: 3/3 successful\n",
      "🚀 End-to-End Processing: 3/3 successful\n",
      "🛡️  Error Handling: 5/5 handled gracefully\n",
      "\n",
      "🎯 OVERALL SUCCESS RATE: 20/20 (100.0%)\n",
      "🏆 EXCELLENT - Workflow is production ready\n",
      "\n",
      "⏱️  PERFORMANCE METRICS:\n",
      "------------------------------\n",
      "🎯 Average routing time: 1.70s\n",
      "🚀 Average end-to-end time: 8.18s\n",
      "📄 Average contexts retrieved: 10.0\n",
      "🔄 Average fallback time: 1.64s\n",
      "\n",
      "🔍 KEY FINDINGS:\n",
      "-------------------------\n",
      "   ✅ All systems functioning within acceptable parameters\n",
      "   🎉 Workflow exceeds quality thresholds for production deployment\n",
      "\n",
      "💡 RECOMMENDATIONS:\n",
      "-------------------------\n",
      "   ✅ Workflow is ready for production deployment\n",
      "   📊 Monitor performance metrics in production environment\n",
      "   🔄 Run these tests regularly as part of CI/CD pipeline\n",
      "\n",
      "📝 TEST COMPLETION SUMMARY:\n",
      "   📅 Test session completed at: 2025-08-18 19:08:40\n",
      "   ⏱️  Total test execution time: ~10.0 seconds (estimated)\n",
      "   🏷️  Workflow version: MultiAgentWorkflow API Integration Testing\n",
      "   🎯 Recommended next step: Deploy to staging environment\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Test Report\n",
    "print(\"\\n📋 COMPREHENSIVE TEST REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"📅 Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Collect all results\n",
    "test_categories = {\n",
    "    'initialization': initialization_results if 'initialization_results' in locals() else {},\n",
    "    'routing': routing_results if 'routing_results' in locals() else [],\n",
    "    'fallbacks': fallback_results if 'fallback_results' in locals() else {},\n",
    "    'end_to_end': processing_results if 'processing_results' in locals() else [],\n",
    "    'error_handling': error_results if 'error_results' in locals() else []\n",
    "}\n",
    "\n",
    "# Overall Statistics\n",
    "total_tests = 0\n",
    "passed_tests = 0\n",
    "\n",
    "print(\"\\n📊 OVERALL TEST STATISTICS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Initialization results\n",
    "init_passed = sum(1 for k, v in test_categories['initialization'].items() if v and k != 'errors')\n",
    "init_total = len([k for k in test_categories['initialization'].keys() if k != 'errors'])\n",
    "if init_total > 0:\n",
    "    print(f\"🔧 Initialization: {init_passed}/{init_total} components\")\n",
    "    total_tests += init_total\n",
    "    passed_tests += init_passed\n",
    "\n",
    "# Routing results  \n",
    "routing_passed = sum(1 for r in test_categories['routing'] if r.get('decision_correct', False))\n",
    "routing_total = len([r for r in test_categories['routing'] if 'error' not in r])\n",
    "if routing_total > 0:\n",
    "    print(f\"🎯 Routing Decisions: {routing_passed}/{routing_total} correct\")\n",
    "    total_tests += routing_total\n",
    "    passed_tests += routing_passed\n",
    "\n",
    "# Fallback results\n",
    "fallback_passed = sum(1 for r in test_categories['fallbacks'].values() if r.get('success') and r.get('contexts', 0) > 0)\n",
    "fallback_total = len(test_categories['fallbacks'])\n",
    "if fallback_total > 0:\n",
    "    print(f\"🔄 Fallback Methods: {fallback_passed}/{fallback_total} successful\")\n",
    "    total_tests += fallback_total\n",
    "    passed_tests += fallback_passed\n",
    "\n",
    "# End-to-end results\n",
    "e2e_passed = len([r for r in test_categories['end_to_end'] if 'error' not in r])\n",
    "e2e_total = len(test_categories['end_to_end'])\n",
    "if e2e_total > 0:\n",
    "    print(f\"🚀 End-to-End Processing: {e2e_passed}/{e2e_total} successful\")\n",
    "    total_tests += e2e_total\n",
    "    passed_tests += e2e_passed\n",
    "\n",
    "# Error handling results\n",
    "error_passed = sum(1 for r in test_categories['error_handling'] if r.get('success'))\n",
    "error_total = len(test_categories['error_handling'])\n",
    "if error_total > 0:\n",
    "    print(f\"🛡️  Error Handling: {error_passed}/{error_total} handled gracefully\")\n",
    "    total_tests += error_total\n",
    "    passed_tests += error_passed\n",
    "\n",
    "# Overall score\n",
    "if total_tests > 0:\n",
    "    overall_score = (passed_tests / total_tests) * 100\n",
    "    print(f\"\\n🎯 OVERALL SUCCESS RATE: {passed_tests}/{total_tests} ({overall_score:.1f}%)\")\n",
    "    \n",
    "    if overall_score >= 90:\n",
    "        print(\"🏆 EXCELLENT - Workflow is production ready\")\n",
    "    elif overall_score >= 80:\n",
    "        print(\"✅ GOOD - Workflow is functional with minor issues\")\n",
    "    elif overall_score >= 70:\n",
    "        print(\"⚠️  ACCEPTABLE - Workflow needs some improvements\")\n",
    "    else:\n",
    "        print(\"❌ NEEDS WORK - Workflow requires significant fixes\")\n",
    "else:\n",
    "    print(\"❌ NO TESTS EXECUTED - Check test environment setup\")\n",
    "\n",
    "# Performance Metrics\n",
    "print(f\"\\n⏱️  PERFORMANCE METRICS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if test_categories['routing']:\n",
    "    avg_routing_time = sum(r.get('routing_time', 0) for r in test_categories['routing']) / len(test_categories['routing'])\n",
    "    print(f\"🎯 Average routing time: {avg_routing_time:.2f}s\")\n",
    "\n",
    "if test_categories['end_to_end']:\n",
    "    successful_e2e = [r for r in test_categories['end_to_end'] if 'error' not in r]\n",
    "    if successful_e2e:\n",
    "        avg_e2e_time = sum(r.get('processing_time', 0) for r in successful_e2e) / len(successful_e2e)\n",
    "        avg_contexts = sum(r.get('contexts_count', 0) for r in successful_e2e) / len(successful_e2e)\n",
    "        print(f\"🚀 Average end-to-end time: {avg_e2e_time:.2f}s\")\n",
    "        print(f\"📄 Average contexts retrieved: {avg_contexts:.1f}\")\n",
    "\n",
    "if test_categories['fallbacks']:\n",
    "    successful_fallbacks = [r for r in test_categories['fallbacks'].values() if r.get('success')]\n",
    "    if successful_fallbacks:\n",
    "        avg_fallback_time = sum(r.get('time', 0) for r in successful_fallbacks) / len(successful_fallbacks)\n",
    "        print(f\"🔄 Average fallback time: {avg_fallback_time:.2f}s\")\n",
    "\n",
    "# Key Findings and Recommendations\n",
    "print(f\"\\n🔍 KEY FINDINGS:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "findings = []\n",
    "\n",
    "# Check initialization issues\n",
    "if test_categories['initialization'].get('errors'):\n",
    "    findings.append(\"❌ Initialization errors detected - check environment variables\")\n",
    "\n",
    "# Check routing accuracy\n",
    "if test_categories['routing']:\n",
    "    routing_accuracy = (routing_passed / max(routing_total, 1)) * 100\n",
    "    if routing_accuracy < 80:\n",
    "        findings.append(f\"⚠️  Routing accuracy is {routing_accuracy:.1f}% - review supervisor logic\")\n",
    "\n",
    "# Check retrieval success\n",
    "if test_categories['fallbacks']:\n",
    "    retrieval_success = (fallback_passed / max(fallback_total, 1)) * 100\n",
    "    if retrieval_success < 70:\n",
    "        findings.append(f\"⚠️  Retrieval success is {retrieval_success:.1f}% - check Supabase connection\")\n",
    "\n",
    "# Check error handling\n",
    "if test_categories['error_handling']:\n",
    "    error_handling_rate = (error_passed / max(error_total, 1)) * 100\n",
    "    if error_handling_rate < 80:\n",
    "        findings.append(f\"⚠️  Error handling rate is {error_handling_rate:.1f}% - improve robustness\")\n",
    "\n",
    "# Positive findings\n",
    "if not findings:\n",
    "    findings.append(\"✅ All systems functioning within acceptable parameters\")\n",
    "\n",
    "if overall_score >= 90:\n",
    "    findings.append(\"🎉 Workflow exceeds quality thresholds for production deployment\")\n",
    "\n",
    "for finding in findings:\n",
    "    print(f\"   {finding}\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\n💡 RECOMMENDATIONS:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Performance recommendations\n",
    "if test_categories['end_to_end']:\n",
    "    successful_e2e = [r for r in test_categories['end_to_end'] if 'error' not in r]\n",
    "    if successful_e2e:\n",
    "        avg_e2e_time = sum(r.get('processing_time', 0) for r in successful_e2e) / len(successful_e2e)\n",
    "        if avg_e2e_time > 10:\n",
    "            recommendations.append(\"⚡ Consider caching or optimization for >10s processing times\")\n",
    "\n",
    "# Error handling recommendations\n",
    "if test_categories['error_handling']:\n",
    "    failed_errors = [r for r in test_categories['error_handling'] if not r.get('success')]\n",
    "    if failed_errors:\n",
    "        recommendations.append(\"🛡️  Add validation and sanitization for edge cases\")\n",
    "\n",
    "# Fallback recommendations\n",
    "if test_categories['fallbacks']:\n",
    "    failed_fallbacks = [k for k, r in test_categories['fallbacks'].items() if not r.get('success')]\n",
    "    if failed_fallbacks:\n",
    "        recommendations.append(f\"🔄 Fix fallback methods: {', '.join(failed_fallbacks)}\")\n",
    "\n",
    "# General recommendations\n",
    "if overall_score < 100:\n",
    "    recommendations.append(\"🔍 Address failing test cases before production deployment\")\n",
    "\n",
    "if not recommendations:\n",
    "    recommendations.append(\"✅ Workflow is ready for production deployment\")\n",
    "\n",
    "recommendations.append(\"📊 Monitor performance metrics in production environment\")\n",
    "recommendations.append(\"🔄 Run these tests regularly as part of CI/CD pipeline\")\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(f\"   {rec}\")\n",
    "\n",
    "print(f\"\\n📝 TEST COMPLETION SUMMARY:\")\n",
    "print(f\"   📅 Test session completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"   ⏱️  Total test execution time: ~{total_tests * 0.5:.1f} seconds (estimated)\")\n",
    "print(f\"   🏷️  Workflow version: MultiAgentWorkflow API Integration Testing\")\n",
    "print(f\"   🎯 Recommended next step: {'Deploy to staging environment' if overall_score >= 80 else 'Address failing tests'}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
