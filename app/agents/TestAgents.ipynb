{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ TestAgents.ipynb - LangGraph Multi-Agent System Testing\n",
    "\n",
    "**Purpose**: Comprehensive testing framework for Cuttlefish4's LangGraph multi-agent RAG system  \n",
    "**Status**: üß™ Testing and Validation Framework  \n",
    "**Created**: August 2025  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **Testing Scope**\n",
    "\n",
    "This notebook systematically tests all components of the LangGraph multi-agent system:\n",
    "\n",
    "### **üèóÔ∏è Core Components**\n",
    "1. **AgentState Class** - Shared state management across all agents\n",
    "2. **Common Utilities** - Content extraction, formatting, and helper functions\n",
    "\n",
    "### **ü§ñ Individual Agents**\n",
    "3. **BM25Agent** - Keyword-based search using BM25 algorithm\n",
    "4. **ContextualCompressionAgent** - Fast semantic retrieval with reranking\n",
    "5. **EnsembleAgent** - Multi-method comprehensive retrieval\n",
    "6. **ResponseWriterAgent** - Final response generation using GPT-4o\n",
    "7. **SupervisorAgent** - Intelligent query routing\n",
    "\n",
    "### **‚ö° LangGraph Workflow**\n",
    "8. **Agent Node Functions** - LangGraph integration wrappers\n",
    "9. **StateGraph Workflow** - Complete orchestration pipeline\n",
    "10. **End-to-End Testing** - Real query processing with full agent chain\n",
    "\n",
    "---\n",
    "\n",
    "## üìã **Prerequisites**\n",
    "\n",
    "**Environment Variables Required**:\n",
    "- `SUPABASE_URL`, `SUPABASE_KEY` - Database access\n",
    "- `OPENAI_API_KEY` - For LLM operations and embeddings\n",
    "- `COHERE_API_KEY` - Optional, for advanced reranking\n",
    "\n",
    "**Data Requirements**:\n",
    "- Populated Supabase tables: `bugs` and `pcr` with JIRA data\n",
    "- Vector embeddings and full-text search indices\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° **Quick Start**\n",
    "\n",
    "1. **Run Cell 0** - Install dependencies\n",
    "2. **Run Cell 2** - Environment setup and imports\n",
    "3. **Run Cells 4-6** - Initialize components (vectorstore, agents)\n",
    "4. **Run Cells 8-22** - Individual agent tests\n",
    "5. **Run Cells 24-30** - LangGraph workflow tests\n",
    "\n",
    "### üîç **Success Indicators**\n",
    "- ‚úÖ All agents initialize without errors\n",
    "- ‚úÖ Agent processing returns valid AgentState objects\n",
    "- ‚úÖ LangGraph workflow completes full execution\n",
    "- ‚úÖ Real query produces meaningful responses\n",
    "\n",
    "---\n",
    "\n",
    "*Execute cells in order for systematic testing of the entire multi-agent system.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy<2.0.0,>=1.4.0 in /Users/foohm/github/cuttlefish4/venv/lib/python3.13/site-packages (1.4.54)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Install dependencies\n",
    "!pip install \"sqlalchemy>=1.4.0,<2.0.0\"\n",
    "!pip install -q langgraph langsmith langchain-openai langchain-community langchain-cohere\n",
    "!pip install -q supabase python-dotenv pandas tqdm rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Path Configuration:\n",
      "   Project Root: /Users/foohm/github/cuttlefish4\n",
      "   App Directory: /Users/foohm/github/cuttlefish4/app\n",
      "   Agents Directory: /Users/foohm/github/cuttlefish4/app/agents\n",
      "   Current Directory: /Users/foohm/github/cuttlefish4/app/agents\n",
      "‚úÖ Loaded .env file from: /Users/foohm/github/cuttlefish4/.env\n",
      "‚ùå Missing environment variables: GOOGLE_PROJECT_ID\n",
      "Please set these in your .env file\n",
      "‚úÖ Environment setup complete\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Environment setup and path configuration\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Determine project root - we're in /app/agents/ and need to go up to project root\n",
    "current_path = Path.cwd()\n",
    "project_root = current_path.parent.parent  # Go up two levels: agents -> app -> cuttlefish4\n",
    "\n",
    "app_dir = project_root / \"app\"\n",
    "agents_dir = app_dir / \"agents\"  \n",
    "tools_dir = app_dir / \"tools\"\n",
    "rag_dir = app_dir / \"rag\"\n",
    "\n",
    "# Add to Python path\n",
    "for path in [str(project_root), str(app_dir), str(agents_dir), str(tools_dir), str(rag_dir)]:\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "print(\"üîß Path Configuration:\")\n",
    "print(f\"   Project Root: {project_root}\")\n",
    "print(f\"   App Directory: {app_dir}\")\n",
    "print(f\"   Agents Directory: {agents_dir}\")\n",
    "print(f\"   Current Directory: {current_path}\")\n",
    "\n",
    "# Load environment variables from project root\n",
    "from dotenv import load_dotenv\n",
    "env_file = project_root / \".env\"\n",
    "if env_file.exists():\n",
    "    load_dotenv(str(env_file))\n",
    "    print(f\"‚úÖ Loaded .env file from: {env_file}\")\n",
    "else:\n",
    "    load_dotenv()  # Try current directory\n",
    "    print(\"‚ö†Ô∏è  Loading .env from current directory (project root .env not found)\")\n",
    "\n",
    "# Verify environment variables\n",
    "required_vars = ['SUPABASE_URL', 'SUPABASE_KEY', 'OPENAI_API_KEY', 'GOOGLE_PROJECT_ID', 'GOOGLE_APPLICATION_CREDENTIALS', 'TAVILY_API_KEY']\n",
    "missing_vars = [var for var in required_vars if not os.environ.get(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"‚ùå Missing environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"Please set these in your .env file\")\n",
    "else:\n",
    "    print(\"‚úÖ All required environment variables found\")\n",
    "    \n",
    "print(f\"‚úÖ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All agent imports successful\n",
      "‚úÖ Supabase imports successful\n",
      "üöÄ All imports completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Core imports\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, TypedDict\n",
    "\n",
    "# LangGraph and LangChain imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "\n",
    "# Agent imports - using absolute imports for Jupyter notebook compatibility\n",
    "try:\n",
    "    # Try importing from the agents directory directly\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    # Make sure we can import from the current directory\n",
    "    agents_dir = os.path.dirname(os.path.abspath(''))\n",
    "    if agents_dir not in sys.path:\n",
    "        sys.path.insert(0, agents_dir)\n",
    "    \n",
    "    # Import agent modules directly\n",
    "    import common\n",
    "    import bm25_agent\n",
    "    import contextual_compression_agent\n",
    "    import ensemble_agent\n",
    "    import response_writer_agent\n",
    "    import supervisor_agent\n",
    "    \n",
    "    # Import specific classes and functions\n",
    "    from common import AgentState, measure_performance, extract_content_from_document, filter_empty_documents, format_context_for_llm, extract_ticket_info\n",
    "    from bm25_agent import BM25Agent\n",
    "    from contextual_compression_agent import ContextualCompressionAgent\n",
    "    from ensemble_agent import EnsembleAgent\n",
    "    from response_writer_agent import ResponseWriterAgent\n",
    "    from supervisor_agent import SupervisorAgent\n",
    "    \n",
    "    print(\"‚úÖ All agent imports successful\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Agent import error: {e}\")\n",
    "    print(\"Trying alternative import approach...\")\n",
    "    \n",
    "    try:\n",
    "        # Alternative approach - add agents directory to path and import\n",
    "        current_dir = os.getcwd()\n",
    "        sys.path.insert(0, current_dir)\n",
    "        \n",
    "        from common import AgentState, measure_performance, extract_content_from_document, filter_empty_documents, format_context_for_llm, extract_ticket_info\n",
    "        from bm25_agent import BM25Agent\n",
    "        from contextual_compression_agent import ContextualCompressionAgent\n",
    "        from ensemble_agent import EnsembleAgent\n",
    "        from response_writer_agent import ResponseWriterAgent\n",
    "        from supervisor_agent import SupervisorAgent\n",
    "        \n",
    "        print(\"‚úÖ All agent imports successful (alternative method)\")\n",
    "        \n",
    "    except ImportError as e2:\n",
    "        print(f\"‚ùå Alternative agent import also failed: {e2}\")\n",
    "        print(\"Please check that all agent files are present in the agents directory\")\n",
    "        print(\"Required files: common.py, bm25_agent.py, contextual_compression_agent.py,\")\n",
    "        print(\"               ensemble_agent.py, response_writer_agent.py, supervisor_agent.py\")\n",
    "\n",
    "# Supabase and vectorstore imports\n",
    "try:\n",
    "    from supabase import create_client, Client\n",
    "    print(\"‚úÖ Supabase imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Supabase import error: {e}\")\n",
    "\n",
    "print(\"üöÄ All imports completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ **Phase 1: Core Component Testing**\n",
    "\n",
    "Testing the foundational components that all agents depend on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing AgentState class and common utilities...\n",
      "‚úÖ AgentState creation successful\n",
      "   Test query: 'authentication error'\n",
      "   Initial state keys: ['query', 'user_can_wait', 'production_incident', 'routing_decision', 'routing_reasoning', 'retrieved_contexts', 'retrieval_method', 'retrieval_metadata', 'final_answer', 'relevant_tickets', 'messages']\n",
      "‚úÖ measure_performance working: 0.103s\n",
      "‚úÖ extract_content_from_document working correctly\n",
      "   Extracted: Title: Authentication Issue\n",
      "Description: User cann...\n",
      "‚úÖ filter_empty_documents: 1/2 valid docs\n",
      "‚úÖ format_context_for_llm working: 80 chars\n",
      "‚úÖ extract_ticket_info: found 1 tickets\n",
      "   First ticket: {'key': 'HBASE-123', 'title': 'Authentication Issue'}\n",
      "üéØ Core component testing completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Test AgentState class and common utilities\n",
    "print(\"üß™ Testing AgentState class and common utilities...\")\n",
    "\n",
    "# Test AgentState creation\n",
    "try:\n",
    "    test_state: AgentState = {\n",
    "        'query': 'authentication error',\n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'routing_decision': None,\n",
    "        'routing_reasoning': None,\n",
    "        'retrieved_contexts': [],\n",
    "        'retrieval_method': None,\n",
    "        'retrieval_metadata': {},\n",
    "        'final_answer': None,\n",
    "        'relevant_tickets': [],\n",
    "        'messages': []\n",
    "    }\n",
    "    print(\"‚úÖ AgentState creation successful\")\n",
    "    print(f\"   Test query: '{test_state['query']}'\")\n",
    "    print(f\"   Initial state keys: {list(test_state.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå AgentState creation failed: {e}\")\n",
    "\n",
    "# Test measure_performance\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    import time\n",
    "    time.sleep(0.1)  # Small delay\n",
    "    performance = measure_performance(start_time)\n",
    "    print(f\"‚úÖ measure_performance working: {performance:.3f}s\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå measure_performance failed: {e}\")\n",
    "\n",
    "# Test document utilities with mock data\n",
    "try:\n",
    "    # Create test document\n",
    "    test_doc = Document(\n",
    "        page_content=\"Original content\",\n",
    "        metadata={\n",
    "            'title': 'Authentication Issue',\n",
    "            'description': 'User cannot login to system',\n",
    "            'key': 'HBASE-123',\n",
    "            'id': 1\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Test content extraction\n",
    "    extracted_content = extract_content_from_document(test_doc)\n",
    "    expected_format = \"Title: Authentication Issue\\nDescription: User cannot login to system\"\n",
    "    \n",
    "    if extracted_content == expected_format:\n",
    "        print(\"‚úÖ extract_content_from_document working correctly\")\n",
    "        print(f\"   Extracted: {extracted_content[:50]}...\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  extract_content_from_document output unexpected:\")\n",
    "        print(f\"   Got: {extracted_content}\")\n",
    "        print(f\"   Expected: {expected_format}\")\n",
    "    \n",
    "    # Test document filtering\n",
    "    test_docs = [test_doc, Document(page_content=\"\", metadata={})]  # Empty doc\n",
    "    filtered_docs = filter_empty_documents(test_docs)\n",
    "    print(f\"‚úÖ filter_empty_documents: {len(filtered_docs)}/{len(test_docs)} valid docs\")\n",
    "    \n",
    "    # Test context formatting\n",
    "    test_contexts = [{\n",
    "        'content': extracted_content,\n",
    "        'metadata': test_doc.metadata,\n",
    "        'score': 0.8\n",
    "    }]\n",
    "    \n",
    "    formatted_context = format_context_for_llm(test_contexts)\n",
    "    print(f\"‚úÖ format_context_for_llm working: {len(formatted_context)} chars\")\n",
    "    \n",
    "    # Test ticket extraction\n",
    "    tickets = extract_ticket_info(test_contexts)\n",
    "    print(f\"‚úÖ extract_ticket_info: found {len(tickets)} tickets\")\n",
    "    if tickets:\n",
    "        print(f\"   First ticket: {tickets[0]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Document utilities test failed: {e}\")\n",
    "\n",
    "print(\"üéØ Core component testing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è **Phase 2: Initialize Components**\n",
    "\n",
    "Setting up the vectorstore and LLM components needed by the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing LLM components...\n",
      "‚úÖ LLMs initialized:\n",
      "   ‚Ä¢ RAG LLM: GPT-3.5-turbo\n",
      "   ‚Ä¢ Supervisor LLM: GPT-4o\n",
      "   ‚Ä¢ Response Writer LLM: GPT-4o\n",
      "‚úÖ LLM connectivity test successful: 34 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Initialize LLM components\n",
    "print(\"ü§ñ Initializing LLM components...\")\n",
    "\n",
    "try:\n",
    "    # Initialize LLMs\n",
    "    rag_llm = ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.1,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    supervisor_llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.1,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    response_writer_llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ LLMs initialized:\")\n",
    "    print(\"   ‚Ä¢ RAG LLM: GPT-3.5-turbo\")\n",
    "    print(\"   ‚Ä¢ Supervisor LLM: GPT-4o\")\n",
    "    print(\"   ‚Ä¢ Response Writer LLM: GPT-4o\")\n",
    "    \n",
    "    # Test LLM connectivity\n",
    "    test_response = rag_llm.invoke(\"Hello, this is a test message.\")\n",
    "    print(f\"‚úÖ LLM connectivity test successful: {len(test_response.content)} chars\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM initialization failed: {e}\")\n",
    "    print(\"Please check your OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÑÔ∏è Initializing Supabase and vectorstore...\n",
      "‚úÖ Supabase client initialized\n",
      "‚úÖ OpenAI embeddings initialized\n",
      "‚úÖ SupabaseRetriever initialized (bugs collection)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:38,433 - SupabaseRetriever_bugs - INFO - ‚úÖ Connection to bugs table successful\n",
      "2025-08-19 20:40:38,434 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'authentication error...' in bugs\n",
      "2025-08-19 20:40:38,435 - SupabaseRetriever_bugs - INFO - Parameters: k=1, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connection test: PASSED\n",
      "‚úÖ LangChain BaseRetriever wrapper created successfully\n",
      "‚úÖ Vectorstore wrapper with LangChain compatibility created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:39,034 - SupabaseRetriever_bugs - INFO - Processing 3 candidates for similarity calculation\n",
      "2025-08-19 20:40:39,037 - SupabaseRetriever_bugs - INFO - Calculated 3 similarities, 3 above threshold 0.1\n",
      "2025-08-19 20:40:39,037 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2478', '0.2604', '0.1882']\n",
      "2025-08-19 20:40:39,038 - SupabaseRetriever_bugs - INFO - Direct vector search returned 1 results (from 3 candidates)\n",
      "2025-08-19 20:40:39,041 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'authentication error...' in bugs\n",
      "2025-08-19 20:40:39,042 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Similarity search test: 1 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:39,720 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:39,726 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:39,727 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2478', '0.2604', '0.1882']\n",
      "2025-08-19 20:40:39,727 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangChain retriever test: 4 documents\n",
      "   Document type: <class 'langchain_core.documents.base.Document'>\n",
      "   Content preview: Title: context:include-filter can't find ControllerAdvice annotation\n",
      "\n",
      "Description: {code:xml}<contex...\n",
      "\n",
      "‚úÖ Final verification: Vectorstore is ready for agent testing\n",
      "   Type: <class '__main__.SimpleVectorStoreWrapper'>\n",
      "   LangChain retriever available: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Initialize Supabase and vectorstore\n",
    "print(\"üóÑÔ∏è Initializing Supabase and vectorstore...\")\n",
    "\n",
    "try:\n",
    "    # Initialize Supabase client\n",
    "    supabase_url = os.environ.get('SUPABASE_URL')\n",
    "    supabase_key = os.environ.get('SUPABASE_KEY')\n",
    "    \n",
    "    supabase_client: Client = create_client(supabase_url, supabase_key)\n",
    "    print(\"‚úÖ Supabase client initialized\")\n",
    "    \n",
    "    # Initialize embeddings\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        dimensions=1536\n",
    "    )\n",
    "    print(\"‚úÖ OpenAI embeddings initialized\")\n",
    "    \n",
    "    # Use the same pattern as TestRAGTools.ipynb - import and use SupabaseRetriever directly\n",
    "    try:\n",
    "        # Import your custom Supabase retriever\n",
    "        sys.path.insert(0, str(rag_dir))  # Make sure rag directory is in path\n",
    "        from supabase_retriever import create_bugs_retriever\n",
    "        \n",
    "        # Create custom retriever (this works with your RPC functions)\n",
    "        supabase_retriever = create_bugs_retriever()\n",
    "        print(\"‚úÖ SupabaseRetriever initialized (bugs collection)\")\n",
    "        \n",
    "        # Test the custom retriever connectivity\n",
    "        connection_test = supabase_retriever.test_connection()\n",
    "        print(f\"‚úÖ Connection test: {'PASSED' if connection_test else 'FAILED'}\")\n",
    "        \n",
    "        # Import required LangChain classes for proper inheritance\n",
    "        from langchain_core.retrievers import BaseRetriever\n",
    "        from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "        from langchain_core.documents import Document\n",
    "        from typing import List, Any\n",
    "        from pydantic import Field\n",
    "        \n",
    "        # Proper LangChain-compatible retriever with Pydantic field validation\n",
    "        class SupabaseRetrieverWrapper(BaseRetriever):\n",
    "            \"\"\"LangChain-compatible wrapper for SupabaseRetriever that inherits from BaseRetriever.\"\"\"\n",
    "            \n",
    "            # Properly define the field for Pydantic v2\n",
    "            supabase_retriever: Any = Field(description=\"The SupabaseRetriever instance\")\n",
    "            \n",
    "            def __init__(self, supabase_retriever, **kwargs):\n",
    "                super().__init__(supabase_retriever=supabase_retriever, **kwargs)\n",
    "                \n",
    "            def _get_relevant_documents(\n",
    "                self, \n",
    "                query: str, \n",
    "                *, \n",
    "                run_manager: CallbackManagerForRetrieverRun = None\n",
    "            ) -> List[Document]:\n",
    "                \"\"\"Required method for BaseRetriever - this makes it a proper Runnable.\"\"\"\n",
    "                try:\n",
    "                    # Use vector search from our SupabaseRetriever\n",
    "                    results = self.supabase_retriever.vector_search(query, k=4)\n",
    "                    documents = []\n",
    "                    for result in results:\n",
    "                        doc = Document(\n",
    "                            page_content=result.get('content', ''),\n",
    "                            metadata=result.get('metadata', {})\n",
    "                        )\n",
    "                        documents.append(doc)\n",
    "                    return documents\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è  Vector search failed in retriever wrapper: {e}\")\n",
    "                    # Try fallback using the fallback vector search\n",
    "                    try:\n",
    "                        fallback_results = self.supabase_retriever._fallback_vector_search(\n",
    "                            query_embedding=[0.0] * 1536,  # Dummy embedding\n",
    "                            k=4, \n",
    "                            filters=None\n",
    "                        )\n",
    "                        documents = []\n",
    "                        for result in fallback_results:\n",
    "                            doc = Document(\n",
    "                                page_content=result.get('content', ''),\n",
    "                                metadata=result.get('metadata', {})\n",
    "                            )\n",
    "                            documents.append(doc)\n",
    "                        return documents\n",
    "                    except Exception as fallback_error:\n",
    "                        print(f\"‚ö†Ô∏è  Fallback also failed: {fallback_error}\")\n",
    "                        # Return empty list rather than failing\n",
    "                        return []\n",
    "        \n",
    "        # Simple wrapper class that implements the interfaces agents need\n",
    "        class SimpleVectorStoreWrapper:\n",
    "            \"\"\"Simple wrapper that provides both vectorstore and retriever interfaces.\"\"\"\n",
    "            \n",
    "            def __init__(self, retriever):\n",
    "                self.retriever = retriever\n",
    "                # Create the LangChain-compatible retriever\n",
    "                try:\n",
    "                    self._langchain_retriever = SupabaseRetrieverWrapper(retriever)\n",
    "                    print(\"‚úÖ LangChain BaseRetriever wrapper created successfully\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è  LangChain wrapper creation failed: {e}\")\n",
    "                    # Fallback to a simple retriever for basic functionality\n",
    "                    self._langchain_retriever = None\n",
    "                \n",
    "            def similarity_search(self, query, k=4):\n",
    "                \"\"\"Vectorstore-style interface for similarity search.\"\"\"\n",
    "                try:\n",
    "                    results = self.retriever.vector_search(query, k=k)\n",
    "                    documents = []\n",
    "                    for result in results:\n",
    "                        doc = Document(\n",
    "                            page_content=result.get('content', ''),\n",
    "                            metadata=result.get('metadata', {})\n",
    "                        )\n",
    "                        documents.append(doc)\n",
    "                    return documents\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è  Similarity search failed: {e}\")\n",
    "                    # Return empty list for graceful degradation\n",
    "                    return []\n",
    "            \n",
    "            def as_retriever(self, **kwargs):\n",
    "                \"\"\"Return the proper LangChain BaseRetriever if available, else None.\"\"\"\n",
    "                if self._langchain_retriever is not None:\n",
    "                    return self._langchain_retriever\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è  LangChain retriever not available, returning None\")\n",
    "                    return None\n",
    "                \n",
    "            def get_relevant_documents(self, query, k=4):\n",
    "                \"\"\"Direct retriever-style interface.\"\"\"\n",
    "                return self.similarity_search(query, k=k)\n",
    "        \n",
    "        # Create simple wrapper\n",
    "        vectorstore = SimpleVectorStoreWrapper(supabase_retriever)\n",
    "        print(\"‚úÖ Vectorstore wrapper with LangChain compatibility created\")\n",
    "        \n",
    "        # Test the wrapper with a simple query\n",
    "        try:\n",
    "            test_docs = vectorstore.similarity_search(\"authentication error\", k=1)\n",
    "            print(f\"‚úÖ Similarity search test: {len(test_docs)} documents\")\n",
    "            \n",
    "            # Test the LangChain retriever interface if available\n",
    "            retriever = vectorstore.as_retriever()\n",
    "            if retriever:\n",
    "                try:\n",
    "                    test_retriever_docs = retriever.invoke(\"authentication error\")\n",
    "                    print(f\"‚úÖ LangChain retriever test: {len(test_retriever_docs)} documents\")\n",
    "                except Exception as retriever_error:\n",
    "                    print(f\"‚ö†Ô∏è  LangChain retriever test failed: {retriever_error}\")\n",
    "                    print(\"   Continuing with basic vectorstore functionality\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  LangChain retriever not available - agents will use basic functionality\")\n",
    "            \n",
    "            if test_docs:\n",
    "                sample_doc = test_docs[0]\n",
    "                print(f\"   Document type: {type(sample_doc)}\")\n",
    "                content_preview = sample_doc.page_content[:100] if hasattr(sample_doc, 'page_content') else str(sample_doc)[:100]\n",
    "                print(f\"   Content preview: {content_preview}...\")\n",
    "                \n",
    "        except Exception as wrapper_test_error:\n",
    "            print(f\"‚ö†Ô∏è  Wrapper test warning: {wrapper_test_error}\")\n",
    "            print(\"   Basic vectorstore should still work for agent testing\")\n",
    "        \n",
    "    except ImportError as import_error:\n",
    "        print(f\"‚ùå Could not import SupabaseRetriever: {import_error}\")\n",
    "        print(\"   Please check that supabase_retriever.py exists in the rag directory\")\n",
    "        vectorstore = None\n",
    "        \n",
    "    except Exception as custom_error:\n",
    "        print(f\"‚ö†Ô∏è  SupabaseRetriever setup completed with warnings: {custom_error}\")\n",
    "        print(\"   Vectorstore should still be functional for testing\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Supabase initialization failed: {e}\")\n",
    "    print(\"Please check your SUPABASE_URL and SUPABASE_KEY\")\n",
    "    vectorstore = None\n",
    "\n",
    "# Final verification\n",
    "if 'vectorstore' in locals() and vectorstore is not None:\n",
    "    print(f\"\\n‚úÖ Final verification: Vectorstore is ready for agent testing\")\n",
    "    print(f\"   Type: {type(vectorstore)}\")\n",
    "    print(f\"   LangChain retriever available: {vectorstore.as_retriever() is not None}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Final verification: Vectorstore initialization failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ **Phase 3: Individual Agent Testing**\n",
    "\n",
    "Testing each agent individually to ensure proper functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:39,736 - BM25Agent - INFO - Setting up BM25 retriever...\n",
      "2025-08-19 20:40:39,737 - BM25Agent - INFO - Fetching sample documents from vectorstore...\n",
      "2025-08-19 20:40:39,737 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'sample query...' in bugs\n",
      "2025-08-19 20:40:39,737 - SupabaseRetriever_bugs - INFO - Parameters: k=100, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing BM25Agent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:40,769 - SupabaseRetriever_bugs - INFO - Processing 100 candidates for similarity calculation\n",
      "2025-08-19 20:40:40,799 - SupabaseRetriever_bugs - INFO - Calculated 100 similarities, 94 above threshold 0.1\n",
      "2025-08-19 20:40:40,799 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1286', '0.1846', '0.1465']\n",
      "2025-08-19 20:40:40,799 - SupabaseRetriever_bugs - INFO - Direct vector search returned 94 results (from 100 candidates)\n",
      "2025-08-19 20:40:40,800 - BM25Agent - INFO - Retrieved 94 documents from vectorstore\n",
      "2025-08-19 20:40:40,801 - BM25Agent - INFO - Document validation passed: 94/94 valid docs, avg length: 1034.9 chars\n",
      "2025-08-19 20:40:40,801 - BM25Agent - INFO - Creating BM25 retriever with 94 valid documents...\n",
      "2025-08-19 20:40:40,808 - BM25Agent - INFO - ‚úÖ BM25 retriever successfully initialized with 94 documents\n",
      "2025-08-19 20:40:40,808 - BM25Agent - INFO - Using BM25 retriever for query: 'authentication error...'\n",
      "/Users/foohm/github/cuttlefish4/app/agents/bm25_agent.py:164: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  docs = self.bm25_retriever.get_relevant_documents(query)\n",
      "2025-08-19 20:40:40,864 - BM25Agent - INFO - BM25 retriever returned 5 documents\n",
      "2025-08-19 20:40:40,864 - BM25Agent - INFO - Filtered 5 -> 5 valid documents\n",
      "2025-08-19 20:40:40,864 - BM25Agent - INFO - BM25 retrieve returning 5 results with valid content\n",
      "2025-08-19 20:40:40,865 - BM25Agent - INFO - BM25 Agent processing query: 'authentication error'\n",
      "2025-08-19 20:40:40,865 - BM25Agent - INFO - Using BM25 retriever for query: 'authentication error...'\n",
      "2025-08-19 20:40:40,865 - BM25Agent - INFO - BM25 retriever returned 5 documents\n",
      "2025-08-19 20:40:40,866 - BM25Agent - INFO - Filtered 5 -> 5 valid documents\n",
      "2025-08-19 20:40:40,866 - BM25Agent - INFO - BM25 retrieve returning 5 results with valid content\n",
      "2025-08-19 20:40:40,866 - BM25Agent - INFO - BM25 Agent completed in 0.00s with 5 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BM25 retriever initialized with 94 documents\n",
      "‚úÖ BM25Agent initialized\n",
      "\n",
      "üîç Testing BM25 retrieval with query: 'authentication error'\n",
      "‚úÖ BM25 retrieve: 5 results\n",
      "   First result source: bm25\n",
      "   First result score: 1.0\n",
      "   Content preview: Title: Seam Portlet deployment error on JPP 6\n",
      "Description: Deployment of Seam Portal Project with Se...\n",
      "\n",
      "üîÑ Testing BM25Agent.process()...\n",
      "üîç BM25 Agent processing: 'authentication error'\n",
      "‚úÖ BM25 Agent completed: 5 results in 0.00s\n",
      "‚úÖ BM25Agent.process() completed\n",
      "   Retrieved contexts: 5\n",
      "   Retrieval method: BM25\n",
      "   Processing time: 0.001s\n",
      "   BM25 available: True\n",
      "   Messages added: 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Initialize and test BM25Agent\n",
    "print(\"üîç Testing BM25Agent...\")\n",
    "\n",
    "try:\n",
    "    # Initialize BM25Agent\n",
    "    bm25_agent = BM25Agent(\n",
    "        vectorstore=vectorstore,\n",
    "        rag_llm=rag_llm,\n",
    "        k=5\n",
    "    )\n",
    "    print(\"‚úÖ BM25Agent initialized\")\n",
    "    \n",
    "    # Test BM25 retrieval directly\n",
    "    test_query = \"authentication error\"\n",
    "    print(f\"\\nüîç Testing BM25 retrieval with query: '{test_query}'\")\n",
    "    \n",
    "    bm25_results = bm25_agent.retrieve(test_query)\n",
    "    print(f\"‚úÖ BM25 retrieve: {len(bm25_results)} results\")\n",
    "    \n",
    "    if bm25_results:\n",
    "        first_result = bm25_results[0]\n",
    "        print(f\"   First result source: {first_result.get('source')}\")\n",
    "        print(f\"   First result score: {first_result.get('score')}\")\n",
    "        content_preview = first_result.get('content', '')[:100]\n",
    "        print(f\"   Content preview: {content_preview}...\")\n",
    "    \n",
    "    # Test BM25 agent process method\n",
    "    print(f\"\\nüîÑ Testing BM25Agent.process()...\")\n",
    "    test_state: AgentState = {\n",
    "        'query': test_query,\n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'routing_decision': None,\n",
    "        'routing_reasoning': None,\n",
    "        'retrieved_contexts': [],\n",
    "        'retrieval_method': None,\n",
    "        'retrieval_metadata': {},\n",
    "        'final_answer': None,\n",
    "        'relevant_tickets': [],\n",
    "        'messages': []\n",
    "    }\n",
    "    \n",
    "    processed_state = bm25_agent.process(test_state.copy())\n",
    "    \n",
    "    print(f\"‚úÖ BM25Agent.process() completed\")\n",
    "    print(f\"   Retrieved contexts: {len(processed_state['retrieved_contexts'])}\")\n",
    "    print(f\"   Retrieval method: {processed_state['retrieval_method']}\")\n",
    "    print(f\"   Processing time: {processed_state['retrieval_metadata'].get('processing_time', 'N/A'):.3f}s\")\n",
    "    print(f\"   BM25 available: {processed_state['retrieval_metadata'].get('bm25_available', 'Unknown')}\")\n",
    "    print(f\"   Messages added: {len(processed_state['messages'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå BM25Agent test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:40,876 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection timeout...' in bugs\n",
      "2025-08-19 20:40:40,876 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Testing ContextualCompressionAgent...\n",
      "‚úÖ ContextualCompression with Cohere reranking initialized\n",
      "‚úÖ ContextualCompressionAgent initialized\n",
      "\n",
      "‚ö° Testing ContextualCompression retrieval with query: 'database connection timeout'\n",
      "\n",
      "üìä Normal mode test:\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:41,792 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:41,799 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:41,799 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2524', '0.1924', '0.1757']\n",
      "2025-08-19 20:40:41,800 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:41,802 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection timeout...' in bugs\n",
      "2025-08-19 20:40:41,803 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:40:43,369 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:43,374 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:43,375 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2524', '0.1924', '0.1757']\n",
      "2025-08-19 20:40:43,375 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:43,575 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection timeout...' in bugs\n",
      "2025-08-19 20:40:43,576 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n",
      "‚úÖ Normal mode: 3 results\n",
      "\n",
      "üö® Urgent mode test:\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:44,334 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:44,341 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:44,342 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2524', '0.1924', '0.1757']\n",
      "2025-08-19 20:40:44,342 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:44,344 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection timeout...' in bugs\n",
      "2025-08-19 20:40:44,344 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:40:44,874 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:44,880 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:44,881 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2524', '0.1924', '0.1757']\n",
      "2025-08-19 20:40:44,881 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:49,015 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection timeout...' in bugs\n",
      "2025-08-19 20:40:49,022 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n",
      "‚úÖ Urgent mode: 3 results\n",
      "   First result source: contextual_compression_extracted\n",
      "   First result score: 0.8\n",
      "   Content preview: Title: ServletTestExecutionListener breaks old code\n",
      "Description: The Javadoc for {{ServletTestExecut...\n",
      "\n",
      "üîÑ Testing ContextualCompressionAgent.process()...\n",
      "‚ö° ContextualCompression Agent  processing: 'database connection timeout'\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:49,532 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:49,538 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:49,538 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2524', '0.1924', '0.1757']\n",
      "2025-08-19 20:40:49,539 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:49,540 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection timeout...' in bugs\n",
      "2025-08-19 20:40:49,541 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:40:50,167 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:50,175 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:50,176 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2524', '0.1924', '0.1757']\n",
      "2025-08-19 20:40:50,176 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:50,491 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection timeout...' in bugs\n",
      "2025-08-19 20:40:50,491 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n",
      "‚úÖ ContextualCompression Agent completed: 3 results in 1.50s\n",
      "‚úÖ ContextualCompressionAgent.process() completed\n",
      "   Retrieved contexts: 3\n",
      "   Retrieval method: ContextualCompression\n",
      "   Processing time: 1.499s\n",
      "   Is urgent: False\n",
      "   Primary source: contextual_compression_extracted\n",
      "   Messages added: 1\n",
      "\n",
      "üö® Testing urgent/production incident mode...\n",
      "‚ö° ContextualCompression Agent [URGENT] processing: 'database connection timeout'\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:51,100 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:51,106 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:51,106 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2524', '0.1924', '0.1757']\n",
      "2025-08-19 20:40:51,107 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:51,108 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection timeout...' in bugs\n",
      "2025-08-19 20:40:51,108 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:40:51,612 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:51,618 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:51,619 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2524', '0.1924', '0.1757']\n",
      "2025-08-19 20:40:51,619 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n",
      "‚úÖ ContextualCompression Agent completed: 3 results in 1.24s\n",
      "‚úÖ Urgent mode processing completed\n",
      "   Urgent processing time: 1.240s\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Initialize and test ContextualCompressionAgent\n",
    "print(\"‚ö° Testing ContextualCompressionAgent...\")\n",
    "\n",
    "try:\n",
    "    # Initialize ContextualCompressionAgent\n",
    "    contextual_compression_agent = ContextualCompressionAgent(\n",
    "        vectorstore=vectorstore,\n",
    "        rag_llm=rag_llm,\n",
    "        k=5\n",
    "    )\n",
    "    print(\"‚úÖ ContextualCompressionAgent initialized\")\n",
    "    \n",
    "    # Test ContextualCompression retrieval directly\n",
    "    test_query = \"database connection timeout\"\n",
    "    print(f\"\\n‚ö° Testing ContextualCompression retrieval with query: '{test_query}'\")\n",
    "    \n",
    "    # Test both normal and urgent modes\n",
    "    print(\"\\nüìä Normal mode test:\")\n",
    "    normal_results = contextual_compression_agent.retrieve(test_query, is_urgent=False)\n",
    "    print(f\"‚úÖ Normal mode: {len(normal_results)} results\")\n",
    "    \n",
    "    print(\"\\nüö® Urgent mode test:\")\n",
    "    urgent_results = contextual_compression_agent.retrieve(test_query, is_urgent=True)\n",
    "    print(f\"‚úÖ Urgent mode: {len(urgent_results)} results\")\n",
    "    \n",
    "    if normal_results:\n",
    "        first_result = normal_results[0]\n",
    "        print(f\"   First result source: {first_result.get('source')}\")\n",
    "        print(f\"   First result score: {first_result.get('score')}\")\n",
    "        content_preview = first_result.get('content', '')[:100]\n",
    "        print(f\"   Content preview: {content_preview}...\")\n",
    "    \n",
    "    # Test ContextualCompression agent process method\n",
    "    print(f\"\\nüîÑ Testing ContextualCompressionAgent.process()...\")\n",
    "    \n",
    "    # Test normal processing\n",
    "    test_state: AgentState = {\n",
    "        'query': test_query,\n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'routing_decision': None,\n",
    "        'routing_reasoning': None,\n",
    "        'retrieved_contexts': [],\n",
    "        'retrieval_method': None,\n",
    "        'retrieval_metadata': {},\n",
    "        'final_answer': None,\n",
    "        'relevant_tickets': [],\n",
    "        'messages': []\n",
    "    }\n",
    "    \n",
    "    processed_state = contextual_compression_agent.process(test_state.copy())\n",
    "    \n",
    "    print(f\"‚úÖ ContextualCompressionAgent.process() completed\")\n",
    "    print(f\"   Retrieved contexts: {len(processed_state['retrieved_contexts'])}\")\n",
    "    print(f\"   Retrieval method: {processed_state['retrieval_method']}\")\n",
    "    print(f\"   Processing time: {processed_state['retrieval_metadata'].get('processing_time', 'N/A'):.3f}s\")\n",
    "    print(f\"   Is urgent: {processed_state['retrieval_metadata'].get('is_urgent', 'Unknown')}\")\n",
    "    print(f\"   Primary source: {processed_state['retrieval_metadata'].get('primary_source', 'Unknown')}\")\n",
    "    print(f\"   Messages added: {len(processed_state['messages'])}\")\n",
    "    \n",
    "    # Test urgent processing\n",
    "    print(f\"\\nüö® Testing urgent/production incident mode...\")\n",
    "    urgent_state = test_state.copy()\n",
    "    urgent_state['production_incident'] = True\n",
    "    \n",
    "    urgent_processed_state = contextual_compression_agent.process(urgent_state)\n",
    "    print(f\"‚úÖ Urgent mode processing completed\")\n",
    "    print(f\"   Urgent processing time: {urgent_processed_state['retrieval_metadata'].get('processing_time', 'N/A'):.3f}s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ContextualCompressionAgent test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:51,752 - BM25Agent - INFO - Using BM25 retriever for query: 'memory leak issue...'\n",
      "2025-08-19 20:40:51,753 - BM25Agent - INFO - BM25 retriever returned 5 documents\n",
      "2025-08-19 20:40:51,754 - BM25Agent - INFO - Filtered 5 -> 5 valid documents\n",
      "2025-08-19 20:40:51,755 - BM25Agent - INFO - BM25 retrieve returning 5 results with valid content\n",
      "2025-08-19 20:40:51,755 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'memory leak issue...' in bugs\n",
      "2025-08-19 20:40:51,755 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Testing EnsembleAgent...\n",
      "‚úÖ Ensemble retriever initialized with 4 methods:\n",
      "   ‚Ä¢ Naive: 0.25\n",
      "   ‚Ä¢ Multi-Query: 0.25\n",
      "   ‚Ä¢ ContextualCompression: 0.25\n",
      "   ‚Ä¢ BM25: 0.25\n",
      "‚úÖ EnsembleAgent initialized\n",
      "\n",
      "üîó Testing Ensemble retrieval with query: 'memory leak issue'\n",
      "üîÑ Using individual agent ensemble\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:52,435 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:52,441 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:52,442 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.3259', '0.1876', '0.2366']\n",
      "2025-08-19 20:40:52,442 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:52,444 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'memory leak issue...' in bugs\n",
      "2025-08-19 20:40:52,444 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:40:53,061 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:53,068 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:53,068 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.3259', '0.1876', '0.2366']\n",
      "2025-08-19 20:40:53,069 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:53,199 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'memory leak issue...' in bugs\n",
      "2025-08-19 20:40:53,200 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:53,708 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:53,715 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:53,716 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.3259', '0.1876', '0.2366']\n",
      "2025-08-19 20:40:53,716 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:54,709 - SupabaseRetriever_bugs - INFO - Direct vector search for: '1. How can I address a problem with memory leaks i...' in bugs\n",
      "2025-08-19 20:40:54,709 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:40:55,329 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:55,333 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:55,334 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2978', '0.1605', '0.2061']\n",
      "2025-08-19 20:40:55,334 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:55,335 - SupabaseRetriever_bugs - INFO - Direct vector search for: '2. What are some common causes of memory leaks and...' in bugs\n",
      "2025-08-19 20:40:55,335 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:40:56,080 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:56,086 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:56,087 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2775', '0.1636', '0.2333']\n",
      "2025-08-19 20:40:56,087 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:56,088 - SupabaseRetriever_bugs - INFO - Direct vector search for: '3. Are there any best practices for detecting and ...' in bugs\n",
      "2025-08-19 20:40:56,089 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:40:56,770 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:56,776 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 11 above threshold 0.1\n",
      "2025-08-19 20:40:56,777 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2778', '0.1356', '0.2101']\n",
      "2025-08-19 20:40:56,777 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:56,781 - BM25Agent - INFO - Using BM25 retriever for query: 'memory leak issue...'\n",
      "2025-08-19 20:40:56,782 - BM25Agent - INFO - BM25 retriever returned 5 documents\n",
      "2025-08-19 20:40:56,782 - BM25Agent - INFO - Filtered 5 -> 5 valid documents\n",
      "2025-08-19 20:40:56,783 - BM25Agent - INFO - BM25 retrieve returning 5 results with valid content\n",
      "2025-08-19 20:40:56,784 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'memory leak issue...' in bugs\n",
      "2025-08-19 20:40:56,784 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Individual agent ensemble: 5 deduplicated results\n",
      "‚úÖ Ensemble retrieve: 5 results\n",
      "   Sources used: compression_ensemble, bm25_ensemble, naive_ensemble\n",
      "   First result source: bm25_ensemble\n",
      "   First result score: 1.0\n",
      "   Content preview: Title: Cannot start JBT 4.2.0.Alpha1 on Fedora 19\n",
      "Description: Installing JBT on Eclipse -4.4.M4- 4....\n",
      "\n",
      "üîÑ Testing EnsembleAgent.process()...\n",
      "üîó Ensemble Agent processing: 'memory leak issue'\n",
      "   Using comprehensive multi-method retrieval...\n",
      "üîÑ Using individual agent ensemble\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:57,107 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:57,114 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:57,114 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.3259', '0.1876', '0.2366']\n",
      "2025-08-19 20:40:57,115 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:57,117 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'memory leak issue...' in bugs\n",
      "2025-08-19 20:40:57,117 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:40:57,594 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:57,599 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:57,600 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.3259', '0.1876', '0.2366']\n",
      "2025-08-19 20:40:57,600 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:57,705 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'memory leak issue...' in bugs\n",
      "2025-08-19 20:40:57,705 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:40:58,303 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:40:58,311 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:40:58,311 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.3259', '0.1876', '0.2366']\n",
      "2025-08-19 20:40:58,312 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:40:59,032 - SupabaseRetriever_bugs - INFO - Direct vector search for: '1. How can I address a problem with memory leaks i...' in bugs\n",
      "2025-08-19 20:40:59,033 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:41:00,122 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:41:00,128 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:41:00,128 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2978', '0.1605', '0.2061']\n",
      "2025-08-19 20:41:00,129 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:41:00,129 - SupabaseRetriever_bugs - INFO - Direct vector search for: '2. What are some common causes of memory leaks and...' in bugs\n",
      "2025-08-19 20:41:00,130 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:41:00,745 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:41:00,749 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:41:00,750 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2775', '0.1636', '0.2333']\n",
      "2025-08-19 20:41:00,750 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:41:00,752 - SupabaseRetriever_bugs - INFO - Direct vector search for: '3. Are there any best practices for detecting and ...' in bugs\n",
      "2025-08-19 20:41:00,752 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:41:01,420 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:41:01,426 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 11 above threshold 0.1\n",
      "2025-08-19 20:41:01,427 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2778', '0.1356', '0.2101']\n",
      "2025-08-19 20:41:01,428 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Individual agent ensemble: 5 deduplicated results\n",
      "‚úÖ Ensemble Agent completed: 5 results in 4.65s\n",
      "‚úÖ EnsembleAgent.process() completed\n",
      "   Retrieved contexts: 5\n",
      "   Retrieval method: Ensemble\n",
      "   Processing time: 4.651s\n",
      "   Methods used: ['bm25', 'contextual_compression', 'naive', 'multi_query']\n",
      "   Primary source: bm25_ensemble\n",
      "   Messages added: 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Initialize and test EnsembleAgent\n",
    "print(\"üîó Testing EnsembleAgent...\")\n",
    "\n",
    "try:\n",
    "    # Initialize EnsembleAgent (requires other agents as dependencies)\n",
    "    ensemble_agent = EnsembleAgent(\n",
    "        vectorstore=vectorstore,\n",
    "        rag_llm=rag_llm,\n",
    "        bm25_agent=bm25_agent,\n",
    "        contextual_compression_agent=contextual_compression_agent,\n",
    "        k=8\n",
    "    )\n",
    "    print(\"‚úÖ EnsembleAgent initialized\")\n",
    "    \n",
    "    # Test Ensemble retrieval directly\n",
    "    test_query = \"memory leak issue\"\n",
    "    print(f\"\\nüîó Testing Ensemble retrieval with query: '{test_query}'\")\n",
    "    \n",
    "    ensemble_results = ensemble_agent.retrieve(test_query)\n",
    "    print(f\"‚úÖ Ensemble retrieve: {len(ensemble_results)} results\")\n",
    "    \n",
    "    if ensemble_results:\n",
    "        # Show sources used by ensemble\n",
    "        sources = [result.get('source', 'unknown') for result in ensemble_results]\n",
    "        unique_sources = set(sources)\n",
    "        print(f\"   Sources used: {', '.join(unique_sources)}\")\n",
    "        \n",
    "        # Show first result\n",
    "        first_result = ensemble_results[0]\n",
    "        print(f\"   First result source: {first_result.get('source')}\")\n",
    "        print(f\"   First result score: {first_result.get('score')}\")\n",
    "        content_preview = first_result.get('content', '')[:100]\n",
    "        print(f\"   Content preview: {content_preview}...\")\n",
    "    \n",
    "    # Test Ensemble agent process method\n",
    "    print(f\"\\nüîÑ Testing EnsembleAgent.process()...\")\n",
    "    test_state: AgentState = {\n",
    "        'query': test_query,\n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'routing_decision': None,\n",
    "        'routing_reasoning': None,\n",
    "        'retrieved_contexts': [],\n",
    "        'retrieval_method': None,\n",
    "        'retrieval_metadata': {},\n",
    "        'final_answer': None,\n",
    "        'relevant_tickets': [],\n",
    "        'messages': []\n",
    "    }\n",
    "    \n",
    "    processed_state = ensemble_agent.process(test_state.copy())\n",
    "    \n",
    "    print(f\"‚úÖ EnsembleAgent.process() completed\")\n",
    "    print(f\"   Retrieved contexts: {len(processed_state['retrieved_contexts'])}\")\n",
    "    print(f\"   Retrieval method: {processed_state['retrieval_method']}\")\n",
    "    print(f\"   Processing time: {processed_state['retrieval_metadata'].get('processing_time', 'N/A'):.3f}s\")\n",
    "    print(f\"   Methods used: {processed_state['retrieval_metadata'].get('methods_used', [])}\")\n",
    "    print(f\"   Primary source: {processed_state['retrieval_metadata'].get('primary_source', 'Unknown')}\")\n",
    "    print(f\"   Messages added: {len(processed_state['messages'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå EnsembleAgent test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úçÔ∏è  Testing ResponseWriterAgent...\n",
      "‚úÖ ResponseWriterAgent initialized\n",
      "\n",
      "‚úçÔ∏è  Testing response generation for query: 'How to fix connection timeout issues?'\n",
      "\n",
      "üìù Testing normal response generation...\n",
      "‚úÖ Normal response generated: 873 characters\n",
      "   Response preview: To address connection timeout issues, you can consider the following solutions based on the retrieved JIRA tickets:\n",
      "\n",
      "1. **Increase Timeout Values**: As suggested in [HBASE-456], you can try increasing...\n",
      "\n",
      "üö® Testing urgent response generation...\n",
      "‚úÖ Urgent response generated: 914 characters\n",
      "   Response preview: For addressing connection timeout issues in a production environment, it's crucial to implement immediate solutions. Based on the retrieved JIRA tickets, here are two actionable steps you can take:\n",
      "\n",
      "1...\n",
      "\n",
      "üîÑ Testing ResponseWriterAgent.process()...\n",
      "‚úçÔ∏è  ResponseWriter Agent  generating response...\n",
      "‚úÖ ResponseWriter completed in 3.12s\n",
      "   Generated response: 972 characters\n",
      "   Relevant tickets: 2\n",
      "‚úÖ ResponseWriterAgent.process() completed\n",
      "   Final answer generated: 972 characters\n",
      "   Relevant tickets extracted: 2\n",
      "   Messages added: 1\n",
      "   Tickets: ['HBASE-456', 'HBASE-789']\n",
      "   Final answer preview: To address connection timeout issues, you can consider the following steps based on the retrieved JIRA tickets:\n",
      "\n",
      "1. **Increase Timeout Values**: According to [HBASE-456], one effective way to fix conn...\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Initialize and test ResponseWriterAgent\n",
    "print(\"‚úçÔ∏è  Testing ResponseWriterAgent...\")\n",
    "\n",
    "try:\n",
    "    # Initialize ResponseWriterAgent\n",
    "    response_writer_agent = ResponseWriterAgent(\n",
    "        response_writer_llm=response_writer_llm\n",
    "    )\n",
    "    print(\"‚úÖ ResponseWriterAgent initialized\")\n",
    "    \n",
    "    # Test response generation directly\n",
    "    test_query = \"How to fix connection timeout issues?\"\n",
    "    print(f\"\\n‚úçÔ∏è  Testing response generation for query: '{test_query}'\")\n",
    "    \n",
    "    # Create mock retrieved contexts for testing\n",
    "    mock_contexts = [\n",
    "        {\n",
    "            'content': 'Title: Connection Timeout Fix\\nDescription: Increase timeout values in configuration',\n",
    "            'metadata': {'key': 'HBASE-456', 'title': 'Connection Timeout Fix'},\n",
    "            'score': 0.9,\n",
    "            'source': 'test_source'\n",
    "        },\n",
    "        {\n",
    "            'content': 'Title: Network Configuration\\nDescription: Check network settings for proper connectivity',\n",
    "            'metadata': {'key': 'HBASE-789', 'title': 'Network Configuration'},\n",
    "            'score': 0.8,\n",
    "            'source': 'test_source'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Test normal response generation\n",
    "    print(\"\\nüìù Testing normal response generation...\")\n",
    "    normal_response = response_writer_agent.generate_response(\n",
    "        query=test_query,\n",
    "        retrieved_contexts=mock_contexts,\n",
    "        production_incident=False,\n",
    "        retrieval_method=\"Ensemble\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Normal response generated: {len(normal_response)} characters\")\n",
    "    print(f\"   Response preview: {normal_response[:200]}...\")\n",
    "    \n",
    "    # Test urgent response generation\n",
    "    print(\"\\nüö® Testing urgent response generation...\")\n",
    "    urgent_response = response_writer_agent.generate_response(\n",
    "        query=test_query,\n",
    "        retrieved_contexts=mock_contexts,\n",
    "        production_incident=True,\n",
    "        retrieval_method=\"ContextualCompression\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Urgent response generated: {len(urgent_response)} characters\")\n",
    "    print(f\"   Response preview: {urgent_response[:200]}...\")\n",
    "    \n",
    "    # Test ResponseWriter agent process method\n",
    "    print(f\"\\nüîÑ Testing ResponseWriterAgent.process()...\")\n",
    "    test_state: AgentState = {\n",
    "        'query': test_query,\n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'routing_decision': 'Ensemble',\n",
    "        'routing_reasoning': 'Comprehensive search needed',\n",
    "        'retrieved_contexts': mock_contexts,\n",
    "        'retrieval_method': 'Ensemble',\n",
    "        'retrieval_metadata': {'processing_time': 2.5},\n",
    "        'final_answer': None,\n",
    "        'relevant_tickets': [],\n",
    "        'messages': []\n",
    "    }\n",
    "    \n",
    "    processed_state = response_writer_agent.process(test_state.copy())\n",
    "    \n",
    "    print(f\"‚úÖ ResponseWriterAgent.process() completed\")\n",
    "    print(f\"   Final answer generated: {len(processed_state['final_answer'])} characters\")\n",
    "    print(f\"   Relevant tickets extracted: {len(processed_state['relevant_tickets'])}\")\n",
    "    print(f\"   Messages added: {len(processed_state['messages'])}\")\n",
    "    \n",
    "    if processed_state['relevant_tickets']:\n",
    "        print(f\"   Tickets: {[ticket['key'] for ticket in processed_state['relevant_tickets']]}\")\n",
    "    \n",
    "    print(f\"   Final answer preview: {processed_state['final_answer'][:200]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ResponseWriterAgent test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Testing SupervisorAgent...\n",
      "‚úÖ SupervisorAgent initialized\n",
      "\n",
      "üß† Testing routing decisions...\n",
      "\n",
      "üìã Test Case 1: Specific ticket reference\n",
      "   Query: 'HBASE-123 status'\n",
      "   user_can_wait: True, production_incident: False\n",
      "   ‚úÖ Routed to: BM25 (expected: BM25)\n",
      "   Reasoning: The query contains a specific ticket reference 'HBASE-123', which is best handled by the BM25 agent for fast keyword-based search.\n",
      "\n",
      "üìã Test Case 2: Production incident\n",
      "   Query: 'production server is down'\n",
      "   user_can_wait: False, production_incident: True\n",
      "   ‚ö†Ô∏è  Routed to: WebSearch (expected: ContextualCompression)\n",
      "   Reasoning: The query mentions a service status/outage ('server is down') and it's a production incident, which requires real-time information.\n",
      "\n",
      "üìã Test Case 3: Complex research query\n",
      "   Query: 'comprehensive analysis of memory issues'\n",
      "   user_can_wait: True, production_incident: False\n",
      "   ‚úÖ Routed to: Ensemble (expected: Ensemble)\n",
      "   Reasoning: The query requires a comprehensive analysis of memory issues, and the user can wait for thorough results.\n",
      "\n",
      "üìã Test Case 4: Default routing\n",
      "   Query: 'simple error message'\n",
      "   user_can_wait: False, production_incident: False\n",
      "   ‚úÖ Routed to: ContextualCompression (expected: ContextualCompression)\n",
      "   Reasoning: The query is a general troubleshooting question and the user cannot wait, making ContextualCompression the best choice for fast semantic search.\n",
      "\n",
      "üîÑ Testing SupervisorAgent.process()...\n",
      "üß† Supervisor Agent analyzing query: 'How to fix authentication errors?'\n",
      "   user_can_wait: True, production_incident: False\n",
      "‚úÖ Supervisor decision: Ensemble - The user can wait, and the query is a general troubleshooting question that may benefit from a comprehensive analysis.\n",
      "   Analysis time: 1.25s\n",
      "‚úÖ SupervisorAgent.process() completed\n",
      "   Routing decision: Ensemble\n",
      "   Routing reasoning: The user can wait, and the query is a general troubleshooting question that may benefit from a comprehensive analysis.\n",
      "   Messages added: 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Initialize and test SupervisorAgent\n",
    "print(\"üß† Testing SupervisorAgent...\")\n",
    "\n",
    "try:\n",
    "    # Initialize SupervisorAgent\n",
    "    supervisor_agent = SupervisorAgent(\n",
    "        supervisor_llm=supervisor_llm\n",
    "    )\n",
    "    print(\"‚úÖ SupervisorAgent initialized\")\n",
    "    \n",
    "    # Test different routing scenarios\n",
    "    routing_test_cases = [\n",
    "        {\n",
    "            'query': 'HBASE-123 status',\n",
    "            'user_can_wait': True,\n",
    "            'production_incident': False,\n",
    "            'expected_agent': 'BM25',\n",
    "            'description': 'Specific ticket reference'\n",
    "        },\n",
    "        {\n",
    "            'query': 'production server is down',\n",
    "            'user_can_wait': False,\n",
    "            'production_incident': True,\n",
    "            'expected_agent': 'ContextualCompression',\n",
    "            'description': 'Production incident'\n",
    "        },\n",
    "        {\n",
    "            'query': 'comprehensive analysis of memory issues',\n",
    "            'user_can_wait': True,\n",
    "            'production_incident': False,\n",
    "            'expected_agent': 'Ensemble',\n",
    "            'description': 'Complex research query'\n",
    "        },\n",
    "        {\n",
    "            'query': 'simple error message',\n",
    "            'user_can_wait': False,\n",
    "            'production_incident': False,\n",
    "            'expected_agent': 'ContextualCompression',\n",
    "            'description': 'Default routing'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüß† Testing routing decisions...\")\n",
    "    \n",
    "    for i, test_case in enumerate(routing_test_cases, 1):\n",
    "        print(f\"\\nüìã Test Case {i}: {test_case['description']}\")\n",
    "        print(f\"   Query: '{test_case['query']}'\")\n",
    "        print(f\"   user_can_wait: {test_case['user_can_wait']}, production_incident: {test_case['production_incident']}\")\n",
    "        \n",
    "        routing_result = supervisor_agent.route_query(\n",
    "            query=test_case['query'],\n",
    "            user_can_wait=test_case['user_can_wait'],\n",
    "            production_incident=test_case['production_incident']\n",
    "        )\n",
    "        \n",
    "        routed_agent = routing_result['agent']\n",
    "        reasoning = routing_result['reasoning']\n",
    "        \n",
    "        # Check if routing matches expectation\n",
    "        match_indicator = \"‚úÖ\" if routed_agent == test_case['expected_agent'] else \"‚ö†Ô∏è \"\n",
    "        \n",
    "        print(f\"   {match_indicator} Routed to: {routed_agent} (expected: {test_case['expected_agent']})\")\n",
    "        print(f\"   Reasoning: {reasoning}\")\n",
    "    \n",
    "    # Test SupervisorAgent process method\n",
    "    print(f\"\\nüîÑ Testing SupervisorAgent.process()...\")\n",
    "    test_state: AgentState = {\n",
    "        'query': 'How to fix authentication errors?',\n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'routing_decision': None,\n",
    "        'routing_reasoning': None,\n",
    "        'retrieved_contexts': [],\n",
    "        'retrieval_method': None,\n",
    "        'retrieval_metadata': {},\n",
    "        'final_answer': None,\n",
    "        'relevant_tickets': [],\n",
    "        'messages': []\n",
    "    }\n",
    "    \n",
    "    processed_state = supervisor_agent.process(test_state.copy())\n",
    "    \n",
    "    print(f\"‚úÖ SupervisorAgent.process() completed\")\n",
    "    print(f\"   Routing decision: {processed_state['routing_decision']}\")\n",
    "    print(f\"   Routing reasoning: {processed_state['routing_reasoning']}\")\n",
    "    print(f\"   Messages added: {len(processed_state['messages'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå SupervisorAgent test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3a WebSearch Agent Testing\n",
    "\n",
    "Testing the new WebSearch agent for real-time information retrieval using Tavily API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = {\n",
    "    'components_tested': [],  # List of component names that were tested\n",
    "    'test_results': {},       # Dict with detailed results for each component\n",
    "    'recommendations': [],    # List of recommendation strings\n",
    "    'overall_status': 'PENDING'  # Overall status\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "test_websearch_agent"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê TESTING: WebSearch Agent\n",
      "==================================================\n",
      "‚úÖ WebSearch Agent initialized successfully\n",
      "   Max searches: 3\n",
      "‚úÖ Tavily API connection successful\n",
      "\n",
      "üîç Test Case 1: GitHub status outage...\n",
      "   ‚úÖ Retrieved 10 results\n",
      "   üìä Processing time: 25.08s\n",
      "   üîß Method: WebSearch\n",
      "   üîç Searches performed: 3\n",
      "   üìù Sample result content length: 387\n",
      "   üîó Has URL: True\n",
      "   ‚úÖ EXCELLENT\n",
      "\n",
      "üîç Test Case 2: AWS Lambda service down...\n",
      "   ‚úÖ Retrieved 10 results\n",
      "   üìä Processing time: 25.15s\n",
      "   üîß Method: WebSearch\n",
      "   üîç Searches performed: 3\n",
      "   üìù Sample result content length: 1349\n",
      "   üîó Has URL: True\n",
      "   ‚úÖ EXCELLENT\n",
      "\n",
      "üîç Test Case 3: latest security vulnerability Java Sprin...\n",
      "   ‚úÖ Retrieved 9 results\n",
      "   üìä Processing time: 14.35s\n",
      "   üîß Method: WebSearch\n",
      "   üîç Searches performed: 3\n",
      "   üìù Sample result content length: 1228\n",
      "   üîó Has URL: True\n",
      "   ‚úÖ EXCELLENT\n",
      "\n",
      "üìä WEBSEARCH AGENT SUMMARY:\n",
      "   Test cases run: 3\n",
      "   Successful tests: 3/3\n",
      "   Average results per query: 9.7\n",
      "   Average processing time: 21.53s\n",
      "   Overall WebSearch Status: üü° GOOD\n",
      "\n",
      "üß† Testing Supervisor Routing to WebSearch:\n",
      "   ‚úÖ 'Is GitHub down right now?...' ‚Üí WebSearch\n",
      "   ‚úÖ 'AWS outage status...' ‚Üí WebSearch\n",
      "   ‚úÖ 'Docker Hub service status...' ‚Üí WebSearch\n",
      "   Routing accuracy: 3/3\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import and run WebSearch Agent tests from separate module\n",
    "from test_websearch_agent import test_websearch_agent\n",
    "\n",
    "# Run WebSearch Agent tests\n",
    "summary_data = test_websearch_agent(supervisor_llm, supervisor_agent, summary_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3b LogSearch Agent Testing\n",
    "\n",
    "Testing the new LogSearch agent for production log analysis using GCP Cloud Logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã TESTING: LogSearch Agent (GCP Backend)\n",
      "==================================================\n",
      "‚úÖ LogSearch Agent initialized successfully\n",
      "   Max searches: 3\n",
      "   Backend: gcp\n",
      "‚úÖ GCP backend connection successful\n",
      "   Project: octopus-282815\n",
      "\n",
      "üîç Test Case 1: find recent certificate expired errors...\n",
      "   ‚úÖ Retrieved 1 results\n",
      "   üìä Processing time: 1.93s\n",
      "   üîß Method: LogSearch\n",
      "   üìã Backend: gcp\n",
      "   üîç Searches performed: 1\n",
      "   üìù Sample result content length: 471\n",
      "   ‚è∞ Has timestamp: True\n",
      "   üìä Log level: ERROR\n",
      "   ‚úÖ EXCELLENT\n",
      "\n",
      "üîç Test Case 2: database connection timeout errors in lo...\n",
      "   ‚úÖ Retrieved 0 results\n",
      "   üìä Processing time: 3.01s\n",
      "   üîß Method: LogSearch\n",
      "   üìã Backend: gcp\n",
      "   üîç Searches performed: 1\n",
      "   üü† NO RESULTS\n",
      "\n",
      "üîç Test Case 3: application startup errors last 24 hours...\n",
      "   ‚úÖ Retrieved 0 results\n",
      "   üìä Processing time: 1.98s\n",
      "   üîß Method: LogSearch\n",
      "   üìã Backend: gcp\n",
      "   üîç Searches performed: 1\n",
      "   üü† NO RESULTS\n",
      "\n",
      "üîç Test Case 4: disk space exceeded exceptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Search execution failed: 400 Unparseable filter: syntax error at line 1, column 92, token 'disk'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Retrieved 0 results\n",
      "   üìä Processing time: 1.97s\n",
      "   üîß Method: LogSearch\n",
      "   üìã Backend: gcp\n",
      "   üîç Searches performed: 1\n",
      "   üü† NO RESULTS\n",
      "\n",
      "üìä LOGSEARCH AGENT SUMMARY:\n",
      "   Test cases run: 4\n",
      "   Successful tests: 4/4\n",
      "   Average results per query: 0.2\n",
      "   Average processing time: 2.22s\n",
      "   Backend used: gcp\n",
      "   Overall LogSearch Status: üü† FAIR\n",
      "\n",
      "üß† Testing Supervisor Routing to LogSearch:\n",
      "   ‚úÖ 'investigate recent database connect...' ‚Üí LogSearch\n",
      "   ‚úÖ 'find certificate expired errors in ...' ‚Üí LogSearch\n",
      "   ‚úÖ 'application timeout exceptions last...' ‚Üí LogSearch\n",
      "   ‚úÖ 'disk space errors in production...' ‚Üí LogSearch\n",
      "   Routing accuracy: 4/4\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import and run LogSearch Agent tests from separate module\n",
    "from test_logsearch_agent import test_logsearch_agent\n",
    "\n",
    "# Run LogSearch Agent tests\n",
    "summary_data = test_logsearch_agent(supervisor_llm, supervisor_agent, summary_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° **Phase 4: LangGraph Workflow Testing**\n",
    "\n",
    "Testing the complete LangGraph workflow orchestration system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è  Creating LangGraph node functions...\n",
      "‚úÖ LangGraph node functions created:\n",
      "   ‚Ä¢ supervisor_node\n",
      "   ‚Ä¢ bm25_node\n",
      "   ‚Ä¢ contextual_compression_node\n",
      "   ‚Ä¢ ensemble_node\n",
      "   ‚Ä¢ response_writer_node\n",
      "   ‚Ä¢ route_query (conditional routing)\n",
      "\n",
      "üß™ Testing individual node functions...\n",
      "üß† Supervisor Agent analyzing query: 'test node functions'\n",
      "   user_can_wait: True, production_incident: False\n",
      "‚úÖ Supervisor decision: Ensemble - The query is not urgent, and the user can wait, making it suitable for a comprehensive search.\n",
      "   Analysis time: 1.11s\n",
      "‚úÖ supervisor_node: routing_decision = Ensemble\n",
      "‚úÖ route_query: Ensemble -> ensemble\n",
      "‚úÖ All node functions working correctly\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Create LangGraph node functions\n",
    "print(\"üèóÔ∏è  Creating LangGraph node functions...\")\n",
    "\n",
    "# Agent Node Functions for LangGraph\n",
    "# These functions wrap our agent classes for LangGraph integration\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Supervisor node for intelligent query routing.\"\"\"\n",
    "    return supervisor_agent.process(state)\n",
    "\n",
    "def bm25_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"BM25 retrieval node.\"\"\"\n",
    "    return bm25_agent.process(state)\n",
    "\n",
    "def contextual_compression_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ContextualCompression retrieval node.\"\"\"\n",
    "    return contextual_compression_agent.process(state)\n",
    "\n",
    "def ensemble_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Ensemble retrieval node.\"\"\"\n",
    "    return ensemble_agent.process(state)\n",
    "\n",
    "def response_writer_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ResponseWriter node for final response generation.\"\"\"\n",
    "    return response_writer_agent.process(state)\n",
    "\n",
    "# Routing function for conditional edges\n",
    "def route_query(state: AgentState) -> str:\n",
    "    \"\"\"Route queries based on supervisor decision.\"\"\"\n",
    "    routing_decision = state.get('routing_decision')\n",
    "    \n",
    "    if routing_decision == 'BM25':\n",
    "        return 'bm25'\n",
    "    elif routing_decision == 'ContextualCompression':\n",
    "        return 'contextual_compression'\n",
    "    elif routing_decision == 'Ensemble':\n",
    "        return 'ensemble'\n",
    "    else:\n",
    "        # Default fallback\n",
    "        return 'contextual_compression'\n",
    "\n",
    "print(\"‚úÖ LangGraph node functions created:\")\n",
    "print(\"   ‚Ä¢ supervisor_node\")\n",
    "print(\"   ‚Ä¢ bm25_node\")\n",
    "print(\"   ‚Ä¢ contextual_compression_node\")\n",
    "print(\"   ‚Ä¢ ensemble_node\")\n",
    "print(\"   ‚Ä¢ response_writer_node\")\n",
    "print(\"   ‚Ä¢ route_query (conditional routing)\")\n",
    "\n",
    "# Test node functions individually\n",
    "print(\"\\nüß™ Testing individual node functions...\")\n",
    "\n",
    "try:\n",
    "    # Test supervisor node\n",
    "    test_state: AgentState = {\n",
    "        'query': 'test node functions',\n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'routing_decision': None,\n",
    "        'routing_reasoning': None,\n",
    "        'retrieved_contexts': [],\n",
    "        'retrieval_method': None,\n",
    "        'retrieval_metadata': {},\n",
    "        'final_answer': None,\n",
    "        'relevant_tickets': [],\n",
    "        'messages': []\n",
    "    }\n",
    "    \n",
    "    supervisor_result = supervisor_node(test_state.copy())\n",
    "    print(f\"‚úÖ supervisor_node: routing_decision = {supervisor_result['routing_decision']}\")\n",
    "    \n",
    "    # Test routing function\n",
    "    route_result = route_query(supervisor_result)\n",
    "    print(f\"‚úÖ route_query: {supervisor_result['routing_decision']} -> {route_result}\")\n",
    "    \n",
    "    print(\"‚úÖ All node functions working correctly\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Node function test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Creating LangGraph workflow...\n",
      "üèóÔ∏è  Building LangGraph workflow...\n",
      "‚úÖ Added nodes: supervisor, bm25, contextual_compression, ensemble, response_writer\n",
      "‚úÖ Added workflow edges and routing logic\n",
      "‚úÖ LangGraph workflow compiled successfully!\n",
      "\n",
      "üîó Workflow structure:\n",
      "   START -> supervisor -> [bm25|contextual_compression|ensemble] -> response_writer -> END\n",
      "   Graph nodes: ['__start__', 'supervisor', 'bm25', 'contextual_compression', 'ensemble', 'response_writer', '__end__']\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Create and compile LangGraph workflow\n",
    "print(\"üîó Creating LangGraph workflow...\")\n",
    "\n",
    "try:\n",
    "    from langgraph.graph import StateGraph, END\n",
    "    \n",
    "    print(\"üèóÔ∏è  Building LangGraph workflow...\")\n",
    "    \n",
    "    # Create the StateGraph\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add all nodes to the graph\n",
    "    workflow.add_node(\"supervisor\", supervisor_node)\n",
    "    workflow.add_node(\"bm25\", bm25_node)\n",
    "    workflow.add_node(\"contextual_compression\", contextual_compression_node)\n",
    "    workflow.add_node(\"ensemble\", ensemble_node)\n",
    "    workflow.add_node(\"response_writer\", response_writer_node)\n",
    "    \n",
    "    print(\"‚úÖ Added nodes: supervisor, bm25, contextual_compression, ensemble, response_writer\")\n",
    "    \n",
    "    # Define the workflow edges\n",
    "    # Start with supervisor\n",
    "    workflow.set_entry_point(\"supervisor\")\n",
    "    \n",
    "    # Conditional edges from supervisor to retrieval agents\n",
    "    workflow.add_conditional_edges(\n",
    "        \"supervisor\",\n",
    "        route_query,  # Function that determines the route\n",
    "        {\n",
    "            \"bm25\": \"bm25\",\n",
    "            \"contextual_compression\": \"contextual_compression\",\n",
    "            \"ensemble\": \"ensemble\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # All retrieval agents go to response writer\n",
    "    workflow.add_edge(\"bm25\", \"response_writer\")\n",
    "    workflow.add_edge(\"contextual_compression\", \"response_writer\")\n",
    "    workflow.add_edge(\"ensemble\", \"response_writer\")\n",
    "    \n",
    "    # Response writer goes to END\n",
    "    workflow.add_edge(\"response_writer\", END)\n",
    "    \n",
    "    print(\"‚úÖ Added workflow edges and routing logic\")\n",
    "    \n",
    "    # Compile the workflow\n",
    "    compiled_workflow = workflow.compile()\n",
    "    \n",
    "    print(\"‚úÖ LangGraph workflow compiled successfully!\")\n",
    "    print(\"\\nüîó Workflow structure:\")\n",
    "    print(\"   START -> supervisor -> [bm25|contextual_compression|ensemble] -> response_writer -> END\")\n",
    "    \n",
    "    # Show workflow graph info\n",
    "    if hasattr(compiled_workflow, 'get_graph'):\n",
    "        graph_info = compiled_workflow.get_graph()\n",
    "        print(f\"   Graph nodes: {list(graph_info.nodes.keys()) if hasattr(graph_info, 'nodes') else 'N/A'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LangGraph workflow creation failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    compiled_workflow = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Testing complete LangGraph workflow execution...\n",
      "\n",
      "============================================================\n",
      "üß™ WORKFLOW TEST 1: Specific ticket reference\n",
      "============================================================\n",
      "Query: 'HBASE-456 ticket details'\n",
      "Parameters: user_can_wait=True, production_incident=False\n",
      "Expected route: BM25\n",
      "\n",
      "üöÄ Starting workflow execution...\n",
      "üß† Supervisor Agent analyzing query: 'HBASE-456 ticket details'\n",
      "   user_can_wait: True, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:43:28,383 - BM25Agent - INFO - BM25 Agent processing query: 'HBASE-456 ticket details'\n",
      "2025-08-19 20:43:28,384 - BM25Agent - INFO - Using BM25 retriever for query: 'HBASE-456 ticket details...'\n",
      "2025-08-19 20:43:28,385 - BM25Agent - INFO - BM25 retriever returned 5 documents\n",
      "2025-08-19 20:43:28,385 - BM25Agent - INFO - Filtered 5 -> 5 valid documents\n",
      "2025-08-19 20:43:28,385 - BM25Agent - INFO - BM25 retrieve returning 5 results with valid content\n",
      "2025-08-19 20:43:28,385 - BM25Agent - INFO - BM25 Agent completed in 0.00s with 5 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Supervisor decision: BM25 - The query contains a specific ticket reference 'HBASE-456', which is best handled by the BM25 agent for fast keyword-based search.\n",
      "   Analysis time: 0.85s\n",
      "üîç BM25 Agent processing: 'HBASE-456 ticket details'\n",
      "‚úÖ BM25 Agent completed: 5 results in 0.00s\n",
      "‚úçÔ∏è  ResponseWriter Agent  generating response...\n",
      "‚úÖ ResponseWriter completed in 8.18s\n",
      "   Generated response: 722 characters\n",
      "   Relevant tickets: 5\n",
      "\n",
      "‚úÖ WORKFLOW EXECUTION COMPLETED in 9.07s\n",
      "\n",
      "üìä EXECUTION SUMMARY:\n",
      "   üß† Routing Decision: BM25 (The query contains a specific ticket reference 'HBASE-456', which is best handled by the BM25 agent for fast keyword-based search.)\n",
      "   üîç Retrieval Method: BM25\n",
      "   üìÑ Retrieved Contexts: 5\n",
      "   üé´ Relevant Tickets: 5\n",
      "   üí¨ Messages: 3\n",
      "   ‚è±Ô∏è  Retrieval Time: 0.002s\n",
      "\n",
      "‚úçÔ∏è  FINAL ANSWER (722 chars):\n",
      "   Thank you for your query regarding the HBASE-456 ticket details. Unfortunately, the retrieved JIRA tickets do not include any information related to HBASE-456. The tickets retrieved, such as SPR-11147...\n",
      "\n",
      "üé´ RELEVANT TICKETS:\n",
      "   ‚Ä¢ SPR-11147: XStreamMarshaller doesn't set the converterRegistr...\n",
      "   ‚Ä¢ RF-13394: Toggle control: attributes targetItem and targetPa...\n",
      "   ‚Ä¢ RF-13350: pickList: styleClass attribute is rendered wrongly...\n",
      "\n",
      "üí¨ AGENT MESSAGES:\n",
      "   ‚Ä¢ Supervisor routed query to BM25 agent: The query contains a specific ticket reference 'HBASE-456', which is best handled by the BM25 agent for fast keyword-based search.\n",
      "   ‚Ä¢ BM25 Agent retrieved 5 documents using BM25 keyword search (content filtered)\n",
      "   ‚Ä¢ ResponseWriter generated final answer with 5 relevant tickets\n",
      "\n",
      "‚úÖ ROUTING VERIFICATION: Expected BM25, got BM25 ‚úì\n",
      "\n",
      "üèÅ Test 1 completed\n",
      "\n",
      "\n",
      "============================================================\n",
      "üß™ WORKFLOW TEST 2: Production incident\n",
      "============================================================\n",
      "Query: 'server crashed - need immediate help'\n",
      "Parameters: user_can_wait=False, production_incident=True\n",
      "Expected route: ContextualCompression\n",
      "\n",
      "üöÄ Starting workflow execution...\n",
      "üß† Supervisor Agent analyzing query: 'server crashed - need immediate help'\n",
      "   user_can_wait: False, production_incident: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:43:37,642 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'server crashed - need immediate help...' in bugs\n",
      "2025-08-19 20:43:37,642 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Supervisor decision: ContextualCompression - The query indicates an urgent production incident requiring immediate assistance.\n",
      "   Analysis time: 1.06s\n",
      "‚ö° ContextualCompression Agent [URGENT] processing: 'server crashed - need immediate help'\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:43:39,103 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:43:39,109 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 11 above threshold 0.1\n",
      "2025-08-19 20:43:39,109 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.3059', '0.1878', '0.1752']\n",
      "2025-08-19 20:43:39,109 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:43:39,111 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'server crashed - need immediate help...' in bugs\n",
      "2025-08-19 20:43:39,112 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:43:39,887 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:43:39,893 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 11 above threshold 0.1\n",
      "2025-08-19 20:43:39,895 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.3059', '0.1878', '0.1752']\n",
      "2025-08-19 20:43:39,895 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n",
      "‚úÖ ContextualCompression Agent completed: 3 results in 2.62s\n",
      "‚úçÔ∏è  ResponseWriter Agent [PRODUCTION INCIDENT] generating response...\n",
      "‚úÖ ResponseWriter completed in 7.83s\n",
      "   Generated response: 1751 characters\n",
      "   Relevant tickets: 3\n",
      "\n",
      "‚úÖ WORKFLOW EXECUTION COMPLETED in 11.52s\n",
      "\n",
      "üìä EXECUTION SUMMARY:\n",
      "   üß† Routing Decision: ContextualCompression (The query indicates an urgent production incident requiring immediate assistance.)\n",
      "   üîç Retrieval Method: ContextualCompression\n",
      "   üìÑ Retrieved Contexts: 3\n",
      "   üé´ Relevant Tickets: 3\n",
      "   üí¨ Messages: 3\n",
      "   ‚è±Ô∏è  Retrieval Time: 2.623s\n",
      "\n",
      "‚úçÔ∏è  FINAL ANSWER (1751 chars):\n",
      "   Given the urgency of your query regarding a server crash, and considering this is a production incident, here are some immediate steps and insights based on the retrieved JIRA tickets:\n",
      "\n",
      "1. **Memory Is...\n",
      "\n",
      "üé´ RELEVANT TICKETS:\n",
      "   ‚Ä¢ JBIDE-16308: Cannot start JBT 4.2.0.Alpha1 on Fedora 19...\n",
      "   ‚Ä¢ JBIDE-16273: Java EE Web Project archetype from Central cannot ...\n",
      "   ‚Ä¢ JBIDE-16282: EMMA code coverage tool isn't compatible with Luna...\n",
      "\n",
      "üí¨ AGENT MESSAGES:\n",
      "   ‚Ä¢ Supervisor routed query to ContextualCompression agent: The query indicates an urgent production incident requiring immediate assistance.\n",
      "   ‚Ä¢ ContextualCompression Agent retrieved 3 documents using Compression retriever with content extraction (urgent mode)\n",
      "   ‚Ä¢ ResponseWriter generated final answer with 3 relevant tickets\n",
      "\n",
      "‚úÖ ROUTING VERIFICATION: Expected ContextualCompression, got ContextualCompression ‚úì\n",
      "\n",
      "üèÅ Test 2 completed\n",
      "\n",
      "\n",
      "============================================================\n",
      "üß™ WORKFLOW TEST 3: Complex research query\n",
      "============================================================\n",
      "Query: 'comprehensive analysis of authentication issues across the system'\n",
      "Parameters: user_can_wait=True, production_incident=False\n",
      "Expected route: Ensemble\n",
      "\n",
      "üöÄ Starting workflow execution...\n",
      "üß† Supervisor Agent analyzing query: 'comprehensive analysis of authentication issues across the system'\n",
      "   user_can_wait: True, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:43:49,311 - BM25Agent - INFO - Using BM25 retriever for query: 'comprehensive analysis of authentication issues ac...'\n",
      "2025-08-19 20:43:49,312 - BM25Agent - INFO - BM25 retriever returned 5 documents\n",
      "2025-08-19 20:43:49,313 - BM25Agent - INFO - Filtered 5 -> 5 valid documents\n",
      "2025-08-19 20:43:49,313 - BM25Agent - INFO - BM25 retrieve returning 5 results with valid content\n",
      "2025-08-19 20:43:49,314 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'comprehensive analysis of authentication issues ac...' in bugs\n",
      "2025-08-19 20:43:49,314 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Supervisor decision: Ensemble - The query requires a comprehensive analysis of authentication issues, and the user can wait for thorough results.\n",
      "   Analysis time: 1.20s\n",
      "üîó Ensemble Agent processing: 'comprehensive analysis of authentication issues across the system'\n",
      "   Using comprehensive multi-method retrieval...\n",
      "üîÑ Using individual agent ensemble\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:43:50,107 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:43:50,112 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 11 above threshold 0.1\n",
      "2025-08-19 20:43:50,113 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1309', '0.2149', '0.1381']\n",
      "2025-08-19 20:43:50,113 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:43:50,114 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'comprehensive analysis of authentication issues ac...' in bugs\n",
      "2025-08-19 20:43:50,115 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:43:50,741 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:43:50,746 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 11 above threshold 0.1\n",
      "2025-08-19 20:43:50,746 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1309', '0.2150', '0.1382']\n",
      "2025-08-19 20:43:50,747 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:43:51,070 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'comprehensive analysis of authentication issues ac...' in bugs\n",
      "2025-08-19 20:43:51,070 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:43:51,613 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:43:51,619 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 11 above threshold 0.1\n",
      "2025-08-19 20:43:51,619 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1309', '0.2149', '0.1381']\n",
      "2025-08-19 20:43:51,620 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:43:52,373 - SupabaseRetriever_bugs - INFO - Direct vector search for: '1. Can you provide a detailed examination of authe...' in bugs\n",
      "2025-08-19 20:43:52,373 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:43:52,950 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:43:52,953 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:43:52,953 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1179', '0.1862', '0.1144']\n",
      "2025-08-19 20:43:52,953 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:43:52,954 - SupabaseRetriever_bugs - INFO - Direct vector search for: '2. What are the key factors contributing to authen...' in bugs\n",
      "2025-08-19 20:43:52,955 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:43:53,606 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:43:53,610 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 11 above threshold 0.1\n",
      "2025-08-19 20:43:53,610 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1760', '0.1826', '0.1689']\n",
      "2025-08-19 20:43:53,610 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:43:53,611 - SupabaseRetriever_bugs - INFO - Direct vector search for: '3. How can we conduct a thorough review of authent...' in bugs\n",
      "2025-08-19 20:43:53,611 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:43:54,137 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:43:54,141 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:43:54,142 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1494', '0.1821', '0.1555']\n",
      "2025-08-19 20:43:54,142 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Individual agent ensemble: 8 deduplicated results\n",
      "‚úÖ Ensemble Agent completed: 8 results in 4.83s\n",
      "‚úçÔ∏è  ResponseWriter Agent  generating response...\n",
      "‚úÖ ResponseWriter completed in 6.29s\n",
      "   Generated response: 1115 characters\n",
      "   Relevant tickets: 8\n",
      "\n",
      "‚úÖ WORKFLOW EXECUTION COMPLETED in 12.36s\n",
      "\n",
      "üìä EXECUTION SUMMARY:\n",
      "   üß† Routing Decision: Ensemble (The query requires a comprehensive analysis of authentication issues, and the user can wait for thorough results.)\n",
      "   üîç Retrieval Method: Ensemble\n",
      "   üìÑ Retrieved Contexts: 8\n",
      "   üé´ Relevant Tickets: 8\n",
      "   üí¨ Messages: 3\n",
      "   ‚è±Ô∏è  Retrieval Time: 4.834s\n",
      "\n",
      "‚úçÔ∏è  FINAL ANSWER (1115 chars):\n",
      "   Based on your query regarding a comprehensive analysis of authentication issues across the system, it appears that none of the retrieved JIRA tickets directly address authentication issues. The ticket...\n",
      "\n",
      "üé´ RELEVANT TICKETS:\n",
      "   ‚Ä¢ FLEX-33924: iTunes Store submit email....\n",
      "   ‚Ä¢ HBASE-8902: IntegrationTestBulkLoad takes way too long...\n",
      "   ‚Ä¢ SPR-11132: EhCacheFactoryBean.afterPropertiesSet should be sy...\n",
      "\n",
      "üí¨ AGENT MESSAGES:\n",
      "   ‚Ä¢ Supervisor routed query to Ensemble agent: The query requires a comprehensive analysis of authentication issues, and the user can wait for thorough results.\n",
      "   ‚Ä¢ Ensemble Agent retrieved 8 documents using Individual agent ensemble (bm25, contextual_compression, naive, multi_query)\n",
      "   ‚Ä¢ ResponseWriter generated final answer with 8 relevant tickets\n",
      "\n",
      "‚úÖ ROUTING VERIFICATION: Expected Ensemble, got Ensemble ‚úì\n",
      "\n",
      "üèÅ Test 3 completed\n",
      "\n",
      "============================================================\n",
      "üéâ ALL WORKFLOW TESTS COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Test complete LangGraph workflow execution\n",
    "print(\"üöÄ Testing complete LangGraph workflow execution...\")\n",
    "\n",
    "if compiled_workflow is None:\n",
    "    print(\"‚ùå Cannot test workflow - compilation failed in previous cell\")\n",
    "else:\n",
    "    # Test different types of queries to exercise different routing paths\n",
    "    test_queries = [\n",
    "        {\n",
    "            'query': 'HBASE-456 ticket details',\n",
    "            'user_can_wait': True,\n",
    "            'production_incident': False,\n",
    "            'expected_route': 'BM25',\n",
    "            'description': 'Specific ticket reference'\n",
    "        },\n",
    "        {\n",
    "            'query': 'server crashed - need immediate help',\n",
    "            'user_can_wait': False,\n",
    "            'production_incident': True,\n",
    "            'expected_route': 'ContextualCompression',\n",
    "            'description': 'Production incident'\n",
    "        },\n",
    "        {\n",
    "            'query': 'comprehensive analysis of authentication issues across the system',\n",
    "            'user_can_wait': True,\n",
    "            'production_incident': False,\n",
    "            'expected_route': 'Ensemble',\n",
    "            'description': 'Complex research query'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, test_case in enumerate(test_queries, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üß™ WORKFLOW TEST {i}: {test_case['description']}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Query: '{test_case['query']}'\")\n",
    "        print(f\"Parameters: user_can_wait={test_case['user_can_wait']}, production_incident={test_case['production_incident']}\")\n",
    "        print(f\"Expected route: {test_case['expected_route']}\")\n",
    "        \n",
    "        try:\n",
    "            # Create initial state\n",
    "            initial_state: AgentState = {\n",
    "                'query': test_case['query'],\n",
    "                'user_can_wait': test_case['user_can_wait'],\n",
    "                'production_incident': test_case['production_incident'],\n",
    "                'routing_decision': None,\n",
    "                'routing_reasoning': None,\n",
    "                'retrieved_contexts': [],\n",
    "                'retrieval_method': None,\n",
    "                'retrieval_metadata': {},\n",
    "                'final_answer': None,\n",
    "                'relevant_tickets': [],\n",
    "                'messages': []\n",
    "            }\n",
    "            \n",
    "            print(\"\\nüöÄ Starting workflow execution...\")\n",
    "            \n",
    "            # Execute the workflow\n",
    "            start_time = datetime.now()\n",
    "            final_state = compiled_workflow.invoke(initial_state)\n",
    "            execution_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            print(f\"\\n‚úÖ WORKFLOW EXECUTION COMPLETED in {execution_time:.2f}s\")\n",
    "            print(f\"\\nüìä EXECUTION SUMMARY:\")\n",
    "            print(f\"   üß† Routing Decision: {final_state.get('routing_decision')} ({final_state.get('routing_reasoning')})\")\n",
    "            print(f\"   üîç Retrieval Method: {final_state.get('retrieval_method')}\")\n",
    "            print(f\"   üìÑ Retrieved Contexts: {len(final_state.get('retrieved_contexts', []))}\")\n",
    "            print(f\"   üé´ Relevant Tickets: {len(final_state.get('relevant_tickets', []))}\")\n",
    "            print(f\"   üí¨ Messages: {len(final_state.get('messages', []))}\")\n",
    "            \n",
    "            # Show retrieval metadata\n",
    "            retrieval_metadata = final_state.get('retrieval_metadata', {})\n",
    "            if retrieval_metadata:\n",
    "                processing_time = retrieval_metadata.get('processing_time', 'N/A')\n",
    "                print(f\"   ‚è±Ô∏è  Retrieval Time: {processing_time:.3f}s\" if isinstance(processing_time, float) else f\"   ‚è±Ô∏è  Retrieval Time: {processing_time}\")\n",
    "            \n",
    "            # Show final answer preview\n",
    "            final_answer = final_state.get('final_answer', '')\n",
    "            if final_answer:\n",
    "                print(f\"\\n‚úçÔ∏è  FINAL ANSWER ({len(final_answer)} chars):\")\n",
    "                print(f\"   {final_answer[:200]}{'...' if len(final_answer) > 200 else ''}\")\n",
    "            \n",
    "            # Show relevant tickets\n",
    "            relevant_tickets = final_state.get('relevant_tickets', [])\n",
    "            if relevant_tickets:\n",
    "                print(f\"\\nüé´ RELEVANT TICKETS:\")\n",
    "                for ticket in relevant_tickets[:3]:  # Show first 3\n",
    "                    print(f\"   ‚Ä¢ {ticket.get('key', 'N/A')}: {ticket.get('title', 'No title')[:50]}...\")\n",
    "            \n",
    "            # Show agent messages\n",
    "            messages = final_state.get('messages', [])\n",
    "            if messages:\n",
    "                print(f\"\\nüí¨ AGENT MESSAGES:\")\n",
    "                for msg in messages:\n",
    "                    if hasattr(msg, 'content'):\n",
    "                        print(f\"   ‚Ä¢ {msg.content}\")\n",
    "            \n",
    "            # Verify expected routing\n",
    "            actual_route = final_state.get('routing_decision')\n",
    "            if actual_route == test_case['expected_route']:\n",
    "                print(f\"\\n‚úÖ ROUTING VERIFICATION: Expected {test_case['expected_route']}, got {actual_route} ‚úì\")\n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è  ROUTING VERIFICATION: Expected {test_case['expected_route']}, got {actual_route}\")\n",
    "                print(f\"   This might be due to LLM routing variability - not necessarily an error\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå WORKFLOW TEST {i} FAILED: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "        print(f\"\\nüèÅ Test {i} completed\\n\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üéâ ALL WORKFLOW TESTS COMPLETED\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä **Phase 5: Performance and Integration Analysis**\n",
    "\n",
    "Analyzing the performance and integration aspects of the multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:44:00,501 - BM25Agent - INFO - BM25 Agent processing query: 'database connection error timeout'\n",
      "2025-08-19 20:44:00,503 - BM25Agent - INFO - Using BM25 retriever for query: 'database connection error timeout...'\n",
      "2025-08-19 20:44:00,508 - BM25Agent - INFO - BM25 retriever returned 5 documents\n",
      "2025-08-19 20:44:00,509 - BM25Agent - INFO - Filtered 5 -> 5 valid documents\n",
      "2025-08-19 20:44:00,509 - BM25Agent - INFO - BM25 retrieve returning 5 results with valid content\n",
      "2025-08-19 20:44:00,509 - BM25Agent - INFO - BM25 Agent completed in 0.01s with 5 results\n",
      "2025-08-19 20:44:00,510 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection error timeout...' in bugs\n",
      "2025-08-19 20:44:00,510 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Performance comparison between individual agents...\n",
      "\n",
      "üèÉ Performance testing with query: 'database connection error timeout'\n",
      "\n",
      "‚è±Ô∏è  Testing BM25Agent...\n",
      "üîç BM25 Agent processing: 'database connection error timeout'\n",
      "‚úÖ BM25 Agent completed: 5 results in 0.01s\n",
      "   ‚úÖ BM25: 0.008s, 5 results\n",
      "‚è±Ô∏è  Testing ContextualCompressionAgent...\n",
      "‚ö° ContextualCompression Agent  processing: 'database connection error timeout'\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:44:01,175 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:01,179 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:44:01,180 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2513', '0.1837', '0.1588']\n",
      "2025-08-19 20:44:01,180 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:44:01,181 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection error timeout...' in bugs\n",
      "2025-08-19 20:44:01,181 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:44:02,201 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:02,206 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:44:02,206 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2513', '0.1837', '0.1588']\n",
      "2025-08-19 20:44:02,207 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:44:02,390 - BM25Agent - INFO - Using BM25 retriever for query: 'database connection error timeout...'\n",
      "2025-08-19 20:44:02,391 - BM25Agent - INFO - BM25 retriever returned 5 documents\n",
      "2025-08-19 20:44:02,391 - BM25Agent - INFO - Filtered 5 -> 5 valid documents\n",
      "2025-08-19 20:44:02,391 - BM25Agent - INFO - BM25 retrieve returning 5 results with valid content\n",
      "2025-08-19 20:44:02,392 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection error timeout...' in bugs\n",
      "2025-08-19 20:44:02,392 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n",
      "‚úÖ ContextualCompression Agent completed: 3 results in 1.88s\n",
      "   ‚úÖ ContextualCompression: 1.881s, 3 results\n",
      "‚è±Ô∏è  Testing EnsembleAgent...\n",
      "üîó Ensemble Agent processing: 'database connection error timeout'\n",
      "   Using comprehensive multi-method retrieval...\n",
      "üîÑ Using individual agent ensemble\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:44:03,194 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:03,198 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:44:03,198 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2513', '0.1837', '0.1588']\n",
      "2025-08-19 20:44:03,199 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:44:03,200 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection error timeout...' in bugs\n",
      "2025-08-19 20:44:03,200 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:44:03,932 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:03,935 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:44:03,935 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2513', '0.1837', '0.1588']\n",
      "2025-08-19 20:44:03,935 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:44:04,039 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'database connection error timeout...' in bugs\n",
      "2025-08-19 20:44:04,040 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:44:04,736 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:04,740 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:44:04,740 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2513', '0.1837', '0.1588']\n",
      "2025-08-19 20:44:04,741 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:44:05,401 - SupabaseRetriever_bugs - INFO - Direct vector search for: '1. What are common causes of database connection e...' in bugs\n",
      "2025-08-19 20:44:05,414 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:44:06,278 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:06,283 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:44:06,283 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1762', '0.1395', '0.1620']\n",
      "2025-08-19 20:44:06,284 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:44:06,285 - SupabaseRetriever_bugs - INFO - Direct vector search for: '2. How can I troubleshoot a database connection er...' in bugs\n",
      "2025-08-19 20:44:06,286 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:44:06,847 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:06,853 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:44:06,853 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2047', '0.1446', '0.1169']\n",
      "2025-08-19 20:44:06,854 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:44:06,854 - SupabaseRetriever_bugs - INFO - Direct vector search for: '3. What steps can be taken to resolve a database c...' in bugs\n",
      "2025-08-19 20:44:06,855 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:44:07,383 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:07,387 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 12 above threshold 0.1\n",
      "2025-08-19 20:44:07,387 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.2415', '0.1617', '0.1657']\n",
      "2025-08-19 20:44:07,387 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Individual agent ensemble: 8 deduplicated results\n",
      "‚úÖ Ensemble Agent completed: 8 results in 5.00s\n",
      "   ‚úÖ Ensemble: 5.001s, 8 results\n",
      "\n",
      "üìà PERFORMANCE SUMMARY:\n",
      "Agent                Time (s)   Results  Method Type              \n",
      "-----------------------------------------------------------------\n",
      "BM25                 0.008      5        keyword_based            \n",
      "ContextualCompression 1.881      3        semantic_with_reranking  \n",
      "Ensemble             5.001      8        multi_method_ensemble    \n",
      "\n",
      "üí° PERFORMANCE INSIGHTS:\n",
      "   üèÉ Fastest: BM25 (0.008s)\n",
      "   üêå Slowest: Ensemble (5.001s)\n",
      "   üìä Most results: Ensemble (8 results)\n",
      "   ‚è±Ô∏è  Speed difference: 4.992s (59808.0% slower)\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Performance comparison between agents\n",
    "print(\"üìä Performance comparison between individual agents...\")\n",
    "\n",
    "if 'bm25_agent' in locals() and 'contextual_compression_agent' in locals() and 'ensemble_agent' in locals():\n",
    "    test_query = \"database connection error timeout\"\n",
    "    performance_results = []\n",
    "    \n",
    "    print(f\"\\nüèÉ Performance testing with query: '{test_query}'\\n\")\n",
    "    \n",
    "    # Test each agent's performance\n",
    "    agents_to_test = [\n",
    "        ('BM25', bm25_agent),\n",
    "        ('ContextualCompression', contextual_compression_agent),\n",
    "        ('Ensemble', ensemble_agent)\n",
    "    ]\n",
    "    \n",
    "    for agent_name, agent in agents_to_test:\n",
    "        try:\n",
    "            print(f\"‚è±Ô∏è  Testing {agent_name}Agent...\")\n",
    "            \n",
    "            # Create test state\n",
    "            test_state: AgentState = {\n",
    "                'query': test_query,\n",
    "                'user_can_wait': True,\n",
    "                'production_incident': False,\n",
    "                'routing_decision': None,\n",
    "                'routing_reasoning': None,\n",
    "                'retrieved_contexts': [],\n",
    "                'retrieval_method': None,\n",
    "                'retrieval_metadata': {},\n",
    "                'final_answer': None,\n",
    "                'relevant_tickets': [],\n",
    "                'messages': []\n",
    "            }\n",
    "            \n",
    "            # Measure execution time\n",
    "            start_time = datetime.now()\n",
    "            result_state = agent.process(test_state.copy())\n",
    "            execution_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            # Collect results\n",
    "            num_results = len(result_state.get('retrieved_contexts', []))\n",
    "            retrieval_metadata = result_state.get('retrieval_metadata', {})\n",
    "            \n",
    "            performance_results.append({\n",
    "                'agent': agent_name,\n",
    "                'execution_time': execution_time,\n",
    "                'num_results': num_results,\n",
    "                'retrieval_time': retrieval_metadata.get('processing_time', execution_time),\n",
    "                'method_type': retrieval_metadata.get('method_type', 'unknown'),\n",
    "                'additional_info': retrieval_metadata\n",
    "            })\n",
    "            \n",
    "            print(f\"   ‚úÖ {agent_name}: {execution_time:.3f}s, {num_results} results\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå {agent_name} failed: {e}\")\n",
    "            performance_results.append({\n",
    "                'agent': agent_name,\n",
    "                'execution_time': float('inf'),\n",
    "                'num_results': 0,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Display performance summary\n",
    "    print(\"\\nüìà PERFORMANCE SUMMARY:\")\n",
    "    print(f\"{'Agent':<20} {'Time (s)':<10} {'Results':<8} {'Method Type':<25}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    # Sort by execution time\n",
    "    performance_results.sort(key=lambda x: x['execution_time'])\n",
    "    \n",
    "    for result in performance_results:\n",
    "        if 'error' not in result:\n",
    "            agent = result['agent']\n",
    "            exec_time = f\"{result['execution_time']:.3f}\"\n",
    "            num_results = str(result['num_results'])\n",
    "            method_type = result.get('method_type', 'unknown')[:24]\n",
    "            \n",
    "            print(f\"{agent:<20} {exec_time:<10} {num_results:<8} {method_type:<25}\")\n",
    "        else:\n",
    "            print(f\"{result['agent']:<20} {'ERROR':<10} {'0':<8} {result.get('error', '')[:24]:<25}\")\n",
    "    \n",
    "    # Performance insights\n",
    "    print(\"\\nüí° PERFORMANCE INSIGHTS:\")\n",
    "    valid_results = [r for r in performance_results if 'error' not in r]\n",
    "    \n",
    "    if valid_results:\n",
    "        fastest = min(valid_results, key=lambda x: x['execution_time'])\n",
    "        slowest = max(valid_results, key=lambda x: x['execution_time'])\n",
    "        most_results = max(valid_results, key=lambda x: x['num_results'])\n",
    "        \n",
    "        print(f\"   üèÉ Fastest: {fastest['agent']} ({fastest['execution_time']:.3f}s)\")\n",
    "        print(f\"   üêå Slowest: {slowest['agent']} ({slowest['execution_time']:.3f}s)\")\n",
    "        print(f\"   üìä Most results: {most_results['agent']} ({most_results['num_results']} results)\")\n",
    "        \n",
    "        if len(valid_results) > 1:\n",
    "            time_diff = slowest['execution_time'] - fastest['execution_time']\n",
    "            print(f\"   ‚è±Ô∏è  Speed difference: {time_diff:.3f}s ({time_diff/fastest['execution_time']*100:.1f}% slower)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot perform performance comparison - agents not properly initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "cell-15"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:44:07,422 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'test...' in bugs\n",
      "2025-08-19 20:44:07,422 - SupabaseRetriever_bugs - INFO - Parameters: k=1, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Integration and workflow health check...\n",
      "\n",
      "üè• COMPONENT HEALTH CHECK:\n",
      "----------------------------------------\n",
      "‚úÖ Supabase Client: Initialized\n",
      "‚úÖ Vectorstore: Initialized\n",
      "‚úÖ LLMs: Initialized\n",
      "‚úÖ BM25 Agent: Initialized\n",
      "‚úÖ ContextualCompression Agent: Initialized\n",
      "‚úÖ Ensemble Agent: Initialized\n",
      "‚úÖ ResponseWriter Agent: Initialized\n",
      "‚úÖ Supervisor Agent: Initialized\n",
      "‚úÖ Compiled Workflow: Initialized\n",
      "\n",
      "üîó INTEGRATION HEALTH CHECK:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:44:08,168 - SupabaseRetriever_bugs - INFO - Processing 3 candidates for similarity calculation\n",
      "2025-08-19 20:44:08,169 - SupabaseRetriever_bugs - INFO - Calculated 3 similarities, 2 above threshold 0.1\n",
      "2025-08-19 20:44:08,169 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1566', '0.1008']\n",
      "2025-08-19 20:44:08,169 - SupabaseRetriever_bugs - INFO - Direct vector search returned 1 results (from 3 candidates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vectorstore Search: 1 results\n",
      "‚úÖ LLM Connectivity: AIMessage\n",
      "‚úÖ Agent State Creation: Working\n",
      "üß† Supervisor Agent analyzing query: 'test integration'\n",
      "   user_can_wait: True, production_incident: False\n",
      "‚úÖ Supervisor decision: Ensemble - The user can wait, and the query is not urgent or specific, suggesting a comprehensive search is appropriate.\n",
      "   Analysis time: 1.21s\n",
      "‚úÖ Node Function Execution: Working\n",
      "\n",
      "‚ö° WORKFLOW HEALTH CHECK:\n",
      "----------------------------------------\n",
      "üß† Supervisor Agent analyzing query: 'health check test'\n",
      "   user_can_wait: False, production_incident: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:44:11,010 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'health check test...' in bugs\n",
      "2025-08-19 20:44:11,011 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Supervisor decision: ContextualCompression - The query is a general troubleshooting question and the user cannot wait, making ContextualCompression the best choice for fast semantic search.\n",
      "   Analysis time: 1.22s\n",
      "‚ö° ContextualCompression Agent  processing: 'health check test'\n",
      "üîÑ Using compression retriever with LangChain wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:44:11,760 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:11,763 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 6 above threshold 0.1\n",
      "2025-08-19 20:44:11,763 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1059', '0.1264', '0.1356']\n",
      "2025-08-19 20:44:11,764 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n",
      "2025-08-19 20:44:11,764 - SupabaseRetriever_bugs - INFO - Direct vector search for: 'health check test...' in bugs\n",
      "2025-08-19 20:44:11,765 - SupabaseRetriever_bugs - INFO - Parameters: k=4, similarity_threshold=0.1, filters=None\n",
      "2025-08-19 20:44:12,471 - SupabaseRetriever_bugs - INFO - Processing 12 candidates for similarity calculation\n",
      "2025-08-19 20:44:12,475 - SupabaseRetriever_bugs - INFO - Calculated 12 similarities, 6 above threshold 0.1\n",
      "2025-08-19 20:44:12,475 - SupabaseRetriever_bugs - INFO - Result similarities: ['0.1058', '0.1265', '0.1355']\n",
      "2025-08-19 20:44:12,475 - SupabaseRetriever_bugs - INFO - Direct vector search returned 4 results (from 12 candidates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compression retriever with content extraction: 3 results\n",
      "‚úÖ ContextualCompression Agent completed: 3 results in 1.63s\n",
      "‚úçÔ∏è  ResponseWriter Agent  generating response...\n",
      "‚úÖ ResponseWriter completed in 4.63s\n",
      "   Generated response: 830 characters\n",
      "   Relevant tickets: 3\n",
      "‚úÖ End-to-End Workflow: Complete execution successful\n",
      "‚úÖ Workflow Completeness: All required fields populated\n",
      "\n",
      "üè• OVERALL HEALTH ASSESSMENT:\n",
      "==================================================\n",
      "System Health: üü¢ EXCELLENT (15/15 checks passed - 100.0%)\n",
      "\n",
      "Components: 9/9 OK\n",
      "Integration: 4/4 OK\n",
      "Workflow: 2/2 OK\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Integration and workflow health check\n",
    "print(\"üîç Integration and workflow health check...\")\n",
    "\n",
    "health_check_results = {\n",
    "    'components': {},\n",
    "    'integration': {},\n",
    "    'workflow': {},\n",
    "    'overall_status': 'UNKNOWN'\n",
    "}\n",
    "\n",
    "# Component health check\n",
    "print(\"\\nüè• COMPONENT HEALTH CHECK:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "components_to_check = [\n",
    "    ('Supabase Client', 'supabase_client'),\n",
    "    ('Vectorstore', 'vectorstore'),\n",
    "    ('LLMs', 'rag_llm'),\n",
    "    ('BM25 Agent', 'bm25_agent'),\n",
    "    ('ContextualCompression Agent', 'contextual_compression_agent'),\n",
    "    ('Ensemble Agent', 'ensemble_agent'),\n",
    "    ('ResponseWriter Agent', 'response_writer_agent'),\n",
    "    ('Supervisor Agent', 'supervisor_agent'),\n",
    "    ('Compiled Workflow', 'compiled_workflow')\n",
    "]\n",
    "\n",
    "for component_name, variable_name in components_to_check:\n",
    "    try:\n",
    "        if variable_name in locals() or variable_name in globals():\n",
    "            component = locals().get(variable_name) or globals().get(variable_name)\n",
    "            if component is not None:\n",
    "                print(f\"‚úÖ {component_name}: Initialized\")\n",
    "                health_check_results['components'][component_name] = 'OK'\n",
    "            else:\n",
    "                print(f\"‚ùå {component_name}: Variable exists but is None\")\n",
    "                health_check_results['components'][component_name] = 'NULL'\n",
    "        else:\n",
    "            print(f\"‚ùå {component_name}: Not found\")\n",
    "            health_check_results['components'][component_name] = 'MISSING'\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  {component_name}: Error checking - {e}\")\n",
    "        health_check_results['components'][component_name] = 'ERROR'\n",
    "\n",
    "# Integration health check\n",
    "# Integration Health Check - Simplified and Direct\n",
    "print(\"\\nüîó INTEGRATION HEALTH CHECK:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Test vectorstore directly\n",
    "try:\n",
    "    if vectorstore is not None:\n",
    "        test_result = vectorstore.similarity_search(\"test\", k=1)\n",
    "        print(f\"‚úÖ Vectorstore Search: {len(test_result)} results\")\n",
    "        health_check_results['integration']['Vectorstore Search'] = 'OK'\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Vectorstore Search: vectorstore is None\")\n",
    "        health_check_results['integration']['Vectorstore Search'] = 'NULL'\n",
    "except NameError:\n",
    "    print(\"‚ùå Vectorstore Search: Variable not found\")\n",
    "    health_check_results['integration']['Vectorstore Search'] = 'MISSING'\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Vectorstore Search: Failed - {str(e)[:50]}...\")\n",
    "    health_check_results['integration']['Vectorstore Search'] = 'FAILED'\n",
    "\n",
    "# Test LLM directly\n",
    "try:\n",
    "    if rag_llm is not None:\n",
    "        test_result = rag_llm.invoke(\"test\")\n",
    "        print(f\"‚úÖ LLM Connectivity: {type(test_result).__name__}\")\n",
    "        health_check_results['integration']['LLM Connectivity'] = 'OK'\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  LLM Connectivity: rag_llm is None\")\n",
    "        health_check_results['integration']['LLM Connectivity'] = 'NULL'\n",
    "except NameError:\n",
    "    print(\"‚ùå LLM Connectivity: Variable not found\")\n",
    "    health_check_results['integration']['LLM Connectivity'] = 'MISSING'\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM Connectivity: Failed - {str(e)[:50]}...\")\n",
    "    health_check_results['integration']['LLM Connectivity'] = 'FAILED'\n",
    "\n",
    "# Test agent state creation\n",
    "try:\n",
    "    test_state = {\n",
    "        'query': 'test',\n",
    "        'user_can_wait': True,\n",
    "        'production_incident': False,\n",
    "        'routing_decision': None,\n",
    "        'routing_reasoning': None,\n",
    "        'retrieved_contexts': [],\n",
    "        'retrieval_method': None,\n",
    "        'retrieval_metadata': {},\n",
    "        'final_answer': None,\n",
    "        'relevant_tickets': [],\n",
    "        'messages': []\n",
    "    }\n",
    "    print(\"‚úÖ Agent State Creation: Working\")\n",
    "    health_check_results['integration']['Agent State Creation'] = 'OK'\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Agent State Creation: Failed - {str(e)[:50]}...\")\n",
    "    health_check_results['integration']['Agent State Creation'] = 'FAILED'\n",
    "\n",
    "# Test node function execution\n",
    "try:\n",
    "    if supervisor_node is not None:\n",
    "        test_result = supervisor_node({\n",
    "            'query': 'test integration',\n",
    "            'user_can_wait': True,\n",
    "            'production_incident': False,\n",
    "            'routing_decision': None,\n",
    "            'routing_reasoning': None,\n",
    "            'retrieved_contexts': [],\n",
    "            'retrieval_method': None,\n",
    "            'retrieval_metadata': {},\n",
    "            'final_answer': None,\n",
    "            'relevant_tickets': [],\n",
    "            'messages': []\n",
    "        })\n",
    "        if test_result is not None and isinstance(test_result, dict):\n",
    "            print(\"‚úÖ Node Function Execution: Working\")\n",
    "            health_check_results['integration']['Node Function Execution'] = 'OK'\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Node Function Execution: Returned invalid result\")\n",
    "            health_check_results['integration']['Node Function Execution'] = 'NULL'\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Node Function Execution: supervisor_node is None\")\n",
    "        health_check_results['integration']['Node Function Execution'] = 'NULL'\n",
    "except NameError:\n",
    "    print(\"‚ùå Node Function Execution: supervisor_node not found\")\n",
    "    health_check_results['integration']['Node Function Execution'] = 'MISSING'\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Node Function Execution: Failed - {str(e)[:50]}...\")\n",
    "    health_check_results['integration']['Node Function Execution'] = 'FAILED'       \n",
    "# Workflow health check\n",
    "print(\"\\n‚ö° WORKFLOW HEALTH CHECK:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'compiled_workflow' in locals() and compiled_workflow is not None:\n",
    "    try:\n",
    "        # Quick workflow test\n",
    "        quick_test_state: AgentState = {\n",
    "            'query': 'health check test',\n",
    "            'user_can_wait': False,\n",
    "            'production_incident': False,\n",
    "            'routing_decision': None,\n",
    "            'routing_reasoning': None,\n",
    "            'retrieved_contexts': [],\n",
    "            'retrieval_method': None,\n",
    "            'retrieval_metadata': {},\n",
    "            'final_answer': None,\n",
    "            'relevant_tickets': [],\n",
    "            'messages': []\n",
    "        }\n",
    "        \n",
    "        workflow_result = compiled_workflow.invoke(quick_test_state)\n",
    "        \n",
    "        if workflow_result and workflow_result.get('final_answer'):\n",
    "            print(\"‚úÖ End-to-End Workflow: Complete execution successful\")\n",
    "            health_check_results['workflow']['end_to_end'] = 'OK'\n",
    "            \n",
    "            # Check workflow completeness\n",
    "            required_fields = ['routing_decision', 'retrieval_method', 'final_answer']\n",
    "            missing_fields = [field for field in required_fields if not workflow_result.get(field)]\n",
    "            \n",
    "            if not missing_fields:\n",
    "                print(\"‚úÖ Workflow Completeness: All required fields populated\")\n",
    "                health_check_results['workflow']['completeness'] = 'OK'\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Workflow Completeness: Missing fields - {missing_fields}\")\n",
    "                health_check_results['workflow']['completeness'] = 'INCOMPLETE'\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  End-to-End Workflow: Execution completed but no final answer\")\n",
    "            health_check_results['workflow']['end_to_end'] = 'INCOMPLETE'\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå End-to-End Workflow: Failed - {e}\")\n",
    "        health_check_results['workflow']['end_to_end'] = 'FAILED'\n",
    "else:\n",
    "    print(\"‚ùå End-to-End Workflow: Compiled workflow not available\")\n",
    "    health_check_results['workflow']['end_to_end'] = 'MISSING'\n",
    "\n",
    "# Overall health assessment\n",
    "print(\"\\nüè• OVERALL HEALTH ASSESSMENT:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "all_statuses = []\n",
    "all_statuses.extend(health_check_results['components'].values())\n",
    "all_statuses.extend(health_check_results['integration'].values())\n",
    "all_statuses.extend(health_check_results['workflow'].values())\n",
    "\n",
    "ok_count = all_statuses.count('OK')\n",
    "total_count = len(all_statuses)\n",
    "health_percentage = (ok_count / total_count) * 100 if total_count > 0 else 0\n",
    "\n",
    "if health_percentage >= 90:\n",
    "    overall_status = \"üü¢ EXCELLENT\"\n",
    "    health_check_results['overall_status'] = 'EXCELLENT'\n",
    "elif health_percentage >= 75:\n",
    "    overall_status = \"üü° GOOD\"\n",
    "    health_check_results['overall_status'] = 'GOOD'\n",
    "elif health_percentage >= 50:\n",
    "    overall_status = \"üü† FAIR\"\n",
    "    health_check_results['overall_status'] = 'FAIR'\n",
    "else:\n",
    "    overall_status = \"üî¥ POOR\"\n",
    "    health_check_results['overall_status'] = 'POOR'\n",
    "\n",
    "print(f\"System Health: {overall_status} ({ok_count}/{total_count} checks passed - {health_percentage:.1f}%)\")\n",
    "print(f\"\\nComponents: {sum(1 for v in health_check_results['components'].values() if v == 'OK')}/{len(health_check_results['components'])} OK\")\n",
    "print(f\"Integration: {sum(1 for v in health_check_results['integration'].values() if v == 'OK')}/{len(health_check_results['integration'])} OK\")\n",
    "print(f\"Workflow: {sum(1 for v in health_check_results['workflow'].values() if v == 'OK')}/{len(health_check_results['workflow'])} OK\")\n",
    "\n",
    "if health_percentage < 100:\n",
    "    failed_checks = [category + '.' + name for category, checks in health_check_results.items() \n",
    "                    if isinstance(checks, dict) for name, status in checks.items() if status != 'OK']\n",
    "    print(f\"\\n‚ö†Ô∏è  Issues found: {', '.join(failed_checks)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ **Phase 6: Final Summary and Recommendations**\n",
    "\n",
    "Comprehensive summary of testing results and recommendations for system optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã FINAL TESTING SUMMARY AND RECOMMENDATIONS\n",
      "============================================================\n",
      "\n",
      "üß™ COMPONENTS TESTED:\n",
      "   ‚úÖ AgentState class and common utilities\n",
      "   ‚úÖ LLM components (GPT-3.5-turbo, GPT-4o)\n",
      "   ‚úÖ Supabase vectorstore integration\n",
      "   ‚úÖ BM25Agent (keyword-based retrieval)\n",
      "   ‚úÖ ContextualCompressionAgent (semantic + reranking)\n",
      "   ‚úÖ EnsembleAgent (multi-method retrieval)\n",
      "   ‚úÖ ResponseWriterAgent (GPT-4o response generation)\n",
      "   ‚úÖ SupervisorAgent (intelligent query routing)\n",
      "   ‚úÖ LangGraph workflow orchestration\n",
      "   ‚úÖ End-to-end query processing\n",
      "\n",
      "üìä PERFORMANCE INSIGHTS:\n",
      "   üèÉ Best Performance: BM25 (0.008s)\n",
      "   üîç Most Comprehensive: Ensemble (5.001s, 8 results)\n",
      "\n",
      "üè• SYSTEM HEALTH: EXCELLENT\n",
      "   Components: 9 OK\n",
      "   Integration: 4 OK\n",
      "   Workflow: 2 OK\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   1. üöÄ PERFORMANCE: Consider caching for slower retrieval methods to improve response times\n",
      "   2. üîó ENSEMBLE: Consider parallel processing for ensemble methods to reduce latency\n",
      "   3. üìä MONITORING: Implement metrics collection for production usage\n",
      "   4. üîí SECURITY: Review API key management and access controls\n",
      "   5. üìà SCALING: Consider connection pooling for high-throughput scenarios\n",
      "   6. üß™ TESTING: Add automated testing for continuous integration\n",
      "   7. üìù DOCUMENTATION: Document optimal query patterns for each agent type\n",
      "\n",
      "üéØ AGENT USAGE GUIDELINES:\n",
      "   ‚Ä¢ üîç BM25Agent: Use for specific ticket IDs, exact error messages, technical terms\n",
      "   ‚Ä¢ ‚ö° ContextualCompressionAgent: Use for production incidents, general troubleshooting\n",
      "   ‚Ä¢ üîó EnsembleAgent: Use for complex research queries, comprehensive analysis\n",
      "   ‚Ä¢ üß† SupervisorAgent: Automatically routes queries based on urgency and complexity\n",
      "\n",
      "============================================================\n",
      "üéâ TESTING COMPLETE: Multi-agent system is ready for production use!\n",
      "   All core components are functioning correctly.\n",
      "   LangGraph workflow orchestration is working as expected.\n",
      "\n",
      "üìã Test results summary available in local variables for further analysis.\n",
      "============================================================\n",
      "\n",
      "üíæ Test summary data saved to 'test_summary' variable\n",
      "   Timestamp: 2025-08-19T20:44:17.337547\n",
      "   Components tested: 10\n",
      "   Recommendations: 7\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Final testing summary and recommendations\n",
    "print(\"üìã FINAL TESTING SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Collect all test results\n",
    "summary_data = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'components_tested': [],\n",
    "    'performance_data': [],\n",
    "    'health_check': health_check_results if 'health_check_results' in locals() else {},\n",
    "    'recommendations': []\n",
    "}\n",
    "\n",
    "\n",
    "# Components tested\n",
    "components_tested = [\n",
    "    '‚úÖ AgentState class and common utilities',\n",
    "    '‚úÖ LLM components (GPT-3.5-turbo, GPT-4o)',\n",
    "    '‚úÖ Supabase vectorstore integration',\n",
    "    '‚úÖ BM25Agent (keyword-based retrieval)',\n",
    "    '‚úÖ ContextualCompressionAgent (semantic + reranking)',\n",
    "    '‚úÖ EnsembleAgent (multi-method retrieval)',\n",
    "    '‚úÖ ResponseWriterAgent (GPT-4o response generation)',\n",
    "    '‚úÖ SupervisorAgent (intelligent query routing)',\n",
    "    '‚úÖ LangGraph workflow orchestration',\n",
    "    '‚úÖ End-to-end query processing'\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ COMPONENTS TESTED:\")\n",
    "for component in components_tested:\n",
    "    print(f\"   {component}\")\n",
    "    summary_data['components_tested'].append(component)\n",
    "\n",
    "# Performance insights\n",
    "print(\"\\nüìä PERFORMANCE INSIGHTS:\")\n",
    "if 'performance_results' in locals() and performance_results:\n",
    "    valid_results = [r for r in performance_results if 'error' not in r]\n",
    "    if valid_results:\n",
    "        fastest = min(valid_results, key=lambda x: x['execution_time'])\n",
    "        slowest = max(valid_results, key=lambda x: x['execution_time'])\n",
    "        \n",
    "        print(f\"   üèÉ Best Performance: {fastest['agent']} ({fastest['execution_time']:.3f}s)\")\n",
    "        print(f\"   üîç Most Comprehensive: {slowest['agent']} ({slowest['execution_time']:.3f}s, {slowest['num_results']} results)\")\n",
    "        \n",
    "        summary_data['performance_data'] = {\n",
    "            'fastest_agent': fastest['agent'],\n",
    "            'fastest_time': fastest['execution_time'],\n",
    "            'most_comprehensive': slowest['agent'],\n",
    "            'comprehensive_time': slowest['execution_time'],\n",
    "            'all_results': performance_results\n",
    "        }\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Performance data not available\")\n",
    "\n",
    "# Health check summary\n",
    "if 'health_check_results' in locals():\n",
    "    overall_status = health_check_results.get('overall_status', 'UNKNOWN')\n",
    "    print(f\"\\nüè• SYSTEM HEALTH: {overall_status}\")\n",
    "    \n",
    "    # Count successful components\n",
    "    components_ok = sum(1 for v in health_check_results.get('components', {}).values() if v == 'OK')\n",
    "    integration_ok = sum(1 for v in health_check_results.get('integration', {}).values() if v == 'OK')\n",
    "    workflow_ok = sum(1 for v in health_check_results.get('workflow', {}).values() if v == 'OK')\n",
    "    \n",
    "    print(f\"   Components: {components_ok} OK\")\n",
    "    print(f\"   Integration: {integration_ok} OK\")\n",
    "    print(f\"   Workflow: {workflow_ok} OK\")\n",
    "\n",
    "# Generate recommendations\n",
    "print(\"\\nüí° RECOMMENDATIONS:\")\n",
    "recommendations = []\n",
    "\n",
    "# Performance recommendations\n",
    "if 'performance_results' in locals() and performance_results:\n",
    "    valid_results = [r for r in performance_results if 'error' not in r]\n",
    "    if valid_results:\n",
    "        fastest_time = min(r['execution_time'] for r in valid_results)\n",
    "        slowest_time = max(r['execution_time'] for r in valid_results)\n",
    "        \n",
    "        if slowest_time > fastest_time * 3:\n",
    "            recommendations.append(\"üöÄ PERFORMANCE: Consider caching for slower retrieval methods to improve response times\")\n",
    "        \n",
    "        ensemble_result = next((r for r in valid_results if r['agent'] == 'Ensemble'), None)\n",
    "        if ensemble_result and ensemble_result['execution_time'] > 2.0:\n",
    "            recommendations.append(\"üîó ENSEMBLE: Consider parallel processing for ensemble methods to reduce latency\")\n",
    "\n",
    "# Health-based recommendations\n",
    "if 'health_check_results' in locals():\n",
    "    failed_components = [name for name, status in health_check_results.get('components', {}).items() if status != 'OK']\n",
    "    if failed_components:\n",
    "        recommendations.append(f\"üîß COMPONENTS: Address issues with: {', '.join(failed_components)}\")\n",
    "    \n",
    "    failed_integration = [name for name, status in health_check_results.get('integration', {}).items() if status != 'OK']\n",
    "    if failed_integration:\n",
    "        recommendations.append(f\"üîó INTEGRATION: Fix integration issues: {', '.join(failed_integration)}\")\n",
    "    \n",
    "    workflow_status = health_check_results.get('workflow', {}).get('end_to_end')\n",
    "    if workflow_status != 'OK':\n",
    "        recommendations.append(\"‚ö° WORKFLOW: Debug end-to-end workflow execution issues\")\n",
    "\n",
    "# General recommendations\n",
    "general_recommendations = [\n",
    "    \"üìä MONITORING: Implement metrics collection for production usage\",\n",
    "    \"üîí SECURITY: Review API key management and access controls\",\n",
    "    \"üìà SCALING: Consider connection pooling for high-throughput scenarios\",\n",
    "    \"üß™ TESTING: Add automated testing for continuous integration\",\n",
    "    \"üìù DOCUMENTATION: Document optimal query patterns for each agent type\"\n",
    "]\n",
    "\n",
    "recommendations.extend(general_recommendations)\n",
    "\n",
    "# Display recommendations\n",
    "for i, recommendation in enumerate(recommendations, 1):\n",
    "    print(f\"   {i}. {recommendation}\")\n",
    "    summary_data['recommendations'].append(recommendation)\n",
    "\n",
    "# Agent usage guidelines\n",
    "print(\"\\nüéØ AGENT USAGE GUIDELINES:\")\n",
    "usage_guidelines = [\n",
    "    \"üîç BM25Agent: Use for specific ticket IDs, exact error messages, technical terms\",\n",
    "    \"‚ö° ContextualCompressionAgent: Use for production incidents, general troubleshooting\",\n",
    "    \"üîó EnsembleAgent: Use for complex research queries, comprehensive analysis\",\n",
    "    \"üß† SupervisorAgent: Automatically routes queries based on urgency and complexity\"\n",
    "]\n",
    "\n",
    "for guideline in usage_guidelines:\n",
    "    print(f\"   ‚Ä¢ {guideline}\")\n",
    "\n",
    "# Final status\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if 'health_check_results' in locals():\n",
    "    overall_status = health_check_results.get('overall_status', 'UNKNOWN')\n",
    "    if overall_status in ['EXCELLENT', 'GOOD']:\n",
    "        print(\"üéâ TESTING COMPLETE: Multi-agent system is ready for production use!\")\n",
    "        print(\"   All core components are functioning correctly.\")\n",
    "        print(\"   LangGraph workflow orchestration is working as expected.\")\n",
    "    elif overall_status == 'FAIR':\n",
    "        print(\"‚ö†Ô∏è  TESTING COMPLETE: System is functional but needs attention.\")\n",
    "        print(\"   Address the recommendations above before production deployment.\")\n",
    "    else:\n",
    "        print(\"‚ùå TESTING COMPLETE: System has significant issues.\")\n",
    "        print(\"   Critical fixes needed before production use.\")\n",
    "else:\n",
    "    print(\"‚úÖ TESTING COMPLETE: All individual components tested successfully.\")\n",
    "    print(\"   System appears ready for further integration testing.\")\n",
    "\n",
    "print(\"\\nüìã Test results summary available in local variables for further analysis.\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save summary data for potential export\n",
    "test_summary = summary_data\n",
    "print(f\"\\nüíæ Test summary data saved to 'test_summary' variable\")\n",
    "print(f\"   Timestamp: {test_summary['timestamp']}\")\n",
    "print(f\"   Components tested: {len(test_summary['components_tested'])}\")\n",
    "print(f\"   Recommendations: {len(test_summary['recommendations'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
