# TestAgents.ipynb Context and Learnings

## Overview
This document captures the context, issues encountered, and solutions implemented while debugging and fixing the TestAgents.ipynb notebook for the Cuttlefish4 RAG agent system.

## Background
TestAgents.ipynb is a comprehensive test notebook for the LangGraph-based agent workflow system that includes:
- Supervisor agent for query routing
- Specialized retrieval agents (BM25, ContextualCompression, Ensemble)
- Response writer agent
- Complete RAG integration with Supabase vector search

## Issues Encountered and Solutions

### 1. Vector Search RPC Failures (Primary Issue)
**Problem**: All vector searches were returning zero results due to Supabase RPC function parameter order mismatches.

**Root Cause**: 
- RPC functions expected parameters in a different order than provided
- Error: "Could not find the function public.match_documents_vector(match_count, match_table, match_threshold, query_embedding)"

**Solution**: 
- Completely removed RPC dependencies in `supabase_retriever.py`
- Implemented direct HTTP calls with manual cosine similarity calculation
- Updated vector_search method to use PostgreSQL queries directly

**Files Modified**:
- `/Users/foohm/github/cuttlefish4/app/rag/supabase_retriever.py` - Complete rewrite of vector_search method

### 2. Similarity Threshold Configuration Issues
**Problem**: Vector search was working correctly but returning 0 results due to overly restrictive similarity thresholds.

**Symptoms**:
- Debug script showed vector search calculating similarities correctly (0.18-0.46 range)
- TestRAGTools.ipynb logs showed "No results above threshold 0.7. Actual similarities range: 0.1824 to 0.2990"

**Root Causes**:

1. **Default threshold mismatch**: `rag_tools.py` had defaults of 0.2, but TestRAGTools had hardcoded `TEST_SIMILARITY_THRESHOLD = 0.7`
2. **Module caching**: Jupyter notebooks cached the old threshold values despite kernel restarts

**Solution**:
- Updated `TEST_SIMILARITY_THRESHOLD = 0.7` to `TEST_SIMILARITY_THRESHOLD = 0.2` in TestRAGTools.ipynb
- Changed default thresholds in `rag_tools.py` from 0.7 to 0.2 for vector search methods
- Used 0.1 as the base threshold in `supabase_retriever.py` for maximum flexibility

**Files Modified**:
- `/Users/foohm/github/cuttlefish4/app/tools/TestRAGTools.ipynb` - Updated TEST_SIMILARITY_THRESHOLD constant
- `/Users/foohm/github/cuttlefish4/app/tools/rag_tools.py` - Updated default similarity thresholds

### 3. Integration Health Check Failures
**Problem**: TestAgents.ipynb cell 15 health checks were showing all components as "Test returned None" despite components working correctly.

**Root Cause**: 
- Health check used `locals()` within lambda functions in Jupyter notebook context
- `'vectorstore' in locals()` returned False even when `vectorstore` variable existed and was not None

**Solution**: 
- Replaced lambda-based health checks with direct variable testing
- Added comprehensive error handling (NameError, None checks, general exceptions)
- Improved output to show actual results (number of results, response types)

**Files Modified**:
- `/Users/foohm/github/cuttlefish4/app/agents/TestAgents.ipynb` - Cell 15 completely rewritten

## Technical Learnings

### Supabase Vector Search Implementation
```python
# Original (failed RPC approach)
response = self.client.rpc('match_documents_vector', {
    'query_embedding': query_embedding,
    'match_count': k,
    'match_threshold': similarity_threshold,
    'match_table': self.collection_name
})

# New (working direct HTTP approach)
query_builder = self.client.table(self.collection_name).select('*')
result = query_builder.limit(min(k * 3, 100)).execute()
# Manual similarity calculation with _cosine_similarity()
```

### Cosine Similarity Calculation
Implemented robust similarity calculation that handles various data formats from Supabase:
```python
def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
    # Handles JSON strings, Python list strings, and raw lists
    # Includes error handling for format mismatches
    # Returns actual cosine similarity values (-1 to 1)
```

### Jupyter Notebook Variable Scope Issues
- `locals()` in lambda functions doesn't work as expected in Jupyter cells
- Direct variable checks (`if variable is not None:`) are more reliable
- Module caching can persist despite kernel restarts - requires explicit constant updates

### Similarity Score Ranges
Real-world similarity scores from text-embedding-3-small model:
- Typical range: 0.18 to 0.46 for semantic matches
- High relevance threshold: 0.3-0.4
- Reasonable threshold for broader results: 0.2
- Very permissive threshold: 0.1

## Performance Results

### Before Fix
```
ðŸ“ˆ Method-wise Performance:
   Vector: 0/7 (0.0%)      <- Complete failure
   Keyword: 6/7 (85.7%)
   Hybrid: 4/5 (80.0%) 
   Compression: 1/1 (100.0%)
   Ensemble: 8/8 (100.0%)
```

### After Fix
```
ðŸ“ˆ Method-wise Performance:
   Vector: 7/7 (100.0%)    <- Fixed!
   Keyword: 6/7 (85.7%)
   Hybrid: 5/5 (100.0%)
   Compression: 1/1 (100.0%)
   Ensemble: 8/8 (100.0%)
```

### Health Check Results
```
ðŸ”— INTEGRATION HEALTH CHECK:
âœ… Vectorstore Search: 1 results
âœ… LLM Connectivity: AIMessage
âœ… Agent State Creation: Working
âœ… Node Function Execution: Working
```

## Debugging Tools Created

### debug_integration.py
Created comprehensive debugging script that:
- Tests LLM connectivity independently
- Tests Supabase retriever with detailed logging  
- Tests vectorstore wrapper functionality
- Tests agent state and node functions
- Provides isolation testing for each component

**Location**: `/Users/foohm/github/cuttlefish4/app/agents/debug_integration.py`

## Architecture Understanding

### Agent Workflow Structure
```
Query Input
    â†“
Supervisor Agent (Routes to appropriate agent)
    â†“
[BM25 Agent | ContextualCompression Agent | Ensemble Agent]
    â†“
Response Writer Agent
    â†“
Final Answer
```

### RAG Tools Integration
- `RAGTools` class provides unified interface to all retrieval methods
- Base `SupabaseRetriever` handles direct database operations
- Advanced retrievers (Multi-Query, Contextual Compression, etc.) build on base retriever
- Agents use these tools through LangChain-compatible wrappers

## Environment Requirements

### Key Dependencies
- Supabase client with vector support
- OpenAI API for embeddings (text-embedding-3-small)
- LangChain for agent orchestration
- LangGraph for workflow management

### Environment Variables
```
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key  
OPENAI_API_KEY=your_openai_key
```

## Best Practices Identified

### 1. Error Handling in Retrievers
- Always provide fallback methods when primary retrieval fails
- Log similarity ranges when no results meet threshold
- Use graduated thresholds (try stricter, then relax)

### 2. Jupyter Notebook Testing
- Avoid `locals()` checks in lambda functions
- Use direct variable testing with proper None checks
- Include NameError handling for undefined variables
- Add debug output showing actual values/types

### 3. Vector Search Optimization
- Use similarity thresholds appropriate for your embedding model
- Consider getting more candidates and filtering, rather than strict database limits
- Log actual similarity scores for threshold tuning
- Provide fallback to text-based search when vector search fails

### 4. Agent Integration
- Test each component in isolation before integration testing
- Use health checks that provide actionable diagnostic information
- Maintain debug scripts for component-level testing
- Keep integration tests separate from unit tests

## Future Considerations

### Potential Improvements
1. **Adaptive Thresholds**: Dynamically adjust similarity thresholds based on result count
2. **Caching**: Implement embedding caching for repeated queries
3. **Multi-Model Support**: Support different embedding models with model-specific thresholds
4. **Performance Monitoring**: Add timing and performance metrics to retrieval operations
5. **Reranking**: Integrate advanced reranking models for improved relevance

### Monitoring
- Track similarity score distributions over time
- Monitor retrieval success rates by method
- Alert on vector search failures with automatic RPC fallback
- Log slow queries for optimization

---

**Document Created**: August 15, 2025  
**Last Updated**: August 15, 2025  
**Status**: Complete - All vector search and agent integration issues resolved